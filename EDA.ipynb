{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load data\n",
    "\n",
    "data = np.loadtxt('training_data.txt', skiprows=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = data[:,range(1,1001)]\n",
    "y_train = data[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load words\n",
    "\n",
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "# Import data and labels\n",
    "training_data = np.loadtxt('data/training_data.txt', skiprows=1)\n",
    "with open('data/training_data.txt') as f:\n",
    "    reader = csv.reader(f, delimiter=\" \")\n",
    "    labels = next(reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.84725\n",
      "0.84725\n",
      "0.84775\n",
      "0.84675\n",
      "0.84775\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Test Normalization\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# KFold cross validation\n",
    "\n",
    "# from sklearn.model_selection import KFold\n",
    "    \n",
    "# kf = KFold(n_splits = 5, shuffle=True)\n",
    "# inds = [ind for ind in kf.split(x_train, y_train)]\n",
    "\n",
    "# for fold in range(5):\n",
    "#     x_train_folds = x_train[inds[fold][0]]\n",
    "#     x_val_folds = x_train[inds[fold][1]]\n",
    "#     y_train_folds = y_train[inds[fold][0]]\n",
    "#     y_val_folds = y_train[inds[fold][1]]\n",
    "    \n",
    "# print(len(x_train_folds))\n",
    "\n",
    "# Split the data\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train_s, x_val, y_train_s, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# w/o normalization\n",
    "\n",
    "# l1 regularization\n",
    "\n",
    "model = LogisticRegression(penalty='l1')\n",
    "model.fit(x_train_s, y_train_s)\n",
    "\n",
    "print(model.score(x_val, y_val))\n",
    "\n",
    "# l2 regularization\n",
    "\n",
    "model = LogisticRegression(penalty='l1')\n",
    "model.fit(x_train_s, y_train_s)\n",
    "\n",
    "print(model.score(x_val, y_val))\n",
    "\n",
    "# w/ normalization\n",
    "\n",
    "x_train_s_norm = preprocessing.normalize(x_train_s, norm='l2')\n",
    "x_val_norm = preprocessing.normalize(x_val, norm='l2')\n",
    "\n",
    "# l1 regularization\n",
    "\n",
    "model = LogisticRegression(penalty='l1')\n",
    "model.fit(x_train_s_norm, y_train_s)\n",
    "\n",
    "print(model.score(x_val_norm, y_val))\n",
    "\n",
    "# l2 regularization\n",
    "\n",
    "model = LogisticRegression(penalty='l2')\n",
    "model.fit(x_train_s_norm, y_train_s)\n",
    "\n",
    "print(model.score(x_val_norm, y_val))\n",
    "\n",
    "# Recoded data: 0 and 1 to -1 and 1\n",
    "\n",
    "y_train_neg1 = y_train\n",
    "y_train_neg1[y_train == 0] = -1\n",
    "\n",
    "x_train_s, x_val, y_train_s, y_val = train_test_split(x_train, y_train_neg1, test_size=0.2, random_state=42)\n",
    "\n",
    "x_train_s_norm = preprocessing.normalize(x_train_s, norm='l2')\n",
    "x_val_norm = preprocessing.normalize(x_val, norm='l2')\n",
    "\n",
    "# Best model\n",
    "\n",
    "model = LogisticRegression(penalty='l1')\n",
    "model.fit(x_train_s_norm, y_train_s)\n",
    "\n",
    "print(model.score(x_val_norm, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Optimize regularization parameter Logistic Regression of best model \n",
    "# (l1-regularized, normalized data)\n",
    "\n",
    "cs = []\n",
    "ci = 0.00001\n",
    "for i in range(18):\n",
    "    ci = 5*ci\n",
    "    cs.append(ci)\n",
    "    \n",
    "x_train_s, x_val, y_train_s, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=42)\n",
    "x_train_s_norm = preprocessing.normalize(x_train_s, norm='l2')\n",
    "x_val_norm = preprocessing.normalize(x_val, norm='l2')\n",
    "\n",
    "opt_c = []\n",
    "for ci in cs:\n",
    "    model = LogisticRegression(penalty='l1', C=ci)\n",
    "    model.fit(x_train_s_norm, y_train_s)\n",
    "    opt_c.append(model.score(x_val_norm, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 0.84950000000000003, 3.90625)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(opt_c), opt_c[7], cs[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Optimize regularization parameter Logistic Regression of best model \n",
    "# (l1-regularized, non normalized data)\n",
    "\n",
    "cs = []\n",
    "ci = 0.00001\n",
    "for i in range(18):\n",
    "    ci = 5*ci\n",
    "    cs.append(ci)\n",
    "    \n",
    "x_train_s, x_val, y_train_s, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "opt_c = []\n",
    "for ci in cs:\n",
    "    model = LogisticRegression(penalty='l1', C=ci)\n",
    "    model.fit(x_train_s, y_train_s)\n",
    "    opt_c.append(model.score(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Predict on test set\n",
    "\n",
    "data_train = np.loadtxt('training_data.txt', skiprows=1)\n",
    "data_test = np.loadtxt('test_data.txt', skiprows=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = data_train[:,range(1,1001)]\n",
    "y_train = data_train[:,0]\n",
    "\n",
    "x_test = data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Id  Prediction\n",
      "0   1           1\n",
      "1   2           1\n",
      "2   3           0\n",
      "3   4           0\n",
      "4   5           0\n",
      "5   6           0\n",
      "6   7           1\n",
      "7   8           1\n",
      "8   9           1\n",
      "9  10           0\n"
     ]
    }
   ],
   "source": [
    "# Best Logistic Regression Model\n",
    "\n",
    "# Normalize data\n",
    "x_train_norm = preprocessing.normalize(x_train, norm='l2')\n",
    "x_test_norm = preprocessing.normalize(x_test, norm='l2')\n",
    "\n",
    "model = LogisticRegression(penalty='l1', C=3.90625)\n",
    "model.fit(x_train_norm, y_train)\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "submission = pd.DataFrame({'Id': range(1, len(x_test)+1), 'Prediction': [int(x) for x in y_pred]})\n",
    "print(submission.head(10))\n",
    "\n",
    "submission.to_csv('submission_Logistic_Regression.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8471875\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression(C=3.1, penalty='l1')\n",
    "model.fit(x_train_s_norm, y_train_s)\n",
    "\n",
    "print(model.score(x_val_norm, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8303125\n"
     ]
    }
   ],
   "source": [
    "# Eric's best Logistic Regression\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression(C=0.33, penalty='l1')\n",
    "model.fit(x_train_s_norm, y_train_s)\n",
    "\n",
    "print(model.score(x_val_norm, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Id  Prediction\n",
      "0   1           1\n",
      "1   2           1\n",
      "2   3           0\n",
      "3   4           0\n",
      "4   5           0\n",
      "5   6           0\n",
      "6   7           1\n",
      "7   8           1\n",
      "8   9           1\n",
      "9  10           0\n"
     ]
    }
   ],
   "source": [
    "# Trying different C \n",
    "\n",
    "# Best Logistic Regression Model\n",
    "\n",
    "model = LogisticRegression(penalty='l1', C=0.28436)\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "submission = pd.DataFrame({'Id': range(1, len(x_test)+1), 'Prediction': [int(x) for x in y_pred]})\n",
    "print(submission.head(10))\n",
    "\n",
    "submission.to_csv('submission_Logistic_Regression_Eric_opt.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Id  Prediction\n",
      "0   1           1\n",
      "1   2           1\n",
      "2   3           0\n",
      "3   4           0\n",
      "4   5           0\n",
      "5   6           0\n",
      "6   7           1\n",
      "7   8           1\n",
      "8   9           1\n",
      "9  10           0\n"
     ]
    }
   ],
   "source": [
    "# Trying different C \n",
    "\n",
    "# Best Logistic Regression Model\n",
    "\n",
    "# Normalize data\n",
    "x_train_norm = preprocessing.normalize(x_train, norm='l2')\n",
    "x_test_norm = preprocessing.normalize(x_test, norm='l2')\n",
    "\n",
    "model = LogisticRegression(penalty='l1', C=3.1)\n",
    "model.fit(x_train_norm, y_train)\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "submission = pd.DataFrame({'Id': range(1, len(x_test)+1), 'Prediction': [int(x) for x in y_pred]})\n",
    "print(submission.head(10))\n",
    "\n",
    "submission.to_csv('submission_Logistic_Regression2.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.503125\n"
     ]
    }
   ],
   "source": [
    "# SVC\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# Normalize data\n",
    "\n",
    "x_train_s, x_val, y_train_s, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=42)\n",
    "x_train_s_norm = preprocessing.normalize(x_train_s, norm='l2')\n",
    "x_val_norm = preprocessing.normalize(x_val, norm='l2')\n",
    "\n",
    "clf = svm.SVC()\n",
    "clf.fit(x_train_s_norm, y_train_s)\n",
    "\n",
    "print(clf.score(x_val_norm, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.84875\n"
     ]
    }
   ],
   "source": [
    "# Linear SVM, l1 reg\n",
    "\n",
    "x_train_s, x_val, y_train_s, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=42)\n",
    "x_train_s_norm = preprocessing.normalize(x_train_s, norm='l2')\n",
    "x_val_norm = preprocessing.normalize(x_val, norm='l2')\n",
    "\n",
    "clf = svm.LinearSVC(penalty='l1', loss='squared_hinge', dual=False)\n",
    "clf.fit(x_train_s_norm, y_train_s)\n",
    "\n",
    "print(clf.score(x_val_norm, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8485\n"
     ]
    }
   ],
   "source": [
    "x_train_s, x_val, y_train_s, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=42)\n",
    "x_train_s_norm = preprocessing.normalize(x_train_s, norm='l2')\n",
    "x_val_norm = preprocessing.normalize(x_val, norm='l2')\n",
    "\n",
    "clf = svm.LinearSVC(C=0.77, penalty='l1', loss='squared_hinge', dual=False)\n",
    "clf.fit(x_train_s_norm, y_train_s)\n",
    "\n",
    "print(clf.score(x_val_norm, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Trying different C \n",
    "\n",
    "# Best SVC\n",
    "\n",
    "# Normalize data\n",
    "x_train_norm = preprocessing.normalize(x_train, norm='l2')\n",
    "x_test_norm = preprocessing.normalize(x_test, norm='l2')\n",
    "\n",
    "clf = svm.LinearSVC(C=0.77, penalty='l1', loss='squared_hinge', dual=False)\n",
    "clf.fit(x_train_s_norm, y_train_s)\n",
    "\n",
    "y_pred = clf.predict(x_test)\n",
    "\n",
    "submission = pd.DataFrame({'Id': range(1, len(x_test)+1), 'Prediction': [int(x) for x in y_pred]})\n",
    "print(submission.head(10))\n",
    "\n",
    "submission.to_csv('submission_LinearSVC.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Optimizing\n",
    "\n",
    "cs = []\n",
    "ci = 0.00001\n",
    "for i in range(18):\n",
    "    ci = 5*ci\n",
    "    cs.append(ci)\n",
    "\n",
    "x_train_s, x_val, y_train_s, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=42)\n",
    "x_train_s_norm = preprocessing.normalize(x_train_s, norm='l2')\n",
    "x_val_norm = preprocessing.normalize(x_val, norm='l2')\n",
    "\n",
    "opt_c = []\n",
    "for ci in cs:\n",
    "    clf = svm.LinearSVC(C=ci, penalty='l1', loss='squared_hinge', dual=False)\n",
    "    clf.fit(x_train_s_norm, y_train_s)\n",
    "    opt_c.append(clf.score(x_val_norm, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.49687500000000001,\n",
       " 0.49687500000000001,\n",
       " 0.49687500000000001,\n",
       " 0.67500000000000004,\n",
       " 0.79843750000000002,\n",
       " 0.84593750000000001,\n",
       " 0.84968750000000004,\n",
       " 0.84406250000000005,\n",
       " 0.84406250000000005,\n",
       " 0.84375,\n",
       " 0.84375,\n",
       " 0.84375,\n",
       " 0.84375,\n",
       " 0.84375,\n",
       " 0.84375,\n",
       " 0.84375,\n",
       " 0.84375,\n",
       " 0.84375]"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 0.84406250000000005, 3.90625)"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(opt_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.497\n"
     ]
    }
   ],
   "source": [
    "# SVC, rbf kernel\n",
    "\n",
    "x_train_s, x_val, y_train_s, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=42)\n",
    "x_train_s_norm = preprocessing.normalize(x_train_s, norm='l2')\n",
    "x_val_norm = preprocessing.normalize(x_val, norm='l2')\n",
    "\n",
    "clf = svm.SVC(C=1, kernel='rbf')\n",
    "clf.fit(x_train_s_norm, y_train_s)\n",
    "\n",
    "print(clf.score(x_val_norm, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Optimizing\n",
    "\n",
    "cs = []\n",
    "ci = 0.00001\n",
    "for i in range(18):\n",
    "    ci = 5*ci\n",
    "    cs.append(ci)\n",
    "\n",
    "x_train_s, x_val, y_train_s, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=42)\n",
    "x_train_s_norm = preprocessing.normalize(x_train_s, norm='l2')\n",
    "x_val_norm = preprocessing.normalize(x_val, norm='l2')\n",
    "\n",
    "opt_c = []\n",
    "for ci in cs:\n",
    "    clf = svm.SVC(C=ci, kernel='rbf')\n",
    "    clf.fit(x_train_s_norm, y_train_s)\n",
    "    opt_c.append(clf.score(x_val_norm, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.85125\n"
     ]
    }
   ],
   "source": [
    "# SVC, linear kernel\n",
    "\n",
    "x_train_s, x_val, y_train_s, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=42)\n",
    "x_train_s_norm = preprocessing.normalize(x_train_s, norm='l2')\n",
    "x_val_norm = preprocessing.normalize(x_val, norm='l2')\n",
    "\n",
    "clf = svm.SVC(C=1, kernel='linear')\n",
    "clf.fit(x_train_s_norm, y_train_s)\n",
    "\n",
    "print(clf.score(x_val_norm, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Optimizing\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "\n",
    "cs = []\n",
    "ci = 0.01\n",
    "for i in range(4):\n",
    "    ci = 5*ci\n",
    "    cs.append(ci)\n",
    "\n",
    "x_train_s, x_val, y_train_s, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=42)\n",
    "x_train_s_norm = preprocessing.normalize(x_train_s, norm='l2')\n",
    "x_val_norm = preprocessing.normalize(x_val, norm='l2')\n",
    "\n",
    "opt_c = []\n",
    "for ci in cs:\n",
    "    clf = svm.SVC(C=ci, kernel='linear')\n",
    "    clf.fit(x_train_s_norm, y_train_s)\n",
    "    opt_c.append(clf.score(x_val_norm, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2,\n",
       " 0.84799999999999998,\n",
       " 1.25,\n",
       " [0.82874999999999999,\n",
       "  0.84724999999999995,\n",
       "  0.84799999999999998,\n",
       "  0.84350000000000003])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(opt_c), opt_c[2], cs[2], opt_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Id  Prediction\n",
      "0   1           1\n",
      "1   2           1\n",
      "2   3           0\n",
      "3   4           0\n",
      "4   5           0\n",
      "5   6           0\n",
      "6   7           1\n",
      "7   8           1\n",
      "8   9           1\n",
      "9  10           0\n"
     ]
    }
   ],
   "source": [
    "# Optimal  SVC, linear kernel, C=1\n",
    "\n",
    "# Normalize data\n",
    "x_train_norm = preprocessing.normalize(x_train, norm='l2')\n",
    "x_test_norm = preprocessing.normalize(x_test, norm='l2')\n",
    "\n",
    "clf = svm.SVC(C=1, kernel='linear')\n",
    "clf.fit(x_train_norm, y_train)\n",
    "\n",
    "y_pred = clf.predict(x_test_norm)\n",
    "\n",
    "submission = pd.DataFrame({'Id': range(1, len(x_test)+1), 'Prediction': [int(x) for x in y_pred]})\n",
    "print(submission.head(10))\n",
    "\n",
    "submission.to_csv('submission_LinearSVC.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Optimizing\n",
    "\n",
    "cs = []\n",
    "ci = 0.00001\n",
    "for i in range(18):\n",
    "    ci = 5*ci\n",
    "    cs.append(ci)\n",
    "\n",
    "x_train_s, x_val, y_train_s, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=42)\n",
    "x_train_s_norm = preprocessing.normalize(x_train_s, norm='l2')\n",
    "x_val_norm = preprocessing.normalize(x_val, norm='l2')\n",
    "\n",
    "opt_c = []\n",
    "for ci in cs:\n",
    "    clf = svm.SVC(C=ci, kernel='linear')\n",
    "    clf.fit(x_train_s_norm, y_train_s)\n",
    "    opt_c.append(clf.score(x_val_norm, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8334375\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Normalize data\n",
    "\n",
    "x_train_s, x_val, y_train_s, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=42)\n",
    "x_train_s_norm = preprocessing.normalize(x_train_s, norm='l2')\n",
    "x_val_norm = preprocessing.normalize(x_val, norm='l2')\n",
    "\n",
    "# Base (1000 Classifiers)\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=1000)\n",
    "clf.fit(x_train_s_norm, y_train_s)\n",
    "\n",
    "print(clf.score(x_val_norm, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Id  Prediction\n",
      "0   1           1\n",
      "1   2           1\n",
      "2   3           0\n",
      "3   4           0\n",
      "4   5           1\n",
      "5   6           0\n",
      "6   7           1\n",
      "7   8           1\n",
      "8   9           1\n",
      "9  10           0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Normalize data\n",
    "\n",
    "x_train_norm = preprocessing.normalize(x_train, norm='l2')\n",
    "x_test_norm = preprocessing.normalize(x_test, norm='l2')\n",
    "\n",
    "# Best Random Forest\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=1000)\n",
    "clf.fit(x_train_norm, y_train)\n",
    "\n",
    "y_pred = clf.predict(x_test_norm)\n",
    "\n",
    "submission = pd.DataFrame({'Id': range(1, len(x_test)+1), 'Prediction': [int(x) for x in y_pred]})\n",
    "print(submission.head(10))\n",
    "\n",
    "submission.to_csv('submission_random_forest.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def classification_err(y, real_y):\n",
    "    \n",
    "    return (len(y) - np.sum(np.equal(y, real_y)))/(len(y))\n",
    "    \n",
    "    pass\n",
    "\n",
    "def eval_tree_based_model_min_samples(clf, min_samples_leaf, X_train, y_train, X_test, y_test):\n",
    "    \n",
    "    train_err = []\n",
    "    test_err = []\n",
    "    for i in min_samples_leaf:\n",
    "        clf = clf\n",
    "        clf.min_samples_leaf = i\n",
    "        clf.fit(X_train, y_train)\n",
    "        train_err.append(classification_err(clf.predict(X_train), y_train))\n",
    "        test_err.append(classification_err(clf.predict(X_test), y_test))\n",
    "    \n",
    "    return train_err, test_err\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def eval_tree_based_model_max_depth(clf, max_depth, X_train, y_train, X_test, y_test):\n",
    "\n",
    "    train_err = []\n",
    "    test_err = []\n",
    "    for i in max_depth:\n",
    "        clf = clf\n",
    "        clf.max_depth = i\n",
    "        clf.fit(X_train, y_train)\n",
    "        train_err.append(classification_err(clf.predict(X_train), y_train))\n",
    "        test_err.append(classification_err(clf.predict(X_test), y_test))\n",
    "    \n",
    "    return train_err, test_err\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x24185283fd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test error minimized at min_samples_leaf = 7\n"
     ]
    }
   ],
   "source": [
    "# Normalize data\n",
    "\n",
    "x_train_s, x_val, y_train_s, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=42)\n",
    "x_train_s_norm = preprocessing.normalize(x_train_s, norm='l2')\n",
    "x_val_norm = preprocessing.normalize(x_val, norm='l2')\n",
    "\n",
    "\n",
    "n_estimators = 10\n",
    "clf = RandomForestClassifier(n_estimators = n_estimators, criterion = 'gini')\n",
    "\n",
    "min_samples_leaf = np.arange(1, 26)\n",
    "\n",
    "train_err, test_err = eval_tree_based_model_min_samples(clf, min_samples_leaf, x_train_s_norm, \n",
    "                                                        y_train_s, x_val_norm, y_val)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(min_samples_leaf, test_err, label='Testing error')\n",
    "plt.plot(min_samples_leaf, train_err, label='Training error')\n",
    "plt.xlabel('Minimum Node Size')\n",
    "plt.ylabel('Classification error')\n",
    "plt.title('Random Forest with Gini Impurity and Minimum Node Size')\n",
    "plt.legend(loc=0, shadow=True, fontsize='x-large')\n",
    "plt.savefig(\"2D\")\n",
    "plt.show()\n",
    "\n",
    "print('Test error minimized at min_samples_leaf = %i' % min_samples_leaf[np.argmin(test_err)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x241808c42b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test error minimized at max_depth = 16\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators = n_estimators, criterion = 'gini')\n",
    "\n",
    "max_depth = np.arange(2, 21)\n",
    "\n",
    "train_err, test_err = eval_tree_based_model_max_depth(clf, max_depth, x_train_s_norm, \n",
    "                                                        y_train_s, x_val_norm, y_val)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(max_depth, test_err, label='Testing error')\n",
    "plt.plot(max_depth, train_err, label='Training error')\n",
    "plt.xlabel('Maximum Depth')\n",
    "plt.ylabel('Classification error')\n",
    "plt.title('Random Forest with Gini Impurity and Maximum Depth')\n",
    "plt.legend(loc=0, shadow=True, fontsize='x-large')\n",
    "plt.savefig('2E')\n",
    "plt.show()\n",
    "\n",
    "print('Test error minimized at max_depth = %i' % max_depth[np.argmin(test_err)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.825625\n"
     ]
    }
   ],
   "source": [
    "# Try optimal Random Forest\n",
    "\n",
    "# Normalize data\n",
    "\n",
    "x_train_s, x_val, y_train_s, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=42)\n",
    "x_train_s_norm = preprocessing.normalize(x_train_s, norm='l2')\n",
    "x_val_norm = preprocessing.normalize(x_val, norm='l2')\n",
    "\n",
    "# Base (1000 Classifiers)\n",
    "\n",
    "# clf = RandomForestClassifier(n_estimators=n_estimators, min_samples_leaf=7, max_depth=30)\n",
    "clf = RandomForestClassifier(n_estimators=1000, min_samples_leaf=7, max_depth=30)\n",
    "clf.fit(x_train_s_norm, y_train_s)\n",
    "\n",
    "print(clf.score(x_val_norm, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomizedSearchCV took 27.71 seconds for 20 candidates parameter settings.\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.814 (std: 0.005)\n",
      "Parameters: {'max_features': 9, 'min_samples_leaf': 8, 'bootstrap': False, 'min_samples_split': 4, 'criterion': 'gini', 'max_depth': None}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: 0.811 (std: 0.002)\n",
      "Parameters: {'max_features': 5, 'min_samples_leaf': 3, 'bootstrap': True, 'min_samples_split': 5, 'criterion': 'entropy', 'max_depth': None}\n",
      "\n",
      "Model with rank: 3\n",
      "Mean validation score: 0.807 (std: 0.002)\n",
      "Parameters: {'max_features': 4, 'min_samples_leaf': 7, 'bootstrap': True, 'min_samples_split': 4, 'criterion': 'entropy', 'max_depth': None}\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-967d2796f37a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[0mgrid_search\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m \u001b[0mgrid_search\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train_norm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m print(\"GridSearchCV took %.2f seconds for %d candidate parameter settings.\"\n",
      "\u001b[1;32mc:\\users\\ben hoscheit\\desktop\\python3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    637\u001b[0m                                   error_score=self.error_score)\n\u001b[0;32m    638\u001b[0m           for parameters, (train, test) in product(candidate_params,\n\u001b[1;32m--> 639\u001b[1;33m                                                    cv.split(X, y, groups)))\n\u001b[0m\u001b[0;32m    640\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    641\u001b[0m         \u001b[1;31m# if one choose to see train score, \"out\" will contain train score info\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ben hoscheit\\desktop\\python3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    777\u001b[0m             \u001b[1;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    778\u001b[0m             \u001b[1;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 779\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    780\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    781\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ben hoscheit\\desktop\\python3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    623\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    624\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 625\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    626\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ben hoscheit\\desktop\\python3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    586\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    587\u001b[0m         \u001b[0mcb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 588\u001b[1;33m         \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    589\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ben hoscheit\\desktop\\python3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    109\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 111\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    112\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ben hoscheit\\desktop\\python3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    330\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    331\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 332\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    333\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    334\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ben hoscheit\\desktop\\python3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ben hoscheit\\desktop\\python3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ben hoscheit\\desktop\\python3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, error_score)\u001b[0m\n\u001b[0;32m    456\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    457\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 458\u001b[1;33m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    459\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    460\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ben hoscheit\\desktop\\python3\\lib\\site-packages\\sklearn\\ensemble\\forest.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    326\u001b[0m                     \u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrees\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    327\u001b[0m                     verbose=self.verbose, class_weight=self.class_weight)\n\u001b[1;32m--> 328\u001b[1;33m                 for i, t in enumerate(trees))\n\u001b[0m\u001b[0;32m    329\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    330\u001b[0m             \u001b[1;31m# Collect newly grown trees\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ben hoscheit\\desktop\\python3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    777\u001b[0m             \u001b[1;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    778\u001b[0m             \u001b[1;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 779\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    780\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    781\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ben hoscheit\\desktop\\python3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    623\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    624\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 625\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    626\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ben hoscheit\\desktop\\python3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    586\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    587\u001b[0m         \u001b[0mcb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 588\u001b[1;33m         \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    589\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ben hoscheit\\desktop\\python3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    109\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 111\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    112\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ben hoscheit\\desktop\\python3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    330\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    331\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 332\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    333\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    334\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ben hoscheit\\desktop\\python3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ben hoscheit\\desktop\\python3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ben hoscheit\\desktop\\python3\\lib\\site-packages\\sklearn\\ensemble\\forest.py\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[1;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight)\u001b[0m\n\u001b[0;32m    119\u001b[0m             \u001b[0mcurr_sample_weight\u001b[0m \u001b[1;33m*=\u001b[0m \u001b[0mcompute_sample_weight\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'balanced'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 121\u001b[1;33m         \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcurr_sample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    122\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m         \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ben hoscheit\\desktop\\python3\\lib\\site-packages\\sklearn\\tree\\tree.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    788\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    789\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 790\u001b[1;33m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[0;32m    791\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    792\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ben hoscheit\\desktop\\python3\\lib\\site-packages\\sklearn\\tree\\tree.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    360\u001b[0m                                            min_impurity_split)\n\u001b[0;32m    361\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 362\u001b[1;33m         \u001b[0mbuilder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    363\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    364\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Grid Search\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from time import time\n",
    "from scipy.stats import randint as sp_randint\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Normalize data\n",
    "\n",
    "x_train_norm = preprocessing.normalize(x_train, norm='l2')\n",
    "\n",
    "# build a classifier\n",
    "clf = RandomForestClassifier(n_estimators=20)\n",
    "\n",
    "\n",
    "# Utility function to report best scores\n",
    "def report(results, n_top=3):\n",
    "    for i in range(1, n_top + 1):\n",
    "        candidates = np.flatnonzero(results['rank_test_score'] == i)\n",
    "        for candidate in candidates:\n",
    "            print(\"Model with rank: {0}\".format(i))\n",
    "            print(\"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n",
    "                  results['mean_test_score'][candidate],\n",
    "                  results['std_test_score'][candidate]))\n",
    "            print(\"Parameters: {0}\".format(results['params'][candidate]))\n",
    "            print(\"\")\n",
    "\n",
    "\n",
    "# specify parameters and distributions to sample from\n",
    "param_dist = {\"max_depth\": [3, None],\n",
    "              \"max_features\": sp_randint(1, 11),\n",
    "              \"min_samples_split\": sp_randint(2, 11),\n",
    "              \"min_samples_leaf\": sp_randint(1, 11),\n",
    "              \"bootstrap\": [True, False],\n",
    "              \"criterion\": [\"gini\", \"entropy\"]}\n",
    "\n",
    "# run randomized search\n",
    "n_iter_search = 20\n",
    "random_search = RandomizedSearchCV(clf, param_distributions=param_dist,\n",
    "                                   n_iter=n_iter_search)\n",
    "\n",
    "start = time()\n",
    "random_search.fit(x_train_norm, y_train)\n",
    "print(\"RandomizedSearchCV took %.2f seconds for %d candidates\"\n",
    "      \" parameter settings.\" % ((time() - start), n_iter_search))\n",
    "report(random_search.cv_results_)\n",
    "\n",
    "# use a full grid over all parameters\n",
    "param_grid = {\"max_depth\": [3, None],\n",
    "              \"max_features\": [1, 3, 10],\n",
    "              \"min_samples_split\": [2, 3, 10],\n",
    "              \"min_samples_leaf\": [1, 3, 10],\n",
    "              \"bootstrap\": [True, False],\n",
    "              \"criterion\": [\"gini\", \"entropy\"]}\n",
    "\n",
    "# run grid search\n",
    "grid_search = GridSearchCV(clf, param_grid=param_grid)\n",
    "start = time()\n",
    "grid_search.fit(x_train_norm, y_train)\n",
    "\n",
    "print(\"GridSearchCV took %.2f seconds for %d candidate parameter settings.\"\n",
    "      % (time() - start, len(grid_search.cv_results_['params'])))\n",
    "report(grid_search.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Naive Bayes\n",
    "# Find most informative features\n",
    "\n",
    "import nltk \n",
    "\n",
    "# normalize data\n",
    "\n",
    "x_train_s, x_val, y_train_s, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=42)\n",
    "x_train_s_norm = preprocessing.normalize(x_train_s, norm='l2')\n",
    "x_val_norm = preprocessing.normalize(x_val, norm='l2')\n",
    "\n",
    "# Base (1000 Classifiers)\n",
    "\n",
    "# clf = RandomForestClassifier(n_estimators=n_estimators, min_samples_leaf=7, max_depth=30)\n",
    "clf = RandomForestClassifier(n_estimators=1000, min_samples_leaf=7, max_depth=30)\n",
    "clf.fit(x_train_s_norm, y_train_s)\n",
    "\n",
    "print(clf.score(x_val_norm, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.78343750000000001"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gaussian NB\n",
    "\n",
    "# normalize data\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train_s, x_val, y_train_s, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=42)\n",
    "x_train_s_norm = preprocessing.normalize(x_train_s, norm='l2')\n",
    "x_val_norm = preprocessing.normalize(x_val, norm='l2')\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(x_train_s_norm, y_train_s)\n",
    "\n",
    "gnb.score(x_val_norm, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.84075"
      ]
     },
     "execution_count": 583,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Multinomial NB\n",
    "\n",
    "# normalize data\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train_s, x_val, y_train_s, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=42)\n",
    "x_train_s_norm = preprocessing.normalize(x_train_s, norm='l2')\n",
    "x_val_norm = preprocessing.normalize(x_val, norm='l2')\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "mnb = MultinomialNB(alpha=0.000001)\n",
    "mnb.fit(x_train_s_norm, y_train_s)\n",
    "\n",
    "mnb.score(x_val_norm, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Optimizing\n",
    "\n",
    "cs = []\n",
    "ci = 0.0000001\n",
    "for i in range(5):\n",
    "    ci = 5*ci\n",
    "    cs.append(ci)\n",
    "\n",
    "x_train_s, x_val, y_train_s, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=42)\n",
    "x_train_s_norm = preprocessing.normalize(x_train_s, norm='l2')\n",
    "x_val_norm = preprocessing.normalize(x_val, norm='l2')\n",
    "\n",
    "opt_c = []\n",
    "for ci in cs:\n",
    "    mnb = MultinomialNB(alpha=ci)\n",
    "    mnb.fit(x_train_s_norm, y_train_s)\n",
    "    opt_c.append(mnb.score(x_val_norm, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0,\n",
       " 0.84075,\n",
       " 5e-07,\n",
       " [0.84075, 0.84075, 0.84075, 0.84075, 0.84075],\n",
       " [5e-07, 2.4999999999999998e-06, 1.2499999999999999e-05, 6.25e-05, 0.0003125])"
      ]
     },
     "execution_count": 579,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(opt_c), opt_c[0], cs[0], opt_c, cs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Id  Prediction\n",
      "0   1           1\n",
      "1   2           1\n",
      "2   3           1\n",
      "3   4           0\n",
      "4   5           1\n",
      "5   6           0\n",
      "6   7           1\n",
      "7   8           1\n",
      "8   9           1\n",
      "9  10           0\n"
     ]
    }
   ],
   "source": [
    "# Best MultinomialNB\n",
    "\n",
    "# Normalize data\n",
    "x_train_norm = preprocessing.normalize(x_train, norm='l2')\n",
    "x_test_norm = preprocessing.normalize(x_test, norm='l2')\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "mnb = MultinomialNB(alpha=0.000001)\n",
    "mnb.fit(x_train_norm, y_train)\n",
    "\n",
    "y_pred = mnb.predict(x_test_norm)\n",
    "\n",
    "submission = pd.DataFrame({'Id': range(1, len(x_test)+1), 'Prediction': [int(x) for x in y_pred]})\n",
    "print(submission.head(10))\n",
    "\n",
    "submission.to_csv('submission_Multinomial_NB.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.82343750000000004"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bernoulli NB\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train_s, x_val, y_train_s, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=42)\n",
    "x_train_s_norm = preprocessing.normalize(x_train_s, norm='l2')\n",
    "x_val_norm = preprocessing.normalize(x_val, norm='l2')\n",
    "\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "bnb = BernoulliNB(alpha=0.00001)\n",
    "bnb.fit(x_train_s_norm, y_train_s)\n",
    "\n",
    "bnb.score(x_val_norm, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Optimizing\n",
    "\n",
    "cs = []\n",
    "ci = 0.0000001\n",
    "for i in range(5):\n",
    "    ci = 5*ci\n",
    "    cs.append(ci)\n",
    "\n",
    "x_train_s, x_val, y_train_s, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=42)\n",
    "x_train_s_norm = preprocessing.normalize(x_train_s, norm='l2')\n",
    "x_val_norm = preprocessing.normalize(x_val, norm='l2')\n",
    "\n",
    "opt_c = []\n",
    "for ci in cs:\n",
    "    bnb = BernoulliNB(alpha=ci)\n",
    "    bnb.fit(x_train_s_norm, y_train_s)\n",
    "    opt_c.append(bnb.score(x_val_norm, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0,\n",
       " 0.82343750000000004,\n",
       " 5e-07,\n",
       " [0.82343750000000004,\n",
       "  0.82343750000000004,\n",
       "  0.82343750000000004,\n",
       "  0.82343750000000004,\n",
       "  0.82343750000000004])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(opt_c), opt_c[0], cs[0], opt_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bag_of_words = []\n",
    "with open('data_train.txt','r') as f:\n",
    "    for line in f:\n",
    "        for word in line.split():\n",
    "             bag_of_words.append(word)\n",
    "                \n",
    "bag_of_words = bag_of_words[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Label', 'thi', 'book', 'wa', 'one', 'read', 'movi', 'like', 'great', 'good']"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_of_words[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]), 1.0)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0][:10], y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sent = []\n",
    "for i in range(len(x_train)):\n",
    "    for w in range(len(bag_of_words)):\n",
    "        if x_train[i][w] == 0:\n",
    "            sent.append(({bag_of_words[w]: False}, y_train[i]))\n",
    "        elif x_train[i][w] == 1:\n",
    "            sent.append(({bag_of_words[w]: True}, y_train[i]))\n",
    "\n",
    "# [({'this': True, 'love': True, 'view': False}, 'pos'), . . .]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[({'Label': False}, 1.0),\n",
       " ({'thi': False}, 1.0),\n",
       " ({'book': False}, 1.0),\n",
       " ({'wa': False}, 1.0),\n",
       " ({'one': False}, 1.0),\n",
       " ({'read': False}, 1.0),\n",
       " ({'movi': False}, 1.0),\n",
       " ({'like': False}, 1.0),\n",
       " ({'great': False}, 1.0),\n",
       " ({'good': False}, 1.0)]"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier = nltk.NaiveBayesClassifier.train(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "                    loud = True              0.0 : 1.0    =     45.8 : 1.0\n",
      "                    room = True              0.0 : 1.0    =     26.2 : 1.0\n",
      "                    show = True              0.0 : 1.0    =     23.0 : 1.0\n",
      "                    tool = True              0.0 : 1.0    =     13.9 : 1.0\n",
      "                 impress = True              0.0 : 1.0    =     13.6 : 1.0\n",
      "                    tell = True              0.0 : 1.0    =     13.0 : 1.0\n",
      "                    area = True              1.0 : 0.0    =     12.1 : 1.0\n",
      "                    emot = True              0.0 : 1.0    =     11.4 : 1.0\n",
      "                  singer = True              0.0 : 1.0    =     11.2 : 1.0\n",
      "                    fine = True              0.0 : 1.0    =      9.6 : 1.0\n"
     ]
    }
   ],
   "source": [
    "#  Most informative words\n",
    "\n",
    "classifier.show_most_informative_features(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sent_val = []\n",
    "for i in range(len(x_val)):\n",
    "    for w in range(len(bag_of_words)):\n",
    "        if x_train[i][w] == 0:\n",
    "            sent.append(({bag_of_words[w]: False}, y_train[i]))\n",
    "        elif x_train[i][w] == 1:\n",
    "            sent.append(({bag_of_words[w]: True}, y_train[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.50697712663941019"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.classify.accuracy(classifier, sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.81674999999999998"
      ]
     },
     "execution_count": 575,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GBM\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train_s, x_val, y_train_s, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=42)\n",
    "x_train_s_norm = preprocessing.normalize(x_train_s, norm='l2')\n",
    "x_val_norm = preprocessing.normalize(x_val, norm='l2')\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "clf = GradientBoostingClassifier(n_estimators=500, learning_rate=1, max_depth=3, random_state=0)\n",
    "\n",
    "clf.fit(x_train_s_norm, y_train_s)\n",
    "\n",
    "clf.score(x_val_norm, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 598,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Id  Prediction\n",
      "0   1           1\n",
      "1   2           1\n",
      "2   3           0\n",
      "3   4           0\n",
      "4   5           0\n",
      "5   6           0\n",
      "6   7           1\n",
      "7   8           1\n",
      "8   9           1\n",
      "9  10           0\n"
     ]
    }
   ],
   "source": [
    "# Best GBM\n",
    "\n",
    "# Normalize data\n",
    "x_train_norm = preprocessing.normalize(x_train, norm='l2')\n",
    "x_test_norm = preprocessing.normalize(x_test, norm='l2')\n",
    "\n",
    "clf = GradientBoostingClassifier(n_estimators=500, learning_rate=1, max_depth=3, random_state=0)\n",
    "clf.fit(x_train_norm, y_train)\n",
    "\n",
    "y_pred = clf.predict(x_test_norm)\n",
    "\n",
    "submission = pd.DataFrame({'Id': range(1, len(x_test)+1), 'Prediction': [int(x) for x in y_pred]})\n",
    "print(submission.head(10))\n",
    "\n",
    "submission.to_csv('submission_GBM.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.80312499999999998"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# AdaBoost\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train_s, x_val, y_train_s, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=42)\n",
    "x_train_s_norm = preprocessing.normalize(x_train_s, norm='l2')\n",
    "x_val_norm = preprocessing.normalize(x_val, norm='l2')\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "clf = AdaBoostClassifier(n_estimators=100, learning_rate=1)\n",
    "                   \n",
    "clf.fit(x_train_s_norm, y_train_s)\n",
    "\n",
    "clf.score(x_val_norm, y_val)                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Prediction0</th>\n",
       "      <th>Prediction1</th>\n",
       "      <th>Prediction2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Id  Prediction0  Prediction1  Prediction2\n",
       "0    1            1            1            1\n",
       "1    2            1            1            1\n",
       "2    3            0            0            0\n",
       "3    4            0            0            0\n",
       "4    5            0            0            1\n",
       "5    6            0            0            0\n",
       "6    7            1            1            1\n",
       "7    8            1            1            1\n",
       "8    9            1            1            1\n",
       "9   10            0            0            0\n",
       "10  11            1            1            1\n",
       "11  12            1            0            1\n",
       "12  13            1            1            0\n",
       "13  14            0            0            0\n",
       "14  15            0            0            0\n",
       "15  16            1            1            1\n",
       "16  17            0            0            0\n",
       "17  18            0            0            0\n",
       "18  19            1            1            1\n",
       "19  20            0            0            0\n",
       "20  21            0            0            0\n",
       "21  22            1            1            1\n",
       "22  23            1            1            1\n",
       "23  24            1            1            0\n",
       "24  25            0            0            0\n",
       "25  26            1            1            1\n",
       "26  27            0            0            0\n",
       "27  28            0            0            0\n",
       "28  29            0            0            0\n",
       "29  30            1            1            1"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stack Logistic Regression, Random Forest, LinearSVM\n",
    "\n",
    "# Majority Stacking\n",
    "\n",
    "import os\n",
    "\n",
    "sub_path = \"submissions/\"\n",
    "all_files = os.listdir(sub_path)\n",
    "\n",
    "# Read and concatenate submissions\n",
    "outs = [pd.read_csv(os.path.join(sub_path, f), index_col=0) for f in all_files]\n",
    "concat_sub = pd.concat(outs, axis=1)\n",
    "cols = list(map(lambda x: \"Prediction\" + str(x), range(len(concat_sub.columns))))\n",
    "concat_sub.columns = cols\n",
    "concat_sub.reset_index(inplace=True)\n",
    "concat_sub.head(n=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "483\n"
     ]
    }
   ],
   "source": [
    "pred_svm = concat_sub.Prediction0\n",
    "pred_log = concat_sub.Prediction1\n",
    "pred_rfo = concat_sub.Prediction2\n",
    "disagree_svm_log = np.logical_not(np.equal(pred_svm, pred_log))\n",
    "print(len(disagree_svm_log))\n",
    "print(np.sum(disagree_svm_log))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0])"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictDF = np.array(concat_sub.iloc[:, 1:4])\n",
    "predictDF[0:5, ] #.head()\n",
    "majority = np.mean(predictDF, axis=1)\n",
    "majority[0:5]\n",
    "stacked = (majority > 0.5) + 0\n",
    "stacked[0:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Id  Prediction\n",
      "0   1           1\n",
      "1   2           1\n",
      "2   3           0\n",
      "3   4           0\n",
      "4   5           0\n",
      "5   6           0\n",
      "6   7           1\n",
      "7   8           1\n",
      "8   9           1\n",
      "9  10           0\n"
     ]
    }
   ],
   "source": [
    "# Majority stack\n",
    "\n",
    "submission = pd.DataFrame({'Id': range(1, len(x_test)+1), 'Prediction': [int(x) for x in stacked]})\n",
    "print(submission.head(10))\n",
    "\n",
    "submission.to_csv('submission_majority_stack_svm_logreg_rfo.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Prediction0</th>\n",
       "      <th>Prediction1</th>\n",
       "      <th>Prediction2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.006020</td>\n",
       "      <td>0.005802</td>\n",
       "      <td>0.017638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Prediction0</th>\n",
       "      <td>0.006020</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.905069</td>\n",
       "      <td>0.768188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Prediction1</th>\n",
       "      <td>0.005802</td>\n",
       "      <td>0.905069</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.786237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Prediction2</th>\n",
       "      <td>0.017638</td>\n",
       "      <td>0.768188</td>\n",
       "      <td>0.786237</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Id  Prediction0  Prediction1  Prediction2\n",
       "Id           1.000000     0.006020     0.005802     0.017638\n",
       "Prediction0  0.006020     1.000000     0.905069     0.768188\n",
       "Prediction1  0.005802     0.905069     1.000000     0.786237\n",
       "Prediction2  0.017638     0.768188     0.786237     1.000000"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check correlation\n",
    "\n",
    "concat_sub.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cutoff_lo = 0.8\n",
    "cutoff_hi = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get the data fields ready for stacking\n",
    "concat_sub['Prediction_max'] = concat_sub.iloc[:, 1:3].max(axis=1)\n",
    "concat_sub['Prediction_min'] = concat_sub.iloc[:, 1:3].min(axis=1)\n",
    "concat_sub['Prediction_mean'] = concat_sub.iloc[:, 1:3].mean(axis=1)\n",
    "concat_sub['Prediction_median'] = concat_sub.iloc[:, 1:3].median(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "concat_sub['Prediction'] = np.where(np.all(concat_sub.iloc[:,1:3] > cutoff_lo, axis=1), \n",
    "                                    concat_sub['Prediction_max'], \n",
    "                                    np.where(np.all(concat_sub.iloc[:,1:3] < cutoff_hi, axis=1),\n",
    "                                             concat_sub['Prediction_min'], \n",
    "                                             concat_sub['Prediction_median']))\n",
    "concat_sub[['Id', 'Prediction']].to_csv('stack_minmax_median_round.csv', \n",
    "                                        index=False, float_format='%.6f')\n",
    "# # Round 0.5 down to 0\n",
    "# concat_sub[['Id', 'Prediction']].round().to_csv('stack_minmax_median_round.csv', \n",
    "#                                         index=False, float_format='%.6f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9970</th>\n",
       "      <td>9971</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9971</th>\n",
       "      <td>9972</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9972</th>\n",
       "      <td>9973</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9973</th>\n",
       "      <td>9974</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9974</th>\n",
       "      <td>9975</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9975</th>\n",
       "      <td>9976</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9976</th>\n",
       "      <td>9977</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9977</th>\n",
       "      <td>9978</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9978</th>\n",
       "      <td>9979</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9979</th>\n",
       "      <td>9980</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9980</th>\n",
       "      <td>9981</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9981</th>\n",
       "      <td>9982</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9982</th>\n",
       "      <td>9983</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9983</th>\n",
       "      <td>9984</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9984</th>\n",
       "      <td>9985</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9985</th>\n",
       "      <td>9986</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9986</th>\n",
       "      <td>9987</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9987</th>\n",
       "      <td>9988</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9988</th>\n",
       "      <td>9989</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9989</th>\n",
       "      <td>9990</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9990</th>\n",
       "      <td>9991</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9991</th>\n",
       "      <td>9992</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9992</th>\n",
       "      <td>9993</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9993</th>\n",
       "      <td>9994</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9994</th>\n",
       "      <td>9995</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>9996</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>9997</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>9998</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>9999</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>10000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Id  Prediction\n",
       "0         1         1.0\n",
       "1         2         1.0\n",
       "2         3         0.0\n",
       "3         4         0.0\n",
       "4         5         0.0\n",
       "5         6         0.0\n",
       "6         7         1.0\n",
       "7         8         1.0\n",
       "8         9         1.0\n",
       "9        10         0.0\n",
       "10       11         1.0\n",
       "11       12         0.5\n",
       "12       13         1.0\n",
       "13       14         0.0\n",
       "14       15         0.0\n",
       "15       16         1.0\n",
       "16       17         0.0\n",
       "17       18         0.0\n",
       "18       19         1.0\n",
       "19       20         0.0\n",
       "20       21         0.0\n",
       "21       22         1.0\n",
       "22       23         1.0\n",
       "23       24         1.0\n",
       "24       25         0.0\n",
       "25       26         1.0\n",
       "26       27         0.0\n",
       "27       28         0.0\n",
       "28       29         0.0\n",
       "29       30         1.0\n",
       "...     ...         ...\n",
       "9970   9971         0.0\n",
       "9971   9972         0.0\n",
       "9972   9973         1.0\n",
       "9973   9974         0.5\n",
       "9974   9975         0.0\n",
       "9975   9976         1.0\n",
       "9976   9977         1.0\n",
       "9977   9978         1.0\n",
       "9978   9979         0.0\n",
       "9979   9980         1.0\n",
       "9980   9981         0.5\n",
       "9981   9982         1.0\n",
       "9982   9983         1.0\n",
       "9983   9984         0.0\n",
       "9984   9985         0.0\n",
       "9985   9986         0.5\n",
       "9986   9987         1.0\n",
       "9987   9988         1.0\n",
       "9988   9989         0.0\n",
       "9989   9990         1.0\n",
       "9990   9991         0.0\n",
       "9991   9992         1.0\n",
       "9992   9993         0.0\n",
       "9993   9994         0.0\n",
       "9994   9995         0.0\n",
       "9995   9996         1.0\n",
       "9996   9997         1.0\n",
       "9997   9998         0.0\n",
       "9998   9999         1.0\n",
       "9999  10000         0.0\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concat_sub[['Id', 'Prediction']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# How many diagreements\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Neural Networks\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Embedding\n",
    "from keras.layers import LSTM\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from keras.layers import Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train_s, x_val, y_train_s, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=42)\n",
    "x_train_s_norm = preprocessing.normalize(x_train_s, norm='l2')\n",
    "x_val_norm = preprocessing.normalize(x_val, norm='l2')\n",
    "\n",
    "y_train_s_hot = np_utils.to_categorical(y_train_s)\n",
    "y_val_hot = np_utils.to_categorical(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16000, 1000)\n",
      "(16000,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(x_train_s.shape), print(y_train_s.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_87 (Dense)             (None, 120)               120120    \n",
      "_________________________________________________________________\n",
      "activation_85 (Activation)   (None, 120)               0         \n",
      "_________________________________________________________________\n",
      "dropout_32 (Dropout)         (None, 120)               0         \n",
      "_________________________________________________________________\n",
      "dense_88 (Dense)             (None, 60)                7260      \n",
      "_________________________________________________________________\n",
      "activation_86 (Activation)   (None, 60)                0         \n",
      "_________________________________________________________________\n",
      "dropout_33 (Dropout)         (None, 60)                0         \n",
      "_________________________________________________________________\n",
      "dense_89 (Dense)             (None, 20)                1220      \n",
      "_________________________________________________________________\n",
      "activation_87 (Activation)   (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "dense_90 (Dense)             (None, 2)                 42        \n",
      "_________________________________________________________________\n",
      "activation_88 (Activation)   (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 128,642\n",
      "Trainable params: 128,642\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Dense NN\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(120, input_shape=(1000,)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(60))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(20))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dense(2))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/keras/models.py:939: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "16000/16000 [==============================] - 6s 379us/step - loss: 0.4397 - acc: 0.7913\n",
      "4000/4000 [==============================] - 1s 244us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.33595985072851181, 0.85099999999999998]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(x_train_s_norm, y_train_s_hot, batch_size=32, nb_epoch=1, verbose=1)\n",
    "\n",
    "model.evaluate(x_val_norm, y_val_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "16000/16000 [==============================] - 7s 447us/step - loss: 0.4827 - acc: 0.7687\n",
      "4000/4000 [==============================] - 2s 457us/step\n",
      "Epoch 1/2\n",
      "16000/16000 [==============================] - 7s 457us/step - loss: 0.4817 - acc: 0.7654\n",
      "Epoch 2/2\n",
      "16000/16000 [==============================] - 4s 242us/step - loss: 0.3485 - acc: 0.8501\n",
      "4000/4000 [==============================] - 2s 445us/step\n",
      "Epoch 1/3\n",
      "16000/16000 [==============================] - 7s 451us/step - loss: 0.4875 - acc: 0.7551\n",
      "Epoch 2/3\n",
      "16000/16000 [==============================] - 4s 238us/step - loss: 0.3501 - acc: 0.8510\n",
      "Epoch 3/3\n",
      "16000/16000 [==============================] - 4s 243us/step - loss: 0.3167 - acc: 0.8664\n",
      "4000/4000 [==============================] - 2s 457us/step\n",
      "Epoch 1/4\n",
      "16000/16000 [==============================] - 8s 484us/step - loss: 0.4871 - acc: 0.7595\n",
      "Epoch 2/4\n",
      "16000/16000 [==============================] - 4s 241us/step - loss: 0.3464 - acc: 0.8501\n",
      "Epoch 3/4\n",
      "16000/16000 [==============================] - 4s 249us/step - loss: 0.3194 - acc: 0.8633\n",
      "Epoch 4/4\n",
      "16000/16000 [==============================] - 4s 249us/step - loss: 0.2970 - acc: 0.8751\n",
      "4000/4000 [==============================] - 2s 454us/step\n",
      "Epoch 1/5\n",
      "16000/16000 [==============================] - 8s 471us/step - loss: 0.4751 - acc: 0.7695\n",
      "Epoch 2/5\n",
      "16000/16000 [==============================] - 4s 252us/step - loss: 0.3481 - acc: 0.8503\n",
      "Epoch 3/5\n",
      "16000/16000 [==============================] - 4s 246us/step - loss: 0.3202 - acc: 0.8632\n",
      "Epoch 4/5\n",
      "16000/16000 [==============================] - 4s 236us/step - loss: 0.2943 - acc: 0.8778\n",
      "Epoch 5/5\n",
      "16000/16000 [==============================] - 4s 244us/step - loss: 0.2769 - acc: 0.8847\n",
      "4000/4000 [==============================] - 2s 494us/step\n",
      "Epoch 1/6\n",
      "16000/16000 [==============================] - 8s 479us/step - loss: 0.4813 - acc: 0.7678\n",
      "Epoch 2/6\n",
      "16000/16000 [==============================] - 5s 298us/step - loss: 0.3484 - acc: 0.8506\n",
      "Epoch 3/6\n",
      "16000/16000 [==============================] - 5s 287us/step - loss: 0.3186 - acc: 0.8649\n",
      "Epoch 4/6\n",
      "16000/16000 [==============================] - 4s 240us/step - loss: 0.2980 - acc: 0.8742\n",
      "Epoch 5/6\n",
      "16000/16000 [==============================] - 4s 258us/step - loss: 0.2767 - acc: 0.8861\n",
      "Epoch 6/6\n",
      "16000/16000 [==============================] - 4s 259us/step - loss: 0.2614 - acc: 0.8947\n",
      "4000/4000 [==============================] - 2s 478us/step\n",
      "Epoch 1/7\n",
      "16000/16000 [==============================] - 8s 529us/step - loss: 0.4791 - acc: 0.7645\n",
      "Epoch 2/7\n",
      "16000/16000 [==============================] - 4s 257us/step - loss: 0.3491 - acc: 0.8471\n",
      "Epoch 3/7\n",
      "16000/16000 [==============================] - 4s 252us/step - loss: 0.3220 - acc: 0.8602\n",
      "Epoch 4/7\n",
      "16000/16000 [==============================] - 4s 274us/step - loss: 0.2963 - acc: 0.8775\n",
      "Epoch 5/7\n",
      "16000/16000 [==============================] - 4s 264us/step - loss: 0.2792 - acc: 0.8860\n",
      "Epoch 6/7\n",
      "16000/16000 [==============================] - 4s 253us/step - loss: 0.2597 - acc: 0.8945\n",
      "Epoch 7/7\n",
      "16000/16000 [==============================] - 4s 245us/step - loss: 0.2423 - acc: 0.9026\n",
      "4000/4000 [==============================] - 2s 517us/step\n",
      "Epoch 1/8\n",
      "16000/16000 [==============================] - 8s 503us/step - loss: 0.4792 - acc: 0.7627\n",
      "Epoch 2/8\n",
      "16000/16000 [==============================] - 4s 281us/step - loss: 0.3489 - acc: 0.8501\n",
      "Epoch 3/8\n",
      "16000/16000 [==============================] - 4s 281us/step - loss: 0.3183 - acc: 0.8656\n",
      "Epoch 4/8\n",
      "16000/16000 [==============================] - 4s 275us/step - loss: 0.2951 - acc: 0.8744\n",
      "Epoch 5/8\n",
      "16000/16000 [==============================] - 4s 247us/step - loss: 0.2768 - acc: 0.8845\n",
      "Epoch 6/8\n",
      "16000/16000 [==============================] - 4s 243us/step - loss: 0.2566 - acc: 0.8984\n",
      "Epoch 7/8\n",
      "16000/16000 [==============================] - 4s 241us/step - loss: 0.2422 - acc: 0.9029\n",
      "Epoch 8/8\n",
      "16000/16000 [==============================] - 4s 233us/step - loss: 0.2193 - acc: 0.9132\n",
      "4000/4000 [==============================] - 2s 473us/step\n",
      "Epoch 1/9\n",
      "16000/16000 [==============================] - 8s 475us/step - loss: 0.4887 - acc: 0.7579\n",
      "Epoch 2/9\n",
      "16000/16000 [==============================] - 4s 258us/step - loss: 0.3491 - acc: 0.8478\n",
      "Epoch 3/9\n",
      "16000/16000 [==============================] - 4s 252us/step - loss: 0.3189 - acc: 0.8656\n",
      "Epoch 4/9\n",
      "16000/16000 [==============================] - 4s 244us/step - loss: 0.2999 - acc: 0.8729\n",
      "Epoch 5/9\n",
      "16000/16000 [==============================] - 4s 232us/step - loss: 0.2790 - acc: 0.8869\n",
      "Epoch 6/9\n",
      "16000/16000 [==============================] - 4s 237us/step - loss: 0.2628 - acc: 0.8939\n",
      "Epoch 7/9\n",
      "16000/16000 [==============================] - 4s 244us/step - loss: 0.2450 - acc: 0.9016\n",
      "Epoch 8/9\n",
      "16000/16000 [==============================] - 4s 236us/step - loss: 0.2299 - acc: 0.9098\n",
      "Epoch 9/9\n",
      "16000/16000 [==============================] - 4s 246us/step - loss: 0.2138 - acc: 0.9173\n",
      "4000/4000 [==============================] - 2s 498us/step\n",
      "Epoch 1/10\n",
      "16000/16000 [==============================] - 9s 533us/step - loss: 0.4823 - acc: 0.7692\n",
      "Epoch 2/10\n",
      "16000/16000 [==============================] - 4s 279us/step - loss: 0.3489 - acc: 0.8514\n",
      "Epoch 3/10\n",
      "16000/16000 [==============================] - 4s 251us/step - loss: 0.3203 - acc: 0.8647\n",
      "Epoch 4/10\n",
      "16000/16000 [==============================] - 4s 243us/step - loss: 0.2975 - acc: 0.8748\n",
      "Epoch 5/10\n",
      "16000/16000 [==============================] - 4s 247us/step - loss: 0.2791 - acc: 0.8845\n",
      "Epoch 6/10\n",
      "16000/16000 [==============================] - 4s 249us/step - loss: 0.2631 - acc: 0.8937\n",
      "Epoch 7/10\n",
      "16000/16000 [==============================] - 4s 249us/step - loss: 0.2426 - acc: 0.9013\n",
      "Epoch 8/10\n",
      "16000/16000 [==============================] - 4s 246us/step - loss: 0.2270 - acc: 0.9101\n",
      "Epoch 9/10\n",
      "16000/16000 [==============================] - 4s 258us/step - loss: 0.2111 - acc: 0.9197\n",
      "Epoch 10/10\n",
      "16000/16000 [==============================] - 4s 242us/step - loss: 0.1981 - acc: 0.9230\n",
      "4000/4000 [==============================] - 2s 503us/step\n",
      "Epoch 1/11\n",
      "16000/16000 [==============================] - 8s 492us/step - loss: 0.4929 - acc: 0.7576\n",
      "Epoch 2/11\n",
      "16000/16000 [==============================] - 4s 247us/step - loss: 0.3519 - acc: 0.8461\n",
      "Epoch 3/11\n",
      "16000/16000 [==============================] - 4s 236us/step - loss: 0.3205 - acc: 0.8636\n",
      "Epoch 4/11\n",
      "16000/16000 [==============================] - 4s 247us/step - loss: 0.2997 - acc: 0.8751\n",
      "Epoch 5/11\n",
      "16000/16000 [==============================] - 4s 245us/step - loss: 0.2805 - acc: 0.8856 0s - loss: 0.2770 - a\n",
      "Epoch 6/11\n",
      "16000/16000 [==============================] - 4s 239us/step - loss: 0.2584 - acc: 0.8953\n",
      "Epoch 7/11\n",
      "16000/16000 [==============================] - 4s 237us/step - loss: 0.2456 - acc: 0.9013\n",
      "Epoch 8/11\n",
      "16000/16000 [==============================] - 4s 238us/step - loss: 0.2202 - acc: 0.9158\n",
      "Epoch 9/11\n",
      "16000/16000 [==============================] - 4s 237us/step - loss: 0.2057 - acc: 0.9200\n",
      "Epoch 10/11\n",
      "16000/16000 [==============================] - 4s 247us/step - loss: 0.1957 - acc: 0.9229\n",
      "Epoch 11/11\n",
      "16000/16000 [==============================] - 4s 251us/step - loss: 0.1818 - acc: 0.9299\n",
      "4000/4000 [==============================] - 2s 515us/step\n",
      "Epoch 1/12\n",
      "16000/16000 [==============================] - 8s 473us/step - loss: 0.4815 - acc: 0.7684\n",
      "Epoch 2/12\n",
      "16000/16000 [==============================] - 4s 246us/step - loss: 0.3516 - acc: 0.8484\n",
      "Epoch 3/12\n",
      "16000/16000 [==============================] - 4s 235us/step - loss: 0.3131 - acc: 0.8652\n",
      "Epoch 4/12\n",
      "16000/16000 [==============================] - 4s 247us/step - loss: 0.2950 - acc: 0.8763\n",
      "Epoch 5/12\n",
      "16000/16000 [==============================] - 6s 347us/step - loss: 0.2756 - acc: 0.8863\n",
      "Epoch 6/12\n",
      "16000/16000 [==============================] - 5s 285us/step - loss: 0.2576 - acc: 0.8953\n",
      "Epoch 7/12\n",
      "16000/16000 [==============================] - 4s 261us/step - loss: 0.2383 - acc: 0.9037\n",
      "Epoch 8/12\n",
      "16000/16000 [==============================] - 4s 243us/step - loss: 0.2232 - acc: 0.9133\n",
      "Epoch 9/12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16000/16000 [==============================] - 4s 252us/step - loss: 0.2096 - acc: 0.9199\n",
      "Epoch 10/12\n",
      "16000/16000 [==============================] - 4s 247us/step - loss: 0.1935 - acc: 0.9268\n",
      "Epoch 11/12\n",
      "16000/16000 [==============================] - 4s 259us/step - loss: 0.1799 - acc: 0.9337\n",
      "Epoch 12/12\n",
      "16000/16000 [==============================] - 4s 254us/step - loss: 0.1617 - acc: 0.9393\n",
      "4000/4000 [==============================] - 2s 517us/step\n",
      "Epoch 1/13\n",
      "16000/16000 [==============================] - 8s 470us/step - loss: 0.4839 - acc: 0.7618\n",
      "Epoch 2/13\n",
      "16000/16000 [==============================] - 4s 252us/step - loss: 0.3529 - acc: 0.8472\n",
      "Epoch 3/13\n",
      "16000/16000 [==============================] - 4s 247us/step - loss: 0.3167 - acc: 0.8654\n",
      "Epoch 4/13\n",
      "16000/16000 [==============================] - 4s 244us/step - loss: 0.2950 - acc: 0.8784\n",
      "Epoch 5/13\n",
      "16000/16000 [==============================] - 4s 243us/step - loss: 0.2777 - acc: 0.8872\n",
      "Epoch 6/13\n",
      "16000/16000 [==============================] - 4s 241us/step - loss: 0.2606 - acc: 0.8945\n",
      "Epoch 7/13\n",
      "16000/16000 [==============================] - 4s 249us/step - loss: 0.2419 - acc: 0.9021\n",
      "Epoch 8/13\n",
      "16000/16000 [==============================] - 4s 252us/step - loss: 0.2271 - acc: 0.9102\n",
      "Epoch 9/13\n",
      "16000/16000 [==============================] - 4s 249us/step - loss: 0.2138 - acc: 0.9139\n",
      "Epoch 10/13\n",
      "16000/16000 [==============================] - 4s 256us/step - loss: 0.1955 - acc: 0.9246\n",
      "Epoch 11/13\n",
      "16000/16000 [==============================] - 4s 248us/step - loss: 0.1837 - acc: 0.9312\n",
      "Epoch 12/13\n",
      "16000/16000 [==============================] - 4s 254us/step - loss: 0.1657 - acc: 0.9389\n",
      "Epoch 13/13\n",
      "16000/16000 [==============================] - 4s 253us/step - loss: 0.1607 - acc: 0.9384\n",
      "4000/4000 [==============================] - 2s 522us/step\n",
      "Epoch 1/14\n",
      "16000/16000 [==============================] - 8s 490us/step - loss: 0.4892 - acc: 0.7622\n",
      "Epoch 2/14\n",
      "16000/16000 [==============================] - 4s 233us/step - loss: 0.3542 - acc: 0.8465\n",
      "Epoch 3/14\n",
      "16000/16000 [==============================] - 4s 253us/step - loss: 0.3196 - acc: 0.8634\n",
      "Epoch 4/14\n",
      "16000/16000 [==============================] - 4s 245us/step - loss: 0.2996 - acc: 0.8733\n",
      "Epoch 5/14\n",
      "16000/16000 [==============================] - 4s 238us/step - loss: 0.2823 - acc: 0.8846\n",
      "Epoch 6/14\n",
      "16000/16000 [==============================] - 4s 242us/step - loss: 0.2618 - acc: 0.8918\n",
      "Epoch 7/14\n",
      "16000/16000 [==============================] - 4s 256us/step - loss: 0.2392 - acc: 0.9036\n",
      "Epoch 8/14\n",
      "16000/16000 [==============================] - 4s 248us/step - loss: 0.2273 - acc: 0.9120\n",
      "Epoch 9/14\n",
      "16000/16000 [==============================] - 4s 254us/step - loss: 0.2118 - acc: 0.9183\n",
      "Epoch 10/14\n",
      "16000/16000 [==============================] - 4s 249us/step - loss: 0.1959 - acc: 0.9253\n",
      "Epoch 11/14\n",
      "16000/16000 [==============================] - 4s 253us/step - loss: 0.1880 - acc: 0.9256\n",
      "Epoch 12/14\n",
      "16000/16000 [==============================] - 4s 276us/step - loss: 0.1736 - acc: 0.9337\n",
      "Epoch 13/14\n",
      "16000/16000 [==============================] - 5s 282us/step - loss: 0.1571 - acc: 0.9407\n",
      "Epoch 14/14\n",
      "16000/16000 [==============================] - 4s 256us/step - loss: 0.1498 - acc: 0.9426\n",
      "4000/4000 [==============================] - 3s 641us/step\n",
      "Epoch 1/15\n",
      "16000/16000 [==============================] - 9s 564us/step - loss: 0.4932 - acc: 0.7527\n",
      "Epoch 2/15\n",
      "16000/16000 [==============================] - 4s 251us/step - loss: 0.3484 - acc: 0.8488\n",
      "Epoch 3/15\n",
      "16000/16000 [==============================] - 4s 248us/step - loss: 0.3204 - acc: 0.8605\n",
      "Epoch 4/15\n",
      "16000/16000 [==============================] - 4s 259us/step - loss: 0.2958 - acc: 0.8736\n",
      "Epoch 5/15\n",
      "16000/16000 [==============================] - 4s 247us/step - loss: 0.2816 - acc: 0.8831\n",
      "Epoch 6/15\n",
      "16000/16000 [==============================] - 4s 260us/step - loss: 0.2604 - acc: 0.8942\n",
      "Epoch 7/15\n",
      "16000/16000 [==============================] - 4s 243us/step - loss: 0.2469 - acc: 0.9029\n",
      "Epoch 8/15\n",
      "16000/16000 [==============================] - 4s 247us/step - loss: 0.2285 - acc: 0.9104\n",
      "Epoch 9/15\n",
      "16000/16000 [==============================] - 4s 258us/step - loss: 0.2126 - acc: 0.9178\n",
      "Epoch 10/15\n",
      "16000/16000 [==============================] - 4s 253us/step - loss: 0.2009 - acc: 0.9244\n",
      "Epoch 11/15\n",
      "16000/16000 [==============================] - 4s 252us/step - loss: 0.1830 - acc: 0.9304\n",
      "Epoch 12/15\n",
      "16000/16000 [==============================] - 4s 246us/step - loss: 0.1685 - acc: 0.9356\n",
      "Epoch 13/15\n",
      "16000/16000 [==============================] - 4s 255us/step - loss: 0.1573 - acc: 0.9420\n",
      "Epoch 14/15\n",
      "16000/16000 [==============================] - 4s 248us/step - loss: 0.1503 - acc: 0.9438\n",
      "Epoch 15/15\n",
      "16000/16000 [==============================] - 4s 258us/step - loss: 0.1431 - acc: 0.9428\n",
      "4000/4000 [==============================] - 2s 509us/step\n",
      "Epoch 1/16\n",
      "16000/16000 [==============================] - 8s 506us/step - loss: 0.4879 - acc: 0.7601\n",
      "Epoch 2/16\n",
      "16000/16000 [==============================] - 4s 239us/step - loss: 0.3502 - acc: 0.8470\n",
      "Epoch 3/16\n",
      "16000/16000 [==============================] - 4s 252us/step - loss: 0.3149 - acc: 0.8666\n",
      "Epoch 4/16\n",
      "16000/16000 [==============================] - 4s 266us/step - loss: 0.2966 - acc: 0.8769\n",
      "Epoch 5/16\n",
      "16000/16000 [==============================] - 4s 243us/step - loss: 0.2723 - acc: 0.8883\n",
      "Epoch 6/16\n",
      "16000/16000 [==============================] - 4s 239us/step - loss: 0.2570 - acc: 0.8961\n",
      "Epoch 7/16\n",
      "16000/16000 [==============================] - 4s 245us/step - loss: 0.2408 - acc: 0.9054\n",
      "Epoch 8/16\n",
      "16000/16000 [==============================] - 4s 241us/step - loss: 0.2222 - acc: 0.9125\n",
      "Epoch 9/16\n",
      "16000/16000 [==============================] - 4s 239us/step - loss: 0.2080 - acc: 0.9192\n",
      "Epoch 10/16\n",
      "16000/16000 [==============================] - 4s 244us/step - loss: 0.1935 - acc: 0.9264\n",
      "Epoch 11/16\n",
      "16000/16000 [==============================] - 4s 238us/step - loss: 0.1837 - acc: 0.9270\n",
      "Epoch 12/16\n",
      "16000/16000 [==============================] - 4s 242us/step - loss: 0.1666 - acc: 0.9347\n",
      "Epoch 13/16\n",
      "16000/16000 [==============================] - 4s 247us/step - loss: 0.1590 - acc: 0.9393\n",
      "Epoch 14/16\n",
      "16000/16000 [==============================] - 4s 250us/step - loss: 0.1483 - acc: 0.9434\n",
      "Epoch 15/16\n",
      "16000/16000 [==============================] - 4s 241us/step - loss: 0.1433 - acc: 0.9461\n",
      "Epoch 16/16\n",
      "16000/16000 [==============================] - 4s 248us/step - loss: 0.1353 - acc: 0.9467\n",
      "4000/4000 [==============================] - 2s 496us/step\n",
      "Epoch 1/17\n",
      "16000/16000 [==============================] - 9s 539us/step - loss: 0.4920 - acc: 0.7548\n",
      "Epoch 2/17\n",
      "16000/16000 [==============================] - 4s 255us/step - loss: 0.3488 - acc: 0.8504\n",
      "Epoch 3/17\n",
      "16000/16000 [==============================] - 4s 266us/step - loss: 0.3208 - acc: 0.8649\n",
      "Epoch 4/17\n",
      "16000/16000 [==============================] - 4s 258us/step - loss: 0.2992 - acc: 0.8757\n",
      "Epoch 5/17\n",
      "16000/16000 [==============================] - 4s 256us/step - loss: 0.2809 - acc: 0.8860\n",
      "Epoch 6/17\n",
      "16000/16000 [==============================] - 4s 261us/step - loss: 0.2587 - acc: 0.8965\n",
      "Epoch 7/17\n",
      "16000/16000 [==============================] - 4s 260us/step - loss: 0.2425 - acc: 0.9042\n",
      "Epoch 8/17\n",
      "16000/16000 [==============================] - 4s 267us/step - loss: 0.2292 - acc: 0.9106\n",
      "Epoch 9/17\n",
      "16000/16000 [==============================] - 4s 269us/step - loss: 0.2138 - acc: 0.9173\n",
      "Epoch 10/17\n",
      "16000/16000 [==============================] - 4s 255us/step - loss: 0.1926 - acc: 0.9282\n",
      "Epoch 11/17\n",
      "16000/16000 [==============================] - 4s 257us/step - loss: 0.1819 - acc: 0.9315\n",
      "Epoch 12/17\n",
      "16000/16000 [==============================] - 4s 257us/step - loss: 0.1700 - acc: 0.9351\n",
      "Epoch 13/17\n",
      "16000/16000 [==============================] - 5s 321us/step - loss: 0.1570 - acc: 0.9398\n",
      "Epoch 14/17\n",
      "16000/16000 [==============================] - 5s 321us/step - loss: 0.1484 - acc: 0.9447\n",
      "Epoch 15/17\n",
      "16000/16000 [==============================] - 5s 303us/step - loss: 0.1425 - acc: 0.9449\n",
      "Epoch 16/17\n",
      "16000/16000 [==============================] - 4s 259us/step - loss: 0.1363 - acc: 0.9499\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/17\n",
      "16000/16000 [==============================] - 5s 283us/step - loss: 0.1281 - acc: 0.9494\n",
      "4000/4000 [==============================] - 2s 524us/step\n",
      "Epoch 1/18\n",
      "16000/16000 [==============================] - 9s 555us/step - loss: 0.4828 - acc: 0.7629\n",
      "Epoch 2/18\n",
      "16000/16000 [==============================] - 4s 254us/step - loss: 0.3521 - acc: 0.8453\n",
      "Epoch 3/18\n",
      "16000/16000 [==============================] - 4s 255us/step - loss: 0.3170 - acc: 0.8645\n",
      "Epoch 4/18\n",
      "16000/16000 [==============================] - 5s 292us/step - loss: 0.2959 - acc: 0.8755\n",
      "Epoch 5/18\n",
      "16000/16000 [==============================] - 4s 253us/step - loss: 0.2757 - acc: 0.8868\n",
      "Epoch 6/18\n",
      "16000/16000 [==============================] - 4s 239us/step - loss: 0.2571 - acc: 0.8936\n",
      "Epoch 7/18\n",
      "16000/16000 [==============================] - 4s 249us/step - loss: 0.2440 - acc: 0.9034\n",
      "Epoch 8/18\n",
      "16000/16000 [==============================] - 4s 270us/step - loss: 0.2245 - acc: 0.9121\n",
      "Epoch 9/18\n",
      "16000/16000 [==============================] - 5s 325us/step - loss: 0.2078 - acc: 0.9182\n",
      "Epoch 10/18\n",
      "16000/16000 [==============================] - 4s 239us/step - loss: 0.1896 - acc: 0.9268\n",
      "Epoch 11/18\n",
      "16000/16000 [==============================] - 4s 233us/step - loss: 0.1761 - acc: 0.9336\n",
      "Epoch 12/18\n",
      "16000/16000 [==============================] - 4s 237us/step - loss: 0.1673 - acc: 0.9381\n",
      "Epoch 13/18\n",
      "16000/16000 [==============================] - 4s 245us/step - loss: 0.1552 - acc: 0.9416\n",
      "Epoch 14/18\n",
      "16000/16000 [==============================] - 4s 251us/step - loss: 0.1530 - acc: 0.9420\n",
      "Epoch 15/18\n",
      "16000/16000 [==============================] - 4s 244us/step - loss: 0.1437 - acc: 0.9462\n",
      "Epoch 16/18\n",
      "16000/16000 [==============================] - 4s 272us/step - loss: 0.1315 - acc: 0.9491\n",
      "Epoch 17/18\n",
      "16000/16000 [==============================] - 4s 261us/step - loss: 0.1268 - acc: 0.9525\n",
      "Epoch 18/18\n",
      "16000/16000 [==============================] - 4s 256us/step - loss: 0.1177 - acc: 0.9548\n",
      "4000/4000 [==============================] - 2s 481us/step\n",
      "Epoch 1/19\n",
      "16000/16000 [==============================] - 7s 455us/step - loss: 0.4787 - acc: 0.7661\n",
      "Epoch 2/19\n",
      "16000/16000 [==============================] - 4s 237us/step - loss: 0.3476 - acc: 0.8487\n",
      "Epoch 3/19\n",
      "16000/16000 [==============================] - 4s 248us/step - loss: 0.3159 - acc: 0.8659\n",
      "Epoch 4/19\n",
      "16000/16000 [==============================] - 4s 252us/step - loss: 0.2963 - acc: 0.8744\n",
      "Epoch 5/19\n",
      "16000/16000 [==============================] - 4s 240us/step - loss: 0.2786 - acc: 0.8866\n",
      "Epoch 6/19\n",
      "16000/16000 [==============================] - 4s 240us/step - loss: 0.2575 - acc: 0.8949\n",
      "Epoch 7/19\n",
      "16000/16000 [==============================] - 4s 239us/step - loss: 0.2434 - acc: 0.9031\n",
      "Epoch 8/19\n",
      "16000/16000 [==============================] - 4s 241us/step - loss: 0.2279 - acc: 0.9118\n",
      "Epoch 9/19\n",
      "16000/16000 [==============================] - 4s 234us/step - loss: 0.2155 - acc: 0.9144\n",
      "Epoch 10/19\n",
      "16000/16000 [==============================] - 4s 236us/step - loss: 0.1911 - acc: 0.9276\n",
      "Epoch 11/19\n",
      "16000/16000 [==============================] - 4s 241us/step - loss: 0.1846 - acc: 0.9293\n",
      "Epoch 12/19\n",
      "16000/16000 [==============================] - 4s 244us/step - loss: 0.1698 - acc: 0.9350\n",
      "Epoch 13/19\n",
      "16000/16000 [==============================] - 4s 250us/step - loss: 0.1600 - acc: 0.9393\n",
      "Epoch 14/19\n",
      "16000/16000 [==============================] - 4s 246us/step - loss: 0.1521 - acc: 0.9416\n",
      "Epoch 15/19\n",
      "16000/16000 [==============================] - 4s 241us/step - loss: 0.1452 - acc: 0.9444\n",
      "Epoch 16/19\n",
      "16000/16000 [==============================] - 4s 232us/step - loss: 0.1333 - acc: 0.9496\n",
      "Epoch 17/19\n",
      "16000/16000 [==============================] - 4s 233us/step - loss: 0.1260 - acc: 0.9509\n",
      "Epoch 18/19\n",
      "16000/16000 [==============================] - 4s 234us/step - loss: 0.1230 - acc: 0.9518\n",
      "Epoch 19/19\n",
      "16000/16000 [==============================] - 4s 242us/step - loss: 0.1189 - acc: 0.9525\n",
      "4000/4000 [==============================] - 2s 481us/step\n",
      "Epoch 1/20\n",
      "16000/16000 [==============================] - 8s 478us/step - loss: 0.4775 - acc: 0.7647\n",
      "Epoch 2/20\n",
      "16000/16000 [==============================] - 4s 261us/step - loss: 0.3485 - acc: 0.8514\n",
      "Epoch 3/20\n",
      "16000/16000 [==============================] - 4s 250us/step - loss: 0.3199 - acc: 0.8646\n",
      "Epoch 4/20\n",
      "16000/16000 [==============================] - 4s 249us/step - loss: 0.2937 - acc: 0.8770\n",
      "Epoch 5/20\n",
      "16000/16000 [==============================] - 4s 256us/step - loss: 0.2788 - acc: 0.8871\n",
      "Epoch 6/20\n",
      "16000/16000 [==============================] - 4s 251us/step - loss: 0.2610 - acc: 0.8957\n",
      "Epoch 7/20\n",
      "16000/16000 [==============================] - 4s 235us/step - loss: 0.2408 - acc: 0.9052\n",
      "Epoch 8/20\n",
      "16000/16000 [==============================] - 4s 247us/step - loss: 0.2321 - acc: 0.9094\n",
      "Epoch 9/20\n",
      "16000/16000 [==============================] - 4s 267us/step - loss: 0.2113 - acc: 0.9177\n",
      "Epoch 10/20\n",
      "16000/16000 [==============================] - 4s 259us/step - loss: 0.2021 - acc: 0.9213\n",
      "Epoch 11/20\n",
      "16000/16000 [==============================] - 4s 243us/step - loss: 0.1818 - acc: 0.9311\n",
      "Epoch 12/20\n",
      "16000/16000 [==============================] - 4s 251us/step - loss: 0.1677 - acc: 0.9362\n",
      "Epoch 13/20\n",
      "16000/16000 [==============================] - 4s 246us/step - loss: 0.1573 - acc: 0.9398\n",
      "Epoch 14/20\n",
      "16000/16000 [==============================] - 4s 240us/step - loss: 0.1462 - acc: 0.9453\n",
      "Epoch 15/20\n",
      "16000/16000 [==============================] - 4s 256us/step - loss: 0.1381 - acc: 0.9483\n",
      "Epoch 16/20\n",
      "16000/16000 [==============================] - 4s 251us/step - loss: 0.1361 - acc: 0.9476\n",
      "Epoch 17/20\n",
      "16000/16000 [==============================] - 4s 262us/step - loss: 0.1279 - acc: 0.9493\n",
      "Epoch 18/20\n",
      "16000/16000 [==============================] - 4s 244us/step - loss: 0.1224 - acc: 0.9526\n",
      "Epoch 19/20\n",
      "16000/16000 [==============================] - 4s 267us/step - loss: 0.1128 - acc: 0.9579\n",
      "Epoch 20/20\n",
      "16000/16000 [==============================] - 4s 255us/step - loss: 0.1084 - acc: 0.9568\n",
      "4000/4000 [==============================] - 2s 488us/step\n"
     ]
    }
   ],
   "source": [
    "# Optimze epochs\n",
    "\n",
    "accuracies4 = []\n",
    "models4 = []\n",
    "\n",
    "for i in np.arange(1, 21):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(120, input_shape=(1000,)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.7))\n",
    "    model.add(Dense(20))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(Dense(2))\n",
    "    model.add(Activation('softmax'))\n",
    "    \n",
    "    model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "    \n",
    "    model.fit(x_train_s_norm, y_train_s_hot, epochs=i, batch_size=32, verbose=1)\n",
    "    \n",
    "    accuracies4.append(model.evaluate(x_val_norm, y_val_hot)[1])\n",
    "    models4.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(accuracies4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(1, 21)[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000/4000 [==============================] - 0s 124us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.33541927671432498, 0.85750000000000004]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models4[4].evaluate(x_val_norm, y_val_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "16000/16000 [==============================] - 4s 260us/step - loss: 0.6915 - acc: 0.5381\n",
      "Epoch 2/5\n",
      "16000/16000 [==============================] - 3s 202us/step - loss: 0.6446 - acc: 0.6243\n",
      "Epoch 3/5\n",
      "16000/16000 [==============================] - 3s 209us/step - loss: 0.5575 - acc: 0.7147\n",
      "Epoch 4/5\n",
      "16000/16000 [==============================] - 3s 204us/step - loss: 0.4915 - acc: 0.7645\n",
      "Epoch 5/5\n",
      "16000/16000 [==============================] - 3s 205us/step - loss: 0.4636 - acc: 0.7822\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x11dd707f0>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    model = Sequential()\n",
    "    model.add(Dense(120, input_shape=(1000,)))\n",
    "    model.add(Activation('sigmoid'))\n",
    "    model.add(Dropout(0.7))\n",
    "    model.add(Dense(20))\n",
    "    model.add(Activation('sigmoid'))\n",
    "\n",
    "    model.add(Dense(2))\n",
    "    model.add(Activation('softmax'))\n",
    "    \n",
    "    model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "    \n",
    "    model.fit(x_train_s_norm, y_train_s_hot, epochs=5, batch_size=32, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000/4000 [==============================] - 0s 103us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.37439831280708313, 0.84325000000000006]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_val_norm, y_val_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "16000/16000 [==============================] - 4s 263us/step - loss: 0.4804 - acc: 0.7681\n",
      "Epoch 2/5\n",
      "16000/16000 [==============================] - 3s 202us/step - loss: 0.3486 - acc: 0.8508\n",
      "Epoch 3/5\n",
      "16000/16000 [==============================] - 3s 199us/step - loss: 0.3160 - acc: 0.8651\n",
      "Epoch 4/5\n",
      "16000/16000 [==============================] - 3s 199us/step - loss: 0.2941 - acc: 0.8744\n",
      "Epoch 5/5\n",
      "16000/16000 [==============================] - 3s 202us/step - loss: 0.2750 - acc: 0.8862\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x123f9e390>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    model = Sequential()\n",
    "    model.add(Dense(120, input_shape=(1000,)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.7))\n",
    "    model.add(Dense(20))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(Dense(2))\n",
    "    model.add(Activation('softmax'))\n",
    "    \n",
    "    model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "    \n",
    "    model.fit(x_train_s_norm, y_train_s_hot, epochs=5, batch_size=32, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000/4000 [==============================] - 0s 74us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.35212227517366407, 0.85175000000000001]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_val_norm, y_val_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "0.85499999999999998]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "0.85324999999999995]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000/4000 [==============================] - 1s 132us/step\n",
      "4000/4000 [==============================] - 1s 149us/step\n",
      "4000/4000 [==============================] - 1s 169us/step\n",
      "4000/4000 [==============================] - 1s 191us/step\n",
      "4000/4000 [==============================] - 1s 168us/step\n"
     ]
    }
   ],
   "source": [
    "# CV NN\n",
    "\n",
    "x_train_norm = preprocessing.normalize(x_train, norm='l2')\n",
    "\n",
    "# One-hot\n",
    "y_train_hot = np_utils.to_categorical(y_train)\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# nhypers = 15\n",
    "# kfold = 5\n",
    "# dropouts = np.linspace(0, .7, nhypers)\n",
    "# val_scores = []\n",
    "# models = []\n",
    "\n",
    "# for i in dropouts:\n",
    "#     model = Sequential()\n",
    "#     model.add(Dense(120, input_shape=(1000,)))\n",
    "#     model.add(Activation('relu'))\n",
    "#     model.add(Dropout(i))\n",
    "#     model.add(Dense(20))\n",
    "#     model.add(Activation('relu'))\n",
    "\n",
    "#     model.add(Dense(2))\n",
    "#     model.add(Activation('softmax'))\n",
    "    \n",
    "#     model.compile(optimizer='adam',\n",
    "#               loss='binary_crossentropy',\n",
    "#               metrics=['accuracy'])\n",
    "    \n",
    "# #     model.fit(x_train_norm, y_train_hot, epochs=1, batch_size=32, verbose=1)\n",
    "    \n",
    "#     scores = cross_val_score(model, x_train_norm, y_train_hot, groups=None, scoring=None,\n",
    "#                              cv=kfold, n_jobs=1, verbose=0, fit_params=None)\n",
    "#     val_scores.append(scores)\n",
    "#     models.append(model)\n",
    "    \n",
    "kfold = KFold(n_splits=5, shuffle=True)\n",
    "cvscores = []\n",
    "for train, test in kfold.split(x_train_norm, y_train_hot):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(120, input_shape=(1000,)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(20))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(Dense(2))\n",
    "    model.add(Activation('softmax'))\n",
    "    \n",
    "    model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "    # Fit the model\n",
    "    model.fit(x_train_norm[train], y_train_hot[train], epochs=1, batch_size=10, verbose=0)\n",
    "    # evaluate the model\n",
    "    scores = model.evaluate(x_train_norm[test], y_train_hot[test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.34180925035476684, 0.84775]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ": 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ": 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "[0.34539571571350097, 0.85024999999999995] : 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "20000/20000 [==============================] - 6s 280us/step - loss: 0.4651 - acc: 0.7740\n",
      "Epoch 2/5\n",
      "20000/20000 [==============================] - 5s 241us/step - loss: 0.3449 - acc: 0.8493\n",
      "Epoch 3/5\n",
      "20000/20000 [==============================] - 5s 241us/step - loss: 0.3168 - acc: 0.8628\n",
      "Epoch 4/5\n",
      "20000/20000 [==============================] - 5s 241us/step - loss: 0.2966 - acc: 0.8754\n",
      "Epoch 5/5\n",
      "20000/20000 [==============================] - 5s 241us/step - loss: 0.2818 - acc: 0.8821\n",
      "Epoch 1/1\n",
      "20000/20000 [==============================] - 5s 248us/step - loss: 0.2639 - acc: 0.8946\n",
      "   Id  Prediction\n",
      "0   1           1\n",
      "1   2           1\n",
      "2   3           0\n",
      "3   4           0\n",
      "4   5           0\n",
      "5   6           0\n",
      "6   7           1\n",
      "7   8           1\n",
      "8   9           1\n",
      "9  10           0\n"
     ]
    }
   ],
   "source": [
    "# Submit Optimal NN\n",
    "\n",
    "# Normalize data\n",
    "x_train_norm = preprocessing.normalize(x_train, norm='l2')\n",
    "x_test_norm = preprocessing.normalize(x_test, norm='l2')\n",
    "\n",
    "# One-hot\n",
    "y_train_hot = np_utils.to_categorical(y_train)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(120, input_shape=(1000,)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.7))\n",
    "model.add(Dense(20))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dense(2))\n",
    "model.add(Activation('softmax'))\n",
    "    \n",
    "model.compile(optimizer='adam', loss='binary_crossentropy',metrics=['accuracy'])\n",
    "model.fit(x_train_norm, y_train_hot, epochs=5, batch_size=32, verbose=1)\n",
    "\n",
    "model.fit(x_train_norm, y_train_hot)\n",
    "\n",
    "y_pred = model.predict_classes(x_test_norm)\n",
    "\n",
    "submission = pd.DataFrame({'Id': range(1, len(x_test)+1), 'Prediction': [int(x) for x in y_pred]})\n",
    "print(submission.head(10))\n",
    "\n",
    "submission.to_csv('submission_optimal_Dense_NN.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.04667654,  0.95332348], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00259928,  0.99740076],\n",
       "       [ 0.39218283,  0.60781723],\n",
       "       [ 0.08801281,  0.91198725],\n",
       "       ..., \n",
       "       [ 0.25613365,  0.74386638],\n",
       "       [ 0.0010884 ,  0.99891162],\n",
       "       [ 0.96818894,  0.03181104]], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(x_train_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 0.,  1.],\n",
       "        [ 0.,  1.],\n",
       "        [ 0.,  1.],\n",
       "        ..., \n",
       "        [ 0.,  1.],\n",
       "        [ 0.,  1.],\n",
       "        [ 1.,  0.]]), array([ 1.,  1.,  1., ...,  1.,  1.,  0.]))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_hot, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "16000/16000 [==============================] - 7s 407us/step - loss: 0.4364 - acc: 0.8022\n",
      "Epoch 2/10\n",
      "16000/16000 [==============================] - 3s 173us/step - loss: 0.3240 - acc: 0.8621\n",
      "Epoch 3/10\n",
      "16000/16000 [==============================] - 3s 174us/step - loss: 0.2948 - acc: 0.8765\n",
      "Epoch 4/10\n",
      "16000/16000 [==============================] - 3s 172us/step - loss: 0.2637 - acc: 0.8918\n",
      "Epoch 5/10\n",
      "16000/16000 [==============================] - 3s 174us/step - loss: 0.2269 - acc: 0.9111\n",
      "Epoch 6/10\n",
      "16000/16000 [==============================] - 3s 169us/step - loss: 0.1852 - acc: 0.9304\n",
      "Epoch 7/10\n",
      "16000/16000 [==============================] - 3s 172us/step - loss: 0.1504 - acc: 0.9454\n",
      "Epoch 8/10\n",
      "16000/16000 [==============================] - 3s 169us/step - loss: 0.1173 - acc: 0.9613\n",
      "Epoch 9/10\n",
      "16000/16000 [==============================] - 3s 172us/step - loss: 0.0952 - acc: 0.9678\n",
      "Epoch 10/10\n",
      "16000/16000 [==============================] - 3s 165us/step - loss: 0.0731 - acc: 0.9764\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x18e98fd68>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    model = Sequential()\n",
    "    model.add(Dense(50, input_shape=(1000,)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.7))\n",
    "    model.add(Dense(20))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(Dense(2))\n",
    "    model.add(Activation('softmax'))\n",
    "    \n",
    "    model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "    \n",
    "    model.fit(x_train_s_norm, y_train_s_hot, epochs=10, batch_size=32, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000/4000 [==============================] - 2s 404us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.56419626776129006, 0.84299999999999997]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_val_norm, y_val_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "16000/16000 [==============================] - 6s 399us/step - loss: 0.4243 - acc: 0.8088\n",
      "4000/4000 [==============================] - 1s 357us/step\n",
      "Epoch 1/1\n",
      "16000/16000 [==============================] - 5s 341us/step - loss: 0.4327 - acc: 0.7979\n",
      "4000/4000 [==============================] - 1s 371us/step\n",
      "Epoch 1/1\n",
      "16000/16000 [==============================] - 5s 343us/step - loss: 0.4464 - acc: 0.7973\n",
      "4000/4000 [==============================] - 1s 350us/step\n",
      "Epoch 1/1\n",
      "16000/16000 [==============================] - 6s 344us/step - loss: 0.4438 - acc: 0.7977\n",
      "4000/4000 [==============================] - 1s 374us/step\n",
      "Epoch 1/1\n",
      "16000/16000 [==============================] - 6s 360us/step - loss: 0.4667 - acc: 0.7758\n",
      "4000/4000 [==============================] - 1s 369us/step\n",
      "Epoch 1/1\n",
      "16000/16000 [==============================] - 6s 356us/step - loss: 0.4657 - acc: 0.7777\n",
      "4000/4000 [==============================] - 1s 366us/step\n",
      "Epoch 1/1\n",
      "16000/16000 [==============================] - 6s 359us/step - loss: 0.4918 - acc: 0.7559\n",
      "4000/4000 [==============================] - 1s 367us/step\n",
      "Epoch 1/1\n",
      "16000/16000 [==============================] - 6s 356us/step - loss: 0.5305 - acc: 0.7261\n",
      "4000/4000 [==============================] - 2s 496us/step\n",
      "Epoch 1/1\n",
      "16000/16000 [==============================] - 7s 455us/step - loss: 0.5569 - acc: 0.7080\n",
      "4000/4000 [==============================] - 2s 441us/step\n",
      "Epoch 1/1\n",
      "16000/16000 [==============================] - 6s 406us/step - loss: 0.6351 - acc: 0.6228\n",
      "4000/4000 [==============================] - 2s 444us/step\n",
      "Epoch 1/1\n",
      "16000/16000 [==============================] - 6s 383us/step - loss: 0.4231 - acc: 0.8154\n",
      "4000/4000 [==============================] - 2s 428us/step\n"
     ]
    }
   ],
   "source": [
    "accuracies3 = []\n",
    "models3 = []\n",
    "\n",
    "for i in np.arange(0.0, 1.1, 0.1):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(50, input_shape=(1000,)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(i))\n",
    "    model.add(Dense(20))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(Dense(2))\n",
    "    model.add(Activation('softmax'))\n",
    "    \n",
    "    model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "    \n",
    "    model.fit(x_train_s_norm, y_train_s_hot, epochs=1, batch_size=32, verbose=1)\n",
    "    \n",
    "    accuracies3.append(model.evaluate(x_val_norm, y_val_hot)[1])\n",
    "    models3.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(accuracies3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20000000000000001"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(0.0, 1.1, 0.1)[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000/4000 [==============================] - 0s 94us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.33924327248334885, 0.85175000000000001]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models3[2].evaluate(x_val_norm, y_val_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "16000/16000 [==============================] - 6s 358us/step - loss: 0.4175 - acc: 0.8121\n",
      "4000/4000 [==============================] - 1s 244us/step\n",
      "Epoch 1/1\n",
      "16000/16000 [==============================] - 5s 336us/step - loss: 0.4216 - acc: 0.8083\n",
      "4000/4000 [==============================] - 1s 246us/step\n",
      "Epoch 1/1\n",
      "16000/16000 [==============================] - 5s 336us/step - loss: 0.4300 - acc: 0.8096\n",
      "4000/4000 [==============================] - 1s 252us/step\n",
      "Epoch 1/1\n",
      "16000/16000 [==============================] - 6s 365us/step - loss: 0.4577 - acc: 0.7852\n",
      "4000/4000 [==============================] - 1s 277us/step\n",
      "Epoch 1/1\n",
      "16000/16000 [==============================] - 6s 358us/step - loss: 0.4625 - acc: 0.7838\n",
      "4000/4000 [==============================] - 1s 258us/step\n",
      "Epoch 1/1\n",
      "16000/16000 [==============================] - 6s 387us/step - loss: 0.4951 - acc: 0.7579\n",
      "4000/4000 [==============================] - 1s 286us/step\n",
      "Epoch 1/1\n",
      "16000/16000 [==============================] - 6s 373us/step - loss: 0.5364 - acc: 0.7273\n",
      "4000/4000 [==============================] - 1s 335us/step\n",
      "Epoch 1/1\n",
      "16000/16000 [==============================] - 6s 395us/step - loss: 0.5864 - acc: 0.6698\n",
      "4000/4000 [==============================] - 1s 283us/step\n",
      "Epoch 1/1\n",
      "16000/16000 [==============================] - 6s 373us/step - loss: 0.6519 - acc: 0.5936\n",
      "4000/4000 [==============================] - 1s 301us/step\n",
      "Epoch 1/1\n",
      "16000/16000 [==============================] - 7s 407us/step - loss: 0.6963 - acc: 0.5130\n",
      "4000/4000 [==============================] - 1s 313us/step\n",
      "Epoch 1/1\n",
      "16000/16000 [==============================] - 6s 360us/step - loss: 0.4066 - acc: 0.8204\n",
      "4000/4000 [==============================] - 1s 286us/step\n"
     ]
    }
   ],
   "source": [
    "# Optimize\n",
    "\n",
    "accuracies2 = []\n",
    "models2 = []\n",
    "\n",
    "for i in np.arange(0.0, 1.1, 0.1):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(120, input_shape=(1000,)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(i))\n",
    "    model.add(Dense(20))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(i))\n",
    "\n",
    "    model.add(Dense(2))\n",
    "    model.add(Activation('softmax'))\n",
    "    \n",
    "    model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "    \n",
    "    model.fit(x_train_s_norm, y_train_s_hot, epochs=1, batch_size=32, verbose=1)\n",
    "    \n",
    "    accuracies2.append(model.evaluate(x_val_norm, y_val_hot)[1])\n",
    "    models2.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(accuracies2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000/4000 [==============================] - 0s 97us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3415415415763855, 0.85124999999999995]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models2[4].evaluate(x_val_norm, y_val_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "16000/16000 [==============================] - 5s 329us/step - loss: 0.4143 - acc: 0.8143\n",
      "4000/4000 [==============================] - 1s 182us/step\n",
      "Epoch 1/1\n",
      "16000/16000 [==============================] - 5s 327us/step - loss: 0.4153 - acc: 0.8123\n",
      "4000/4000 [==============================] - 1s 189us/step\n",
      "Epoch 1/1\n",
      "16000/16000 [==============================] - 6s 356us/step - loss: 0.4211 - acc: 0.8124\n",
      "4000/4000 [==============================] - 1s 214us/step\n",
      "Epoch 1/1\n",
      "16000/16000 [==============================] - 4s 278us/step - loss: 0.4315 - acc: 0.8056\n",
      "4000/4000 [==============================] - 1s 252us/step\n",
      "Epoch 1/1\n",
      "16000/16000 [==============================] - 5s 329us/step - loss: 0.4360 - acc: 0.8003\n",
      "4000/4000 [==============================] - 1s 194us/step\n",
      "Epoch 1/1\n",
      "16000/16000 [==============================] - 5s 311us/step - loss: 0.4478 - acc: 0.7905\n",
      "4000/4000 [==============================] - ETA:  - 1s 281us/step\n",
      "Epoch 1/1\n",
      "16000/16000 [==============================] - 6s 346us/step - loss: 0.4653 - acc: 0.7768\n",
      "4000/4000 [==============================] - 1s 263us/step\n",
      "Epoch 1/1\n",
      "16000/16000 [==============================] - 6s 380us/step - loss: 0.4786 - acc: 0.7651\n",
      "4000/4000 [==============================] - 1s 227us/step\n",
      "Epoch 1/1\n",
      "16000/16000 [==============================] - 5s 313us/step - loss: 0.5163 - acc: 0.7396\n",
      "4000/4000 [==============================] - 1s 211us/step\n",
      "Epoch 1/1\n",
      "16000/16000 [==============================] - 5s 310us/step - loss: 0.5981 - acc: 0.6681\n",
      "4000/4000 [==============================] - 1s 213us/step\n",
      "Epoch 1/1\n",
      "16000/16000 [==============================] - 5s 306us/step - loss: 0.4113 - acc: 0.8154\n",
      "4000/4000 [==============================] - 1s 220us/step\n"
     ]
    }
   ],
   "source": [
    "# Optimize\n",
    "\n",
    "accuracies = []\n",
    "models = []\n",
    "\n",
    "for i in np.arange(0.0, 1.1, 0.1):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(120, input_shape=(1000,)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(i))\n",
    "    model.add(Dense(20))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(Dense(2))\n",
    "    model.add(Activation('softmax'))\n",
    "    \n",
    "    model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "    \n",
    "    model.fit(x_train_s_norm, y_train_s_hot, epochs=1, batch_size=32, verbose=1)\n",
    "    \n",
    "    accuracies.append(model.evaluate(x_val_norm, y_val_hot)[1])\n",
    "    models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.70000000000000007"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(0.0, 1.1, 0.1)[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000/4000 [==============================] - 0s 98us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.34473459619283675, 0.85275000000000001]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models[7].evaluate(x_val_norm, y_val_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "16000/16000 [==============================] - 6s 377us/step - loss: 0.4850 - acc: 0.7605\n",
      "Epoch 2/30\n",
      "16000/16000 [==============================] - 4s 235us/step - loss: 0.3472 - acc: 0.8499\n",
      "Epoch 3/30\n",
      "16000/16000 [==============================] - 4s 232us/step - loss: 0.3220 - acc: 0.8646\n",
      "Epoch 4/30\n",
      "16000/16000 [==============================] - 4s 231us/step - loss: 0.2962 - acc: 0.8732\n",
      "Epoch 5/30\n",
      "16000/16000 [==============================] - 4s 227us/step - loss: 0.2796 - acc: 0.8834\n",
      "Epoch 6/30\n",
      "16000/16000 [==============================] - 4s 222us/step - loss: 0.2616 - acc: 0.8933\n",
      "Epoch 7/30\n",
      "16000/16000 [==============================] - 4s 229us/step - loss: 0.2441 - acc: 0.9026\n",
      "Epoch 8/30\n",
      "16000/16000 [==============================] - 4s 226us/step - loss: 0.2274 - acc: 0.9119\n",
      "Epoch 9/30\n",
      "16000/16000 [==============================] - 4s 231us/step - loss: 0.2116 - acc: 0.9204\n",
      "Epoch 10/30\n",
      "16000/16000 [==============================] - 4s 232us/step - loss: 0.1921 - acc: 0.9260\n",
      "Epoch 11/30\n",
      "16000/16000 [==============================] - 4s 239us/step - loss: 0.1844 - acc: 0.9297\n",
      "Epoch 12/30\n",
      "16000/16000 [==============================] - 4s 236us/step - loss: 0.1675 - acc: 0.9354\n",
      "Epoch 13/30\n",
      "16000/16000 [==============================] - 4s 220us/step - loss: 0.1615 - acc: 0.9381\n",
      "Epoch 14/30\n",
      "16000/16000 [==============================] - 4s 237us/step - loss: 0.1472 - acc: 0.9426\n",
      "Epoch 15/30\n",
      "16000/16000 [==============================] - 4s 226us/step - loss: 0.1416 - acc: 0.9460\n",
      "Epoch 16/30\n",
      "16000/16000 [==============================] - 4s 225us/step - loss: 0.1308 - acc: 0.9521\n",
      "Epoch 17/30\n",
      "16000/16000 [==============================] - 4s 238us/step - loss: 0.1286 - acc: 0.9527\n",
      "Epoch 18/30\n",
      "16000/16000 [==============================] - 4s 232us/step - loss: 0.1236 - acc: 0.9509\n",
      "Epoch 19/30\n",
      "16000/16000 [==============================] - 4s 238us/step - loss: 0.1189 - acc: 0.9543\n",
      "Epoch 20/30\n",
      "16000/16000 [==============================] - 4s 238us/step - loss: 0.1107 - acc: 0.9577\n",
      "Epoch 21/30\n",
      "16000/16000 [==============================] - 4s 223us/step - loss: 0.1085 - acc: 0.9561\n",
      "Epoch 22/30\n",
      "16000/16000 [==============================] - 4s 251us/step - loss: 0.1053 - acc: 0.9584\n",
      "Epoch 23/30\n",
      "16000/16000 [==============================] - 4s 225us/step - loss: 0.0997 - acc: 0.9585\n",
      "Epoch 24/30\n",
      "16000/16000 [==============================] - 4s 222us/step - loss: 0.0942 - acc: 0.9623\n",
      "Epoch 25/30\n",
      "16000/16000 [==============================] - 4s 234us/step - loss: 0.0936 - acc: 0.9630\n",
      "Epoch 26/30\n",
      "16000/16000 [==============================] - 4s 225us/step - loss: 0.0960 - acc: 0.9627\n",
      "Epoch 27/30\n",
      "16000/16000 [==============================] - 4s 224us/step - loss: 0.0847 - acc: 0.9666\n",
      "Epoch 28/30\n",
      "16000/16000 [==============================] - 4s 236us/step - loss: 0.0878 - acc: 0.9642\n",
      "Epoch 29/30\n",
      "16000/16000 [==============================] - 4s 236us/step - loss: 0.0827 - acc: 0.9669\n",
      "Epoch 30/30\n",
      "16000/16000 [==============================] - 4s 230us/step - loss: 0.0785 - acc: 0.9680\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1756405c0>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train best NN for 30 epochs\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(120, input_shape=(1000,)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.7))\n",
    "model.add(Dense(20))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dense(2))\n",
    "model.add(Activation('softmax'))\n",
    "    \n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "    \n",
    "model.fit(x_train_s_norm, y_train_s_hot, epochs=30, batch_size=32, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000/4000 [==============================] - 1s 312us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.61870412689447407, 0.85075000000000001]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_val_norm, y_val_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Dataset Statistics (throw away neutral words)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 3.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  3.,  1., ...,  0.,  0.,  0.],\n",
       "       ..., \n",
       "       [ 3.,  0.,  1., ...,  0.,  0.,  0.],\n",
       "       [ 2.,  4.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  3., ...,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read in data as Pandas dataframe\n",
    "data_pd = pd.read_csv('training_data.txt', sep=\" \", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>991</th>\n",
       "      <th>992</th>\n",
       "      <th>993</th>\n",
       "      <th>994</th>\n",
       "      <th>995</th>\n",
       "      <th>996</th>\n",
       "      <th>997</th>\n",
       "      <th>998</th>\n",
       "      <th>999</th>\n",
       "      <th>1000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Label</td>\n",
       "      <td>thi</td>\n",
       "      <td>book</td>\n",
       "      <td>wa</td>\n",
       "      <td>one</td>\n",
       "      <td>read</td>\n",
       "      <td>movi</td>\n",
       "      <td>like</td>\n",
       "      <td>great</td>\n",
       "      <td>good</td>\n",
       "      <td>...</td>\n",
       "      <td>brought</td>\n",
       "      <td>regular</td>\n",
       "      <td>shock</td>\n",
       "      <td>secret</td>\n",
       "      <td>complaint</td>\n",
       "      <td>challeng</td>\n",
       "      <td>halloween</td>\n",
       "      <td>pair</td>\n",
       "      <td>soni</td>\n",
       "      <td>ten</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1001 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    0    1     2    3    4     5     6     7      8     9    ...      991   \\\n",
       "0  Label  thi  book   wa  one  read  movi  like  great  good ...   brought   \n",
       "1      1    0     0    0    0     0     2     0      2     0 ...         0   \n",
       "2      1    3     0    0    0     0     0     0      0     0 ...         0   \n",
       "3      1    0     3    1    0     0     0     0      0     0 ...         0   \n",
       "4      1    1     1    0    0     0     0     0      0     0 ...         0   \n",
       "\n",
       "      992    993     994        995       996        997   998   999  1000  \n",
       "0  regular  shock  secret  complaint  challeng  halloween  pair  soni  ten  \n",
       "1        0      0       0          0         0          0     0     0    0  \n",
       "2        0      0       0          0         0          0     0     0    0  \n",
       "3        0      0       0          0         0          1     0     0    0  \n",
       "4        0      0       0          0         0          0     0     0    0  \n",
       "\n",
       "[5 rows x 1001 columns]"
      ]
     },
     "execution_count": 393,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>342</th>\n",
       "      <th>524</th>\n",
       "      <th>525</th>\n",
       "      <th>660</th>\n",
       "      <th>663</th>\n",
       "      <th>728</th>\n",
       "      <th>843</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.262831</td>\n",
       "      <td>0.347876</td>\n",
       "      <td>0.330211</td>\n",
       "      <td>0.392287</td>\n",
       "      <td>0.431077</td>\n",
       "      <td>0.422631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>524</th>\n",
       "      <td>0.262831</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.429759</td>\n",
       "      <td>0.426896</td>\n",
       "      <td>0.501796</td>\n",
       "      <td>0.548743</td>\n",
       "      <td>0.537139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>525</th>\n",
       "      <td>0.347876</td>\n",
       "      <td>0.429759</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.552558</td>\n",
       "      <td>0.691740</td>\n",
       "      <td>0.752040</td>\n",
       "      <td>0.735247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>660</th>\n",
       "      <td>0.330211</td>\n",
       "      <td>0.426896</td>\n",
       "      <td>0.552558</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.648858</td>\n",
       "      <td>0.703822</td>\n",
       "      <td>0.687844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>663</th>\n",
       "      <td>0.392287</td>\n",
       "      <td>0.501796</td>\n",
       "      <td>0.691740</td>\n",
       "      <td>0.648858</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.895175</td>\n",
       "      <td>0.875350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>728</th>\n",
       "      <td>0.431077</td>\n",
       "      <td>0.548743</td>\n",
       "      <td>0.752040</td>\n",
       "      <td>0.703822</td>\n",
       "      <td>0.895175</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.960918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>843</th>\n",
       "      <td>0.422631</td>\n",
       "      <td>0.537139</td>\n",
       "      <td>0.735247</td>\n",
       "      <td>0.687844</td>\n",
       "      <td>0.875350</td>\n",
       "      <td>0.960918</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          342       524       525       660       663       728       843\n",
       "342  1.000000  0.262831  0.347876  0.330211  0.392287  0.431077  0.422631\n",
       "524  0.262831  1.000000  0.429759  0.426896  0.501796  0.548743  0.537139\n",
       "525  0.347876  0.429759  1.000000  0.552558  0.691740  0.752040  0.735247\n",
       "660  0.330211  0.426896  0.552558  1.000000  0.648858  0.703822  0.687844\n",
       "663  0.392287  0.501796  0.691740  0.648858  1.000000  0.895175  0.875350\n",
       "728  0.431077  0.548743  0.752040  0.703822  0.895175  1.000000  0.960918\n",
       "843  0.422631  0.537139  0.735247  0.687844  0.875350  0.960918  1.000000"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_pd.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>991</th>\n",
       "      <th>992</th>\n",
       "      <th>993</th>\n",
       "      <th>994</th>\n",
       "      <th>995</th>\n",
       "      <th>996</th>\n",
       "      <th>997</th>\n",
       "      <th>998</th>\n",
       "      <th>999</th>\n",
       "      <th>1000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Label</td>\n",
       "      <td>thi</td>\n",
       "      <td>book</td>\n",
       "      <td>wa</td>\n",
       "      <td>one</td>\n",
       "      <td>read</td>\n",
       "      <td>movi</td>\n",
       "      <td>like</td>\n",
       "      <td>great</td>\n",
       "      <td>good</td>\n",
       "      <td>...</td>\n",
       "      <td>brought</td>\n",
       "      <td>regular</td>\n",
       "      <td>shock</td>\n",
       "      <td>secret</td>\n",
       "      <td>complaint</td>\n",
       "      <td>challeng</td>\n",
       "      <td>halloween</td>\n",
       "      <td>pair</td>\n",
       "      <td>soni</td>\n",
       "      <td>ten</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1001 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    0    1     2    3    4     5     6     7      8     9    ...      991   \\\n",
       "0  Label  thi  book   wa  one  read  movi  like  great  good ...   brought   \n",
       "1      1    0     0    0    0     0     0     0      0     0 ...         0   \n",
       "2      1    2     1    0    1     1     0     0      0     0 ...         0   \n",
       "3      1    1     0    0    0     0     0     1      0     1 ...         0   \n",
       "4      1    0     0    0    0     0     0     0      1     0 ...         0   \n",
       "\n",
       "      992    993     994        995       996        997   998   999  1000  \n",
       "0  regular  shock  secret  complaint  challeng  halloween  pair  soni  ten  \n",
       "1        0      0       0          0         0          0     0     0    0  \n",
       "2        0      0       0          0         0          0     0     0    0  \n",
       "3        0      0       0          0         0          0     0     0    0  \n",
       "4        0      0       0          0         0          0     0     0    0  \n",
       "\n",
       "[5 rows x 1001 columns]"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_pd.head(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>991</th>\n",
       "      <th>992</th>\n",
       "      <th>993</th>\n",
       "      <th>994</th>\n",
       "      <th>995</th>\n",
       "      <th>996</th>\n",
       "      <th>997</th>\n",
       "      <th>998</th>\n",
       "      <th>999</th>\n",
       "      <th>1000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 1001 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, ...]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 1001 columns]"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_pd[[]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x13c4ba390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "corr = data_pd.head(n=5).corr()\n",
    "fig = plt.figure(1, figsize=(10,10))\n",
    "plt.imshow(corr,cmap='inferno')\n",
    "labels = np.arange(len(data_pd.head(n=5).columns))\n",
    "plt.xticks(labels,data_pd.head(n=5).columns,rotation=90)\n",
    "plt.yticks(labels,data_pd.head(n=5).columns)\n",
    "plt.title('Correlation Matrix of Global Variables')\n",
    "cbar = plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# words pandas df\n",
    "\n",
    "data_pd_words = data_pd.loc[:,1:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8495\n"
     ]
    }
   ],
   "source": [
    "# Take out neutral words (increase signal to noise/ remove features)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train_s, x_val, y_train_s, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "x_train_s_norm = preprocessing.normalize(x_train_s, norm='l2')\n",
    "x_val_norm = preprocessing.normalize(x_val, norm='l2')\n",
    "\n",
    "model = LogisticRegression(penalty='l1', C=3.90625)\n",
    "model.fit(x_train_s_norm, y_train_s)\n",
    "\n",
    "print(model.score(x_val_norm , y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SelectFromModel(estimator=LogisticRegression(C=3.90625, class_weight=None, dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='ovr', n_jobs=1, penalty='l1', random_state=None,\n",
       "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False),\n",
       "        norm_order=1, prefit=False, threshold=None)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "SelectFromModel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 0.001}\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "tuned_parameters = {'alpha': [10 ** a for a in range(-6, -1)]}\n",
    "clf = GridSearchCV(SGDClassifier(loss='hinge', penalty='elasticnet',l1_ratio=0.15, n_iter=5, shuffle=True, verbose=False, n_jobs=10, average=False, class_weight='balanced')\n",
    "                  , tuned_parameters, cv=10, scoring='f1_macro')\n",
    "\n",
    "#now clf is the best classifier found given the search space\n",
    "clf.fit(x_train_s, y_train_s)\n",
    "#you can find the best alpha here\n",
    "print(clf.best_params_)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.84275\n"
     ]
    }
   ],
   "source": [
    "print(clf.best_estimator_.score(x_val_norm , y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x15a82bba048>]"
      ]
     },
     "execution_count": 549,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x15a82baf4e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Before feature reduction\n",
    "\n",
    "ws =  clf.best_estimator_.coef_\n",
    "plt.plot(range(len(ws[0])), ws[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(0, clf.best_estimator_.coef_.shape[0]):\n",
    "    top10 = np.argsort(clf.best_estimator_.coef_[i])[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bottom10_list = []\n",
    "for i in range(len(top10)):\n",
    "    bottom10_list.append((np.where(clf.best_estimator_.coef_[0] == np.sort(clf.best_estimator_.coef_)[0][:10][i])[0][0], np.sort(clf.best_estimator_.coef_)[0][:10][i]))\n",
    "    \n",
    "bottom10_list_x = []\n",
    "for i in range(len(top10)):\n",
    "    bottom10_list_x.append(sorted(bottom10_list, key=lambda x: x[0])[i][0])\n",
    "    \n",
    "bottom10_list_y = []\n",
    "for i in range(len(top10)):\n",
    "    bottom10_list_y.append(sorted(bottom10_list, key=lambda x: x[0])[i][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "top10_list = []\n",
    "for i in range(len(top10)):\n",
    "    top10_list.append((top10[i], np.take(clf.best_estimator_.coef_, top10)[i]))\n",
    "    \n",
    "top10_list_x = []\n",
    "for i in range(len(top10)):\n",
    "    top10_list_x.append(sorted(top10_list, key=lambda x: x[0])[i][0])\n",
    "    \n",
    "top10_list_y = []\n",
    "for i in range(len(top10)):\n",
    "    top10_list_y.append(sorted(top10_list, key=lambda x: x[0])[i][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-2, 2)"
      ]
     },
     "execution_count": 554,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x15a826d33c8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# After feature selection (top 20)\n",
    "\n",
    "plt.scatter(top10_list_x, top10_list_y)\n",
    "plt.scatter(bottom10_list_x, bottom10_list_y)\n",
    "plt.xlim(-50,1000)\n",
    "plt.ylim(-2,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>235</th>\n",
       "      <th>878</th>\n",
       "      <th>30</th>\n",
       "      <th>838</th>\n",
       "      <th>7</th>\n",
       "      <th>195</th>\n",
       "      <th>503</th>\n",
       "      <th>323</th>\n",
       "      <th>226</th>\n",
       "      <th>129</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Label</td>\n",
       "      <td>wrong</td>\n",
       "      <td>mark</td>\n",
       "      <td>look</td>\n",
       "      <td>remov</td>\n",
       "      <td>like</td>\n",
       "      <td>place</td>\n",
       "      <td>publish</td>\n",
       "      <td>becom</td>\n",
       "      <td>small</td>\n",
       "      <td>problem</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0      235   878   30     838   7      195      503    323    226  \\\n",
       "0  Label  wrong  mark  look  remov  like  place  publish  becom  small   \n",
       "1      1      0     0     0      0     0      0        0      0      0   \n",
       "2      1      0     0     2      0     0      0        0      0      0   \n",
       "3      1      0     0     0      0     0      0        0      0      0   \n",
       "4      1      0     0     0      0     0      0        0      0      0   \n",
       "\n",
       "       129  \n",
       "0  problem  \n",
       "1        0  \n",
       "2        0  \n",
       "3        0  \n",
       "4        0  "
      ]
     },
     "execution_count": 395,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# top 10 words\n",
    "\n",
    "data_pd[[0] + np.ndarray.tolist(top10)].head(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>76</th>\n",
       "      <th>110</th>\n",
       "      <th>118</th>\n",
       "      <th>182</th>\n",
       "      <th>210</th>\n",
       "      <th>283</th>\n",
       "      <th>302</th>\n",
       "      <th>456</th>\n",
       "      <th>529</th>\n",
       "      <th>551</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Label</td>\n",
       "      <td>end</td>\n",
       "      <td>show</td>\n",
       "      <td>differ</td>\n",
       "      <td>tell</td>\n",
       "      <td>next</td>\n",
       "      <td>hour</td>\n",
       "      <td>fine</td>\n",
       "      <td>impress</td>\n",
       "      <td>within</td>\n",
       "      <td>manag</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    76    110     118   182   210   283   302      456     529    551\n",
       "0  Label  end  show  differ  tell  next  hour  fine  impress  within  manag\n",
       "1      1    0     1       0     0     0     0     0        0       0      0\n",
       "2      1    0     0       0     0     0     1     1        1       0      0\n",
       "3      1    0     0       0     0     0     0     0        0       0      0\n",
       "4      1    0     1       0     0     0     0     0        0       0      0"
      ]
     },
     "execution_count": 396,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bottom 10 words\n",
    "\n",
    "data_pd[[0] + bottom10_list_x].head(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Show that largest weights correspond with labels 0 and 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Explore labels for features 'wrong'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list_bool = (data_pd_words[235] == '0') | (data_pd_words[235] == 0)\n",
    "\n",
    "have_wrong = [not i for i in list_bool]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>235</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Label</td>\n",
       "      <td>wrong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0      235\n",
       "0    Label  wrong\n",
       "108      0      1\n",
       "192      0      1\n",
       "248      0      1\n",
       "276      0      1\n",
       "307      0      1\n",
       "312      0      1\n",
       "338      0      1\n",
       "394      0      1\n",
       "416      0      1"
      ]
     },
     "execution_count": 409,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_pd[[0, 235]][have_wrong].head(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "have_wrong_y = data_pd[[0, 235]][have_wrong][0].values[1:len(data_pd[[0, 235]][have_wrong][0].values)].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(369, 178)"
      ]
     },
     "execution_count": 446,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number that have 'wrong' and have label 0, Number that have 'wrong' and have label 1\n",
    "\n",
    "len(have_wrong_y[have_wrong_y == 0]), len(have_wrong_y[have_wrong_y == 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0730337078651684"
      ]
     },
     "execution_count": 450,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(have_wrong_y[have_wrong_y == 0])/len(have_wrong_y[have_wrong_y == 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list_bool_dont = (data_pd_words[235] == '0') | (data_pd_words[235] == 0)\n",
    "\n",
    "dont_have_wrong = list_bool_dont"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>235</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  0   235\n",
       "1   1   0\n",
       "2   1   0\n",
       "3   1   0\n",
       "4   1   0\n",
       "5   0   0"
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_pd[[0, 235]][dont_have_wrong].head(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dont_have_wrong_y = data_pd[[0, 235]][dont_have_wrong][0].values.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9524, 9929)"
      ]
     },
     "execution_count": 448,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number that don't have 'wrong' and have label 0, Number that don't have 'wrong' and have label 1\n",
    "\n",
    "len(dont_have_wrong_y[dont_have_wrong_y == 0]), len(dont_have_wrong_y[dont_have_wrong_y == 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9592103937959513"
      ]
     },
     "execution_count": 451,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dont_have_wrong_y[dont_have_wrong_y == 0])/len(dont_have_wrong_y[dont_have_wrong_y == 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20000"
      ]
     },
     "execution_count": 449,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dont_have_wrong_y) + len(have_wrong_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "965    loud\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 454,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Explore labels for features 'loud'\n",
    "\n",
    "data_pd.iloc[0][data_pd.iloc[0] == 'loud']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>965</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>loud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    965\n",
       "0  loud\n",
       "1     0\n",
       "2     0\n",
       "3     0\n",
       "4     0"
      ]
     },
     "execution_count": 455,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_pd[[965]].head(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list_bool_loud = (data_pd_words[965] == '0') | (data_pd_words[965] == 0)\n",
    "\n",
    "have_loud = [not i for i in list_bool_loud]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "have_loud_y =  data_pd[[0, 965]][have_loud][0].values[1:len(data_pd[[0, 965]][have_loud][0].values)].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(77, 71)"
      ]
     },
     "execution_count": 458,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number that have 'loud' and have label 0, Number that have 'loud' and have label 1\n",
    "\n",
    "len(have_loud_y[have_loud_y == 0]), len(have_loud_y[have_loud_y == 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0845070422535212"
      ]
     },
     "execution_count": 466,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(have_loud_y[have_loud_y == 0])/len(have_loud_y[have_loud_y == 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list_bool_loud_dont = (data_pd_words[965] == '0') | (data_pd_words[965] == 0)\n",
    "\n",
    "dont_have_loud = list_bool_loud_dont"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dont_have_loud_y = data_pd[[0, 965]][dont_have_loud][0].values.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9816, 10036)"
      ]
     },
     "execution_count": 461,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number that don't have 'loud' and have label 0, Number that don't have 'loud' and have label 1\n",
    "\n",
    "len(dont_have_loud_y[dont_have_loud_y == 0]), len(dont_have_loud_y[dont_have_loud_y == 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9780789159027501"
      ]
     },
     "execution_count": 467,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dont_have_loud_y[dont_have_loud_y == 0])/len(dont_have_loud_y[dont_have_loud_y == 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20000"
      ]
     },
     "execution_count": 462,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dont_have_loud_y) + len(have_loud_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculate + show table of largest proportion ratios, then train on only the words with the highest ratios\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train_top20 = []\n",
    "for i in range(len(x_train)):\n",
    "    x_train_top20.append(x_train[i][top10_list_x + bottom10_list_x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([ 2.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.]),\n",
       " array([ 0.,  0.,  2.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.]),\n",
       " array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.]),\n",
       " array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.]),\n",
       " array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  2.,\n",
       "         1.,  0.,  0.,  0.,  0.,  0.,  0.])]"
      ]
     },
     "execution_count": 489,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_top20[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.72175\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression w/ top20 words\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train_s, x_val, y_train_s, y_val = train_test_split(x_train_top20, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "x_train_s_norm = preprocessing.normalize(x_train_s, norm='l2')\n",
    "x_val_norm = preprocessing.normalize(x_val, norm='l2')\n",
    "\n",
    "model = LogisticRegression(penalty='l1', C=3.90625)\n",
    "model.fit(x_train_s_norm, y_train_s)\n",
    "\n",
    "print(model.score(x_val_norm , y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(0, clf.best_estimator_.coef_.shape[0]):\n",
    "    top10 = np.argsort(clf.best_estimator_.coef_[i])[-100:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "top10_list = []\n",
    "for i in range(len(top10)):\n",
    "    top10_list.append((top10[i], np.take(clf.best_estimator_.coef_, top10)[i]))\n",
    "    \n",
    "top10_list_x = []\n",
    "for i in range(len(top10)):\n",
    "    top10_list_x.append(sorted(top10_list, key=lambda x: x[0])[i][0])\n",
    "    \n",
    "top10_list_y = []\n",
    "for i in range(len(top10)):\n",
    "    top10_list_y.append(sorted(top10_list, key=lambda x: x[0])[i][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bottom10_list = []\n",
    "for i in range(len(top10)):\n",
    "    bottom10_list.append((np.where(clf.best_estimator_.coef_[0] == np.sort(clf.best_estimator_.coef_)[0][:len(top10)][i])[0][0], np.sort(clf.best_estimator_.coef_)[0][:len(top10)][i]))\n",
    "    \n",
    "bottom10_list_x = []\n",
    "for i in range(len(top10)):\n",
    "    bottom10_list_x.append(sorted(bottom10_list, key=lambda x: x[0])[i][0])\n",
    "    \n",
    "bottom10_list_y = []\n",
    "for i in range(len(top10)):\n",
    "    bottom10_list_y.append(sorted(bottom10_list, key=lambda x: x[0])[i][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400"
      ]
     },
     "execution_count": 558,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(top10_list_x + bottom10_list_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train_topx = []\n",
    "for i in range(len(x_train)):\n",
    "    x_train_topx.append(x_train[i][top10_list_x + bottom10_list_x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.78625\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression w/ top60 words\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train_s, x_val, y_train_s, y_val = train_test_split(x_train_topx, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "x_train_s_norm = preprocessing.normalize(x_train_s, norm='l2')\n",
    "x_val_norm = preprocessing.normalize(x_val, norm='l2')\n",
    "\n",
    "model = LogisticRegression(penalty='l1', C=3.90625)\n",
    "model.fit(x_train_s_norm, y_train_s)\n",
    "\n",
    "print(model.score(x_val_norm , y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-2, 2)"
      ]
     },
     "execution_count": 564,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x15a82787908>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# After feature selection (top 60)\n",
    "\n",
    "plt.scatter(top10_list_x, top10_list_y)\n",
    "plt.scatter(bottom10_list_x, bottom10_list_y)\n",
    "plt.xlim(-50,1000)\n",
    "plt.ylim(-2,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.80775\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression w/ top100 words\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train_s, x_val, y_train_s, y_val = train_test_split(x_train_topx, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "x_train_s_norm = preprocessing.normalize(x_train_s, norm='l2')\n",
    "x_val_norm = preprocessing.normalize(x_val, norm='l2')\n",
    "\n",
    "model = LogisticRegression(penalty='l1', C=3.90625)\n",
    "model.fit(x_train_s_norm, y_train_s)\n",
    "\n",
    "print(model.score(x_val_norm , y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-2, 2)"
      ]
     },
     "execution_count": 571,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAD8CAYAAACCRVh7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAHVhJREFUeJzt3X+wXGWd5/H3h0vEDKMEhqiQHwPupEDWQaO3EJatLUZQfsgAwygDbq2oVN2aLSmVtVhhrULknwnLljislhqRVadchFV+BGQmg+CUO1bBcCMQCcgQQc1N2CEOEMYlq0n47h99bux0ztO3u8+PPt39eVXdurdPP/c85zx9zvme58d5WhGBmZlZngOGvQFmZtZcDhJmZpbkIGFmZkkOEmZmluQgYWZmSQ4SZmaWVDhISFoh6fuSnpC0SdLHctJI0g2SNkvaKOltRfM1M7PqHVjCOnYDn4iIH0l6DbBB0r0R8XhbmjOBVdnPO4AvZr/NzKzBCtckIuLZiPhR9ve/AE8AyzqSnQt8I1oeAJZIOqJo3mZmVq0yahJ7SToKWA082PHWMmBL2+u5bNmzOeuYAWYADj744Lcfe+yxZW6imdlY27Bhwy8jYmlZ6ystSEj6XeA7wMcj4qXOt3P+JXc+kIhYC6wFmJ6ejtnZ2bI20cxs7En6eZnrK2V0k6RFtALENyPitpwkc8CKttfLgW1l5G1mZtUpY3STgK8CT0TEZxPJ1gEfyEY5nQjsiIj9mprMzKxZymhuOhn4D8CPJT2SLfsvwEqAiPgScA9wFrAZeBn4UAn5mplZxQoHiYj4e/L7HNrTBPCRonmZmVm9/MS1mZklOUiYmVmSg4SZmSU5SJiZWZKDhJmZJTlImJlZkoOEmZklOUiYmVmSg4SZmSU5SJiZWZKDhJmZJTlImJlZkoOEmZklOUiYmVmSg4SZmSU5SJiZWZKDhJmZJTlImJlZUilBQtJNkp6T9Fji/VMk7ZD0SPZzVRn5mplZtQp/x3Xma8DngW90SfO/I+LskvIzM7MalFKTiIgfAM+XsS4zM2uOOvskTpL0qKS/lvSva8zXzMwGVFZz00J+BPx+RPxK0lnAHcCqvISSZoAZgJUrV9a0eWZmlqeWmkREvBQRv8r+vgdYJOnwRNq1ETEdEdNLly6tY/PMzCyhliAh6Q2SlP19QpbvP9eRt5mZDa6U5iZJNwOnAIdLmgM+DSwCiIgvAe8F/qOk3cBO4MKIiDLyNjOz6pQSJCLiogXe/zytIbJmZjZC/MS1mZklOUiYmVmSg4SZmSU5SJiZWZKDhJmZJTlImJlZkoOEmZklOUiYmVmSg4SZmSU5SJiZWZKDhJmZJTlImJlZkoOEmZklOUiYmVmSg4SZmSU5SJiZWZKDhJmZJZXyzXTWvzse3sp1659k24s7OXLJYi4//RjOW71s2JtlZrYPB4khuOPhrVx524/ZuWsPAFtf3MmVt/0YwIHCzBqllOYmSTdJek7SY4n3JekGSZslbZT0tjLyHVXXrX9yb4CYt3PXHq5b/2Qt+d/x8FZOXnM/R1/xXU5ecz93PLy1lnzNbPSU1SfxNeCMLu+fCazKfmaAL5aU70ja9uLOvpaXab4Ws/XFnQS/rcU4UJhZnlKCRET8AHi+S5JzgW9EywPAEklHlJH3KDpyyeK+lpdp2LUYMxstdY1uWgZsaXs9ly3bj6QZSbOSZrdv317LxtXt8tOPYfGiqX2WLV40xeWnH1N53sOsxZjZ6KkrSChnWeQljIi1ETEdEdNLly6teLOG47zVy/iL8/+QZUsWI2DZksX8xfl/WEun9TBrMWY2euoa3TQHrGh7vRzYVlPejXTe6mVDGcl0+enH7DOyCuqrxYCH/pqNmrpqEuuAD2SjnE4EdkTEszXlbW2GWYtxp7nZ6CmlJiHpZuAU4HBJc8CngUUAEfEl4B7gLGAz8DLwoTLytcEMqxbTrdN8nGoTri3ZOCklSETERQu8H8BHysjLRtckdJr7QUkbN567yWozCZ3mHmJs48ZBYow0/UnqYQ79rcsk1JZssnjupjExCs0c89sxzu31Ry5ZzNacgDBOtSWbLGMdJCapA3FUOoWH1Wlel2EPMTYr29gGiVG4sy6TmzmaYRJqS+Nkkm4kBzW2QWJU7qzL4maO5hj32tK4mLQbyUGNbcf1pN1ZT0KnsFmZPBKtN2Nbk1joznrcqplu5jDrz6TdSA5qbINEtw7Eca1mupnDrHeDNNGO281lL8a2uanbHEWuZppZv020kzr32NjWJCB9Z+1qZssk3hWZzeulibb9HDlAYk/s+w0HVQ6Gacr5OdZBIqXpI4HqODjGtcnNrB/dmmg7z5HOADGvipvLJp2fY9vc1E2TRwLVVaV1k5tZd3nnSJ4qbi6bdH5OZJAY5ncqLKSug8NNbmbd9XIuVHVz2aTzcyKbm6C5I4FSB8HWF3dy8pr7S2t6anqTm9mwpc6RKYlXIirtJ2jS+TkRQaLODqCieaUODti/XbJIXp5jyKy71DlSR6tDk87PsQ8SdXYAlZFX3sHRrr3pqUhefvjOrLthniNNOj8ViR77Jpieno7Z2dlC6zh5zf25d+bLlizmh1e8s9C6q8prvoaQqlGIdI2jiv0yG4a6WgCaMtS0LJI2RMR0Wesr6zuuzwD+EpgCboyINR3vfxC4DpgfovP5iLixjLwXUmcHUFl5zfeXpILOkUsW17Jf43byDIvLsT93PLyVq9dt4sWdu/Yuq6oFoClDTYscI53/e8Di1x5W5rYVDhKSpoAvAO8C5oCHJK2LiMc7kt4SEZcWza9fdXYAlZ1Xt3bJVE2jrP1qyslT1LAv0ONSjnmqKNvO8mrX3tRaVr5NmC26yDGS978Hvnbp75e5fWUMgT0B2BwRT0fEb4BvAeeWsN5S1PlMRNl5dRuqW/V+VT0Ut46vWm3CNApNGu9epqrKdqFnE+bzKSvfJgw1LXKM5JaXVOqjDWU0Ny0DtrS9ngPekZPuTyX9O+AfgcsiYktOGiTNADMAK1euLLxxdXYAVZFXaqhu1ftV5clTx931HQ9v5RO3PlraNAqD3jU34SJURGq/q7oDX6hcpqRS823CUNMix0gdx1EZQUI5yzp7w+8Cbo6IX0v6c+DrQG7vakSsBdZCq+O6hO0b+JmIQS4MdT5/UWVeg548vZRZ1VX8+SBU1jQKRYJat3IcdlPYQvL2+7JbHuHjtzyS/J+iF61uQ8AXL5pK1jIGzbcJQ02LBKpu5VWWMqolc8CKttfLgW3tCSLinyPi19nLrwBvLyHfSjWhqaJKCzX3DNKc1WuZVXV3Pb9PH7/lka5NFv3eJRZpDkiV4x8du7Rxx1fnMfGZuzbtt98L3bUVvQPPKy+AQ39n0d6m1zLzbcLsC0WajnPLK+KVMrevjJrEQ8AqSUfTGr10IfD+9gSSjoiIZ7OX5wBPlJBvpZrQodWvXu9Me7kzHqQ5q9cyq6KK363Ds90gd4lFglqqHJt2fOUdE/0q4w68l+Ou7Dv/Yc++UKTpOO9/t7y0/edlbl/hIBERuyVdCqynNQT2pojYJOkaYDYi1gEflXQOsBt4Hvhg0XyrNqy25EGbIPppEunlAjXIdvRaZv1W8Qdtwuo0Je13l9jLuosGtbyL0GWJJpth9VX0OpldnvnndspqLut20W7SQ2ZlKhKoOv9XV770fFnbBSU9JxER9wD3dCy7qu3vK4Ery8irSgvNHQ/VdmgVafvu5850oYv5oNvR68X0vNXLmP3589z84Bb2RDAl8advzz9Jet2WhS6uedMp9LruKtqt6+ww7SUQDhqchvHwZj8X1Lqm3R/0xm4Ugt1EzgKbp7M9PS9AVN2hVaTtu5+aT+pCNL980O3otW31joe38p0NW/eW8Z4IvrNha257fK/b0u3immpn7nXdVbRb1zU0u9d+olT5LV50wN5+gM4RKk2f66uOfsVB8xilPk8HiUyquj0l1dahVaSJa6ELf7uFLlCDbkevF9N+glA/TVh5+/S5P3srP7zinbmfWz/7ed7qZfzwinfyzJr3JNfXj7o6THst68tPP4ZFB+w/UHH3K8Hlpx/Dz9a8h+v/7K2NnF4/pY5nVAbNY5Senxn7Cf56lbpgvBLBM2veU8s2FGmC6KdJZKF23SLb0UtTQL+1nl6bsKC/tuphj5Gvo8O017I+b/UyPnPXJl54edc+y3ftib1NlsPu4O1XHf2Kg+YxSs/POEhkhn3BgGJt3/1eJLud8FWPHe+nrPsNfv1cxJowRr5q/ZT1ix0BYl4TL1y9qOOcHjSPJlxveuXmpkwTvtK0aBNEWU0iVTeF9FPWVW5LE8bIV62fsu6nyXIU1HFOD5pHE643vRr7qcL7MSqjDcaBy7o+gz4/A/V9yU5VJnF0U9lThTtImNleDt6jr5HfJ2Fm42HUOqeteu6TMDOzJAcJMzNLcpAwM7MkBwkzM0tykDAzsyQHCTMzS3KQMDOzJAcJMzNLcpAwM7MkBwkzM0sqJUhIOkPSk5I2S7oi5/2DJN2Svf+gpKPKyNfMzKpVOEhImgK+AJwJHAdcJOm4jmSXAC9ExB8A1wPXFs3XzMyqV0ZN4gRgc0Q8HRG/Ab4FnNuR5lzg69nf3wZOlbT/dyWamVmjlBEklgFb2l7PZcty00TEbmAH8Ht5K5M0I2lW0uz27dtL2DwzMxtUGUEir0bQ+SUVvaRpLYxYGxHTETG9dOnSwhtnZmaDKyNIzAEr2l4vB7al0kg6EDgEeL6EvM3MrEJlBImHgFWSjpb0KuBCYF1HmnXAxdnf7wXujyZ/JZ6ZmQElfDNdROyWdCmwHpgCboqITZKuAWYjYh3wVeCvJG2mVYO4sGi+ZmZWvVK+vjQi7gHu6Vh2Vdvf/w94Xxl5mZlZffzEtZmZJTlImJlZkoOEmZklOUiYmVmSg4SZmSU5SJiZWZKDhJmZJTlImJlZkoOEmZklOUiYmVmSg4SZmSU5SJiZWZKDhJmZJTlImJlZkoOEmZklOUiYmVmSg4SZNcPGW+H6N8PVS1q/N9467C3KV9Z2jsj+lvLNdGZmfdt4K9x3DezYAgho+9r7HVvgro+2/j7+gmFsXb6Nt7a2a9fO1usdW+C2GfjFA3D2Z7v/333XwI45OGQ5rHo3PPo/913PQvvbuY5Tr6qlbArVJCQdJuleSU9lvw9NpNsj6ZHsZ12RPM1sDMxfbHdsyRbE/ml27WxdFJvkvmt+e2HfK2D2pnRNYJ99jdbv2Zv2X0+3/c1bx10fraX2UbS56QrgvohYBdyXvc6zMyLemv2cUzDP4RuRaqJZZcdq0fXmXmxz7JgbbPuqktyeSF/gU4Gln/XnraOmIFq0uelc4JTs768Dfwd8suA6m6WMauKwDama2liTUh55TSNlHKuDrLezzPfWIBZwyPLBt3MhqeOg2/HRbdtTF/h+Al1qf8tY94CK1iReHxHPAmS/X5dI92pJs5IekHRetxVKmsnSzm7fvr3g5hVURjVx2IZYTW2kSSqPqu4++11vXpmjhfNZtLh1gS5Le+3n2qPhzo/sfxzc/Z+6Hx+nXpXe9tQFPhnoOtbTbX/7Xnd5FgwSkr4n6bGcn3P7yGdlREwD7wc+J+lfpRJGxNqImI6I6aVLl/aRRQXKqCYO2xCrqY00juWRavqp6u6z3/Umz6MugWLxYfDHNwxe4+ksk86L/87nYc9v9v2fXTthw9e6Hx/HXwDTH95/27td4E+9qvV+Z/rpD8MhK1rrOmRF9/1NraPMIJqwYHNTRJyWek/SP0k6IiKelXQE8FxiHduy309L+jtgNfDTwTa5RmVUE4dtiNXURhqn8th4K/z1J1sXvHntTT+pppGix2q/6+3Wjn/Iita6NAWxp/W6aPNfXnPY7Fd7+9/Yk7+8fR/O/iysPLH3Jsv55UWaOMtYx4CK9kmsAy4G1mS/7+xMkI14ejkifi3pcOBk4L8WzLceyfbHjuF6/UT0utvDq7pQjKpxKY/OC2G7+TvfU6/aP00Zd5/9rjdZ5ivgsseKbUu7fYbUDmg+WHXqPD6Ov6D/i3zR87yMdQygaJ/EGuBdkp4C3pW9RtK0pBuzNG8CZiU9CnwfWBMRjxfMtx5lVBPbDaM9fIjV1EYal/JYaHTQjrnWMfnHNwx2rHbT73rrKPP9htQOYNFiePsHm3d8DHk0pSISbewNMD09HbOzs8PdiDLv/K9/cz13VJ0mZTRPr8ahPK5eQrJ/DKo/pvpVdZmnzq1uDlgEB70Gdr7Q++imuuXVGBct7hqUJW3I+oBL4SBRp+SJLbj6xbq3xoatyMWo20VxgYtI4/RbDnnpb5uha9DsVEbfRx2uPXrfPqd5XW4Cyg4SnrupTkMcxmY9qqtqX7TpMa8JB4qPCqpbv+WQSr84d7KH/S1aDOd/pXWBbXoZbbw1P0BArQMtHCTqVFbb7CQ98V3nvtbZZ5Qainv7n/eWX16/wPlfgU8+0/yLX7t+hySn0kOi//CSfcvoLe9vrWMUJufrNiy7xhtLT/BXpzKGsVX1FG3TLDS8s4p97XbBKju/1J1g7Ol9H9tHu8w3wdw2M/x29H70OyQ5tXznC3D+2u7nVlnnTl3nYLfaQo0d6Q4SdSs6jK3OC9mw9DK8s4p9rfMZim7TO7TvYy/t9aN849DvkORu6Rc6t8o6d+o6B1P7uviwWj9XNzeNmnF6GCyll+GdVaizzyjVpzBvx1zvzV+j/BR5v02wRZpsyzp36joHU/t65rXl5rMAB4lRMwmd3wudbFXta53PUMz3KWgq//1Dlvd+8R/lG4d+n7ko8uxHWedOXedgVc+59MnNTaOmqqdom6RbU0yV+1r31Afz6019nrfN5P9f58V/1J8ir+vp5bLOnTrPwSE9Zd3ONYlR05C7i0oNc3jn8Re0hkde/WJ1wyTbR8bcd01rxE3e59nrHWsZNaBJGDFX1rlTxnpGqLz9MJ0NrsonU5v01GuZ+nmCtt+0g5bXAE/1WgEVl7efuLZm8IVlMP1OzVJHsBzWdDGTquLyLjtIuE/CBjMJQ3Gr0G8ncx1t0qPc8T2KRqy83SdhgxmxA70xmjg6rYnbNM5GrLwdJGwwI3agN8ZCnczD6NAcl+nTR8WIlbeDhA1mxA70xug2MmZY3789CSPmmmTEytsd1za4VKfquI5Mqpo7kK0E7ri25sjrVB3leYSGzf081kBubrJyjfI8QsPmfh5roEJBQtL7JG2S9IqkZPVG0hmSnpS0WdIVRfK0hhuXu2F3IJsBxWsSjwHnAz9IJZA0BXwBOBM4DrhI0nEF87WmGoe7YXcgm+1VqE8iIp4AkNQt2QnA5oh4Okv7LeBc4PEieVtDjcMEhMN8ULABE7qZtaujT2IZ0D5kYy5blkvSjKRZSbPbt2+vfOOsZONwNzwuTWZmJViwJiHpe8Abct76VETc2UMeedWM5LjbiFgLrIXWENge1m9NM+p3w6M+9bZZiRYMEhFxWsE85oAVba+XA9sKrtOsOuPQZGZWkjqamx4CVkk6WtKrgAuBdTXkayM0Z32jjEOTmVlJCnVcS/oT4L8DS4HvSnokIk6XdCRwY0ScFRG7JV0KrAemgJsiYlPhLbfu/FBbMaPeZGZWEk/LMa48xYPZRCp7Wg4/cV21YTX5eISOmZXAQaJKw3ooC8bjoTYzGzoHiSoNcx4jT/FgZiVwkKjSMJt8PELHzErgqcKrlHooSwe0mpw8xYOZNZxrElXKa/IBiD319U2YmRXgIDGIXkcszTf5aGr/9/wdC2Y2Ahwk+tXviKXjL4B4Jf89D0c1s4ZzkOjXICOWPBzVzEaUg0S/Bhmx5OGoZjaiHCT6NUitwMNRzWxEeQhsvwadRrqK4agbb201c+2YawWpU69y4DGzUjlI9Gv+Ijzsi7NneTWzGjhIDKIJD6kN83uYzWxiuE9iVHmWVzOrgYPEqPKwWjOrgYPEqPKwWjOrgYPEqPKwWjOrQdHvuH4fcDXwJuCEiMj9rlFJPwP+BdgD7C7zq/UmWhM60M1srBUd3fQYcD7w5R7S/lFE/LJgfmZmVqNCQSIingCQVM7WmJlZo9TVJxHA30raIGmmpjzNzKygBWsSkr4HvCHnrU9FxJ095nNyRGyT9DrgXkk/iYgfJPKbAWYAVq5c2ePqzcysCgsGiYg4rWgmEbEt+/2cpNuBE4DcIBERa4G1ANPT01E0bzMzG1zlzU2SDpb0mvm/gXfT6vA2M7OGKxQkJP2JpDngJOC7ktZny4+UdE+W7PXA30t6FPgH4LsR8TdF8jUzs3oUHd10O3B7zvJtwFnZ308DbymSj5mZDYefuDYzsyQHCTMzS3KQMDOzJAcJMzNLcpAwM7MkBwkzM0tykDAzsyQHCTMzS3KQMDOzJAcJMzNLcpAwM7MkBwkzM0tykDAzsyQHCTMzS3KQMDOzJAcJMzNLcpAwM7MkBwkzM0tykDAzs6RCQULSdZJ+ImmjpNslLUmkO0PSk5I2S7qiSJ5mZlafojWJe4E3R8TxwD8CV3YmkDQFfAE4EzgOuEjScQXzNTOzGhQKEhHxtxGxO3v5ALA8J9kJwOaIeDoifgN8Czi3SL5mZlaPA0tc14eBW3KWLwO2tL2eA96RWomkGWAme/krSU8W2KbDgV8W+P9RNsn7Dt5/7//k7v8xZa5swSAh6XvAG3Le+lRE3Jml+RSwG/hm3ipylkUqv4hYC6xdaLt6IWk2IqbLWNeomeR9B++/939y91/SbJnrWzBIRMRp3d6XdDFwNnBqRORd/OeAFW2vlwPb+tlIMzMbjqKjm84APgmcExEvJ5I9BKySdLSkVwEXAuuK5GtmZvUoOrrp88BrgHslPSLpSwCSjpR0D0DWsX0psB54Arg1IjYVzLdXpTRbjahJ3nfw/nv/J1ep+678FiIzMzM/cW1mZl04SJiZWdJYBolJmAZE0gpJ35f0hKRNkj6WLT9M0r2Snsp+H5otl6QbsjLZKOltw92D4iRNSXpY0t3Z66MlPZjt+y3ZQAkkHZS93py9f9Qwt7sMkpZI+nY2Lc4Tkk6asM/+suy4f0zSzZJePc6fv6SbJD0n6bG2ZX1/3pIuztI/lY1MXdDYBYkJmgZkN/CJiHgTcCLwkWw/rwDui4hVwH3Za2iVx6rsZwb4Yv2bXLqP0RoMMe9a4Pps318ALsmWXwK8EBF/AFyfpRt1fwn8TUQcC7yFVjlMxGcvaRnwUWA6It4MTNEaNTnOn//XgDM6lvX1eUs6DPg0rYeZTwA+PR9YuoqIsfoBTgLWt72+Erhy2NtVw37fCbwLeBI4Ilt2BPBk9veXgYva0u9NN4o/tJ63uQ94J3A3rYc2fwkc2Hkc0BpZd1L294FZOg17Hwrs+2uBZzr3YYI++/lZHA7LPs+7gdPH/fMHjgIeG/TzBi4Cvty2fJ90qZ+xq0mQPw3IsiFtSy2y6vNq4EHg9RHxLED2+3VZsnErl88B/xl4JXv9e8CL8du5xNr3b+++Z+/vyNKPqjcC24H/kTW33SjpYCbks4+IrcB/A34BPEvr89zA5Hz+8/r9vAc6DsYxSPQ1Dciok/S7wHeAj0fES92S5iwbyXKRdDbwXERsaF+ckzR6eG8UHQi8DfhiRKwG/i+/bWrIM1b7nzWRnAscDRwJHEyriaXTuH7+C0nt70DlMI5BYmKmAZG0iFaA+GZE3JYt/idJR2TvHwE8ly0fp3I5GThH0s9ozSr8Tlo1iyWS5qeaad+/vfuevX8I8HydG1yyOWAuIh7MXn+bVtCYhM8e4DTgmYjYHhG7gNuAf8PkfP7z+v28BzoOxjFITMQ0IJIEfBV4IiI+2/bWOmB+1MLFtPoq5pd/IBv5cCKwY76qOmoi4sqIWB4RR9H6fO+PiH8PfB94b5asc9/ny+S9WfqRvZOMiP8DbJE0P9vnqcDjTMBnn/kFcKKk38nOg/n9n4jPv02/n/d64N2SDs1qY+/OlnU37M6Yijp4zqL1JUg/pTVb7dC3qYJ9/Le0qoobgUeyn7NotbXeBzyV/T4sSy9ao75+CvyY1siQoe9HCeVwCnB39vcbgX8ANgP/CzgoW/7q7PXm7P03Dnu7S9jvtwKz2ed/B3DoJH32wGeAnwCPAX8FHDTOnz9wM63+l120agSXDPJ50/pKh83Zz4d6ydvTcpiZWdI4NjeZmVlJHCTMzCzJQcLMzJIcJMzMLMlBwszMkhwkzMwsyUHCzMyS/j91c3QUPaL5vgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x15a827870b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# After feature selection (top 100)\n",
    "\n",
    "plt.scatter(top10_list_x, top10_list_y)\n",
    "plt.scatter(bottom10_list_x, bottom10_list_y)\n",
    "plt.xlim(-50,1000)\n",
    "plt.ylim(-2,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Optimize\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "\n",
    "cs = []\n",
    "ci = 0.01\n",
    "for i in range(4):\n",
    "    ci = 5*ci\n",
    "    cs.append(ci)\n",
    "\n",
    "x_train_s, x_val, y_train_s, y_val = train_test_split(x_train_topx, y_train, test_size=0.2, random_state=42)\n",
    "x_train_s_norm = preprocessing.normalize(x_train_s, norm='l2')\n",
    "x_val_norm = preprocessing.normalize(x_val, norm='l2')\n",
    "\n",
    "opt_c = []\n",
    "for ci in cs:\n",
    "    model = LogisticRegression(penalty='l1', C=ci)\n",
    "    model.fit(x_train_s_norm, y_train_s)\n",
    "    opt_c.append(model.score(x_val_norm, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2,\n",
       " 0.78549999999999998,\n",
       " 0.05,\n",
       " [0.78549999999999998,\n",
       "  0.83550000000000002,\n",
       "  0.84250000000000003,\n",
       "  0.84199999999999997],\n",
       " [0.05, 0.25, 1.25, 6.25])"
      ]
     },
     "execution_count": 546,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(opt_c), opt_c[0], cs[0], opt_c, cs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8435\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression w/ top400 words\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train_s, x_val, y_train_s, y_val = train_test_split(x_train_topx, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "x_train_s_norm = preprocessing.normalize(x_train_s, norm='l2')\n",
    "x_val_norm = preprocessing.normalize(x_val, norm='l2')\n",
    "\n",
    "model = LogisticRegression(penalty='l1', C=3.90625)\n",
    "model.fit(x_train_s_norm, y_train_s)\n",
    "\n",
    "print(model.score(x_val_norm , y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-2, 2)"
      ]
     },
     "execution_count": 560,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x15a824fcf98>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# After feature selection (top 400)\n",
    "\n",
    "plt.scatter(top10_list_x, top10_list_y)\n",
    "plt.scatter(bottom10_list_x, bottom10_list_y)\n",
    "plt.xlim(-50,1000)\n",
    "plt.ylim(-2,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.84875\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression w/ top800 words\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train_s, x_val, y_train_s, y_val = train_test_split(x_train_topx, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "x_train_s_norm = preprocessing.normalize(x_train_s, norm='l2')\n",
    "x_val_norm = preprocessing.normalize(x_val, norm='l2')\n",
    "\n",
    "model = LogisticRegression(penalty='l1', C=3.90625)\n",
    "model.fit(x_train_s_norm, y_train_s)\n",
    "\n",
    "print(model.score(x_val_norm , y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Best Naive Bayes Model (TF-IDF, optimzed Hyperparameters, train on top words)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Explore word co-occurances (increase signal to noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Dylan Preprocessing Datasets\n",
    "\n",
    "from scipy.stats import percentileofscore\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = np.loadtxt('training_data.txt', skiprows=1)\n",
    "\n",
    "x_train = data[:,range(1,1001)]\n",
    "y_train = data[:,0]\n",
    "\n",
    "# 2) Add in verbosity term\n",
    "# prereq: 1\n",
    "verbosity = np.sum(x_train, axis = 1)\n",
    "verbosity = np.ndarray( shape=(20000,1), buffer=verbosity )\n",
    "x_train_verbosity = np.append(x_train, verbosity, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train_verb = x_train_verbosity[:,range(1,1001)]\n",
    "y_train_verb = y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0.,   0.,   0., ...,   0.,   0.,  19.],\n",
       "       [  0.,   0.,   0., ...,   0.,   0.,  61.],\n",
       "       [  3.,   1.,   0., ...,   0.,   0.,  21.],\n",
       "       ..., \n",
       "       [  0.,   1.,   1., ...,   0.,   0.,  39.],\n",
       "       [  4.,   0.,   1., ...,   0.,   0.,  56.],\n",
       "       [  0.,   3.,   0., ...,   0.,   0.,  41.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_verb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test set verbosity\n",
    "\n",
    "data_test = np.loadtxt('test_data.txt', skiprows=1)\n",
    "\n",
    "x_test = data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "verbosity_test = np.sum(x_test, axis = 1)\n",
    "verbosity_test = np.ndarray( shape=(10000,1), buffer=verbosity_test )\n",
    "x_test_verbosity = np.append(x_test, verbosity_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_test_verb = x_test_verbosity[:,range(1,1001)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  3.,   1.,   0., ...,   0.,   0.,  14.],\n",
       "       [  0.,   0.,   1., ...,   0.,   0.,  72.],\n",
       "       [  0.,   0.,   0., ...,   0.,   0.,  31.],\n",
       "       ..., \n",
       "       [  0.,   1.,   0., ...,   0.,   0.,  11.],\n",
       "       [  1.,   0.,   0., ...,   0.,   0.,  23.],\n",
       "       [  1.,   1.,   0., ...,   0.,   0.,  21.]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_verb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.846\n"
     ]
    }
   ],
   "source": [
    "# Verbosity + Logistic Regression\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "x_train_s_verb, x_val_verb, y_train_s_verb, y_val_verb = train_test_split(x_train_verb, y_train_verb, test_size=0.2, random_state=42)\n",
    "\n",
    "x_train_s_norm_verb = preprocessing.normalize(x_train_s_verb, norm='l2')\n",
    "x_val_norm_verb = preprocessing.normalize(x_val_verb, norm='l2')\n",
    "\n",
    "model = LogisticRegression(penalty='l1', C=3.90625)\n",
    "model.fit(x_train_s_norm_verb, y_train_s_verb)\n",
    "\n",
    "print(model.score(x_val_norm_verb, y_val_verb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "0.8565"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'LogisticRegression' object has no attribute 'coef_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-56d2111780ef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mws\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mws\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mws\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'LogisticRegression' object has no attribute 'coef_'"
     ]
    }
   ],
   "source": [
    "ws = model.coef_\n",
    "plt.plot(range(len(ws[0])), ws[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Optimize\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "\n",
    "cs = []\n",
    "ci = 0.01\n",
    "for i in range(6):\n",
    "    ci = 5*ci\n",
    "    cs.append(ci)\n",
    "\n",
    "x_train_s_verb, x_val_verb, y_train_s_verb, y_val_verb = train_test_split(x_train_verb, y_train_verb, test_size=0.2, random_state=42)\n",
    "x_train_s_norm_verb = preprocessing.normalize(x_train_s_verb, norm='l2')\n",
    "x_val_norm_verb = preprocessing.normalize(x_val_verb, norm='l2')\n",
    "\n",
    "opt_c = []\n",
    "for ci in cs:\n",
    "    model = LogisticRegression(penalty='l1', C=ci)\n",
    "    model.fit(x_train_s_norm_verb, y_train_s_verb)\n",
    "    opt_c.append(model.score(x_val_norm_verb, y_val_verb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3,\n",
       " 0.64749999999999996,\n",
       " 0.05,\n",
       " [0.64749999999999996,\n",
       "  0.77324999999999999,\n",
       "  0.83199999999999996,\n",
       "  0.84850000000000003,\n",
       "  0.84499999999999997,\n",
       "  0.84399999999999997],\n",
       " [0.05, 0.25, 1.25, 6.25, 31.25, 156.25])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(opt_c), opt_c[0], cs[0], opt_c, cs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.82575\n"
     ]
    }
   ],
   "source": [
    "# Verbosity + Best Linear SVM\n",
    "\n",
    "from sklearn import svm\n",
    "\n",
    "x_train_s_verb, x_val_verb, y_train_s_verb, y_val_verb = train_test_split(x_train_verb, y_train_verb, test_size=0.2, random_state=42)\n",
    "\n",
    "x_train_s_norm_verb = preprocessing.normalize(x_train_s_verb, norm='l2')\n",
    "x_val_norm_verb = preprocessing.normalize(x_val_verb, norm='l2')\n",
    "\n",
    "clf = svm.SVC(C=1, kernel='linear')\n",
    "clf.fit(x_train_s_norm_verb, y_train_s_verb)\n",
    "\n",
    "print(clf.score(x_val_norm_verb, y_val_verb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Normalize data\n",
    "\n",
    "x_train_norm_verb = preprocessing.normalize(x_train_verb, norm='l2')\n",
    "x_test_norm_verb = preprocessing.normalize(x_test_verb, norm='l2')\n",
    "\n",
    "# Optimal Logistic Regression (Verbosity)\n",
    "\n",
    "model = LogisticRegression(penalty='l1', C=ci)\n",
    "model.fit(x_train_norm_verb, y_train_verb)\n",
    "\n",
    "y_pred = clf.predict(x_test_norm_verb)\n",
    "\n",
    "submission = pd.DataFrame({'Id': range(1, len(x_test)+1), 'Prediction': [int(x) for x in y_pred]})\n",
    "print(submission.head(10))\n",
    "\n",
    "submission.to_csv('submission_opt_log_reg_verbosity.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Best SVM score\n",
    "\n",
    "0.8495"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "original_training_data = np.loadtxt(\"training_data.txt\", skiprows=1)\n",
    "train = original_training_data\n",
    "\n",
    "# 4) Add in vocabulary size (% words from entire corpus present in review)\n",
    "# prereq: 1\n",
    "train_binary = np.where(train[:,1:] > 0, 1, 0)\n",
    "raw_vocab = np.sum(train_binary, axis=1)\n",
    "vocab = raw_vocab/1000\n",
    "vocab = np.ndarray( shape=(20000,1), buffer=vocab )\n",
    "train_vocab = np.append( train, vocab, axis=1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train_vocab = train_vocab[:,range(1,1002)]\n",
    "y_train_vocab = train_vocab[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.   ,  0.   ,  0.   , ...,  0.   ,  0.   ,  0.017],\n",
       "       [ 3.   ,  0.   ,  0.   , ...,  0.   ,  0.   ,  0.044],\n",
       "       [ 0.   ,  3.   ,  1.   , ...,  0.   ,  0.   ,  0.016],\n",
       "       ..., \n",
       "       [ 3.   ,  0.   ,  1.   , ...,  0.   ,  0.   ,  0.034],\n",
       "       [ 2.   ,  4.   ,  0.   , ...,  0.   ,  0.   ,  0.042],\n",
       "       [ 0.   ,  0.   ,  3.   , ...,  0.   ,  0.   ,  0.037]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Test data\n",
    "\n",
    "data_test = np.loadtxt('test_data.txt', skiprows=1)\n",
    "test = data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_binary = np.where(test[:,1:] > 0, 1, 0)\n",
    "raw_vocab = np.sum(test_binary, axis=1)\n",
    "vocab = raw_vocab/1000\n",
    "vocab = np.ndarray( shape=(10000,1), buffer=vocab )\n",
    "x_test_vocab = np.append( test, vocab, axis=1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 662,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1001,)"
      ]
     },
     "execution_count": 662,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_vocab[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 663,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1001,)"
      ]
     },
     "execution_count": 663,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_vocab[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "3.90625"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.85025\n"
     ]
    }
   ],
   "source": [
    "# Vocab Size + Logistic Regression\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "x_train_s_vocab, x_val_vocab, y_train_s_vocab, y_val_vocab = train_test_split(x_train_vocab, y_train_vocab, test_size=0.2, random_state=42)\n",
    "\n",
    "x_train_s_norm_vocab = preprocessing.normalize(x_train_s_vocab, norm='l2')\n",
    "x_val_norm_vocab = preprocessing.normalize(x_val_vocab, norm='l2')\n",
    "\n",
    "model = LogisticRegression(penalty='l1', C=3.3)\n",
    "model.fit(x_train_s_norm_vocab, y_train_s_vocab)\n",
    "\n",
    "print(model.score(x_val_norm_vocab, y_val_vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Id  Prediction\n",
      "0   1           1\n",
      "1   2           1\n",
      "2   3           0\n",
      "3   4           0\n",
      "4   5           0\n",
      "5   6           0\n",
      "6   7           1\n",
      "7   8           1\n",
      "8   9           1\n",
      "9  10           0\n"
     ]
    }
   ],
   "source": [
    "# Normalize data\n",
    "\n",
    "x_train_norm_vocab = preprocessing.normalize(x_train_vocab, norm='l2')\n",
    "x_test_norm_vocab = preprocessing.normalize(x_test_vocab, norm='l2')\n",
    "\n",
    "# Optimal Logistic Regression (Verbosity)\n",
    "\n",
    "model = LogisticRegression(penalty='l1', C=3.3)\n",
    "model.fit(x_train_norm_vocab, y_train_vocab)\n",
    "\n",
    "y_pred = model.predict(x_test_norm_vocab)\n",
    "\n",
    "submission = pd.DataFrame({'Id': range(1, len(x_test)+1), 'Prediction': [int(x) for x in y_pred]})\n",
    "print(submission.head(10))\n",
    "\n",
    "submission.to_csv('submission_opt_log_reg_vocab_size.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Optimize\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "\n",
    "cs = []\n",
    "ci = 0.01\n",
    "for i in range(6):\n",
    "    ci = 5*ci\n",
    "    cs.append(ci)\n",
    "\n",
    "x_train_s_vocab, x_val_vocab, y_train_s_vocab, y_val_vocab = train_test_split(x_train_vocab, y_train_vocab, test_size=0.2, random_state=42)\n",
    "x_train_s_norm_vocab = preprocessing.normalize(x_train_s_vocab, norm='l2')\n",
    "x_val_norm_vocab = preprocessing.normalize(x_val_vocab, norm='l2')\n",
    "\n",
    "opt_c = []\n",
    "for ci in cs:\n",
    "    model = LogisticRegression(penalty='l1', C=ci)\n",
    "    model.fit(x_train_s_norm_vocab, y_train_s_vocab)\n",
    "    opt_c.append(model.score(x_val_norm_vocab, y_val_vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3,\n",
       " 0.76700000000000002,\n",
       " 0.05,\n",
       " [0.76700000000000002,\n",
       "  0.82674999999999998,\n",
       "  0.84799999999999998,\n",
       "  0.84975000000000001,\n",
       "  0.84824999999999995,\n",
       "  0.84699999999999998],\n",
       " [0.05, 0.25, 1.25, 6.25, 31.25, 156.25])"
      ]
     },
     "execution_count": 619,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(opt_c), opt_c[0], cs[0], opt_c, cs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Prediction0</th>\n",
       "      <th>Prediction1</th>\n",
       "      <th>Prediction2</th>\n",
       "      <th>Prediction3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Id  Prediction0  Prediction1  Prediction2  Prediction3\n",
       "0    1            1            1            1            1\n",
       "1    2            1            1            1            1\n",
       "2    3            0            0            1            0\n",
       "3    4            0            0            0            0\n",
       "4    5            0            0            1            1\n",
       "5    6            0            0            0            0\n",
       "6    7            1            1            1            1\n",
       "7    8            1            1            1            1\n",
       "8    9            1            1            1            1\n",
       "9   10            0            0            0            0\n",
       "10  11            1            1            1            1\n",
       "11  12            0            1            1            1\n",
       "12  13            1            1            1            0\n",
       "13  14            0            0            0            0\n",
       "14  15            0            0            0            0\n",
       "15  16            1            1            1            1\n",
       "16  17            0            0            0            0\n",
       "17  18            0            0            0            0\n",
       "18  19            1            1            1            1\n",
       "19  20            0            0            1            0\n",
       "20  21            0            0            0            0\n",
       "21  22            1            1            1            1\n",
       "22  23            1            1            1            1\n",
       "23  24            1            1            0            0\n",
       "24  25            0            0            0            0\n",
       "25  26            1            1            0            1\n",
       "26  27            0            0            0            0\n",
       "27  28            0            0            0            0\n",
       "28  29            0            0            0            0\n",
       "29  30            1            1            1            1"
      ]
     },
     "execution_count": 588,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stack Logistic Regression, Random Forest, LinearSVM, Multinomial NB\n",
    "\n",
    "# Majority Stacking\n",
    "\n",
    "import os\n",
    "\n",
    "sub_path = \"submissions/\"\n",
    "all_files = os.listdir(sub_path)\n",
    "\n",
    "# Read and concatenate submissions\n",
    "outs = [pd.read_csv(os.path.join(sub_path, f), index_col=0) for f in all_files]\n",
    "concat_sub = pd.concat(outs, axis=1)\n",
    "cols = list(map(lambda x: \"Prediction\" + str(x), range(len(concat_sub.columns))))\n",
    "concat_sub.columns = cols\n",
    "concat_sub.reset_index(inplace=True)\n",
    "concat_sub.head(n=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 596,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0])"
      ]
     },
     "execution_count": 596,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictDF = np.array(concat_sub.iloc[:, 1:5])\n",
    "predictDF[0:5, ] #.head()\n",
    "majority = np.mean(predictDF, axis=1)\n",
    "majority[0:5]\n",
    "stacked = (majority > 0.5) + 0\n",
    "stacked[0:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 597,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Id  Prediction\n",
      "0   1           1\n",
      "1   2           1\n",
      "2   3           0\n",
      "3   4           0\n",
      "4   5           0\n",
      "5   6           0\n",
      "6   7           1\n",
      "7   8           1\n",
      "8   9           1\n",
      "9  10           0\n"
     ]
    }
   ],
   "source": [
    "# Majority stack\n",
    "\n",
    "submission = pd.DataFrame({'Id': range(1, len(x_test)+1), 'Prediction': [int(x) for x in stacked]})\n",
    "print(submission.head(10))\n",
    "\n",
    "submission.to_csv('submission_majority_stack_svm_logreg_rfo_Multinomial_NB.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 607,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Prediction0</th>\n",
       "      <th>Prediction1</th>\n",
       "      <th>Prediction2</th>\n",
       "      <th>Prediction3</th>\n",
       "      <th>Prediction4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Id  Prediction0  Prediction1  Prediction2  Prediction3  Prediction4\n",
       "0    1            1            1            1            1            1\n",
       "1    2            1            1            1            1            1\n",
       "2    3            0            0            0            1            0\n",
       "3    4            0            0            0            0            0\n",
       "4    5            0            0            0            1            1\n",
       "5    6            0            0            0            0            0\n",
       "6    7            1            1            1            1            1\n",
       "7    8            1            1            1            1            1\n",
       "8    9            1            1            1            1            1\n",
       "9   10            0            0            0            0            0\n",
       "10  11            1            1            1            1            1\n",
       "11  12            0            0            1            1            1\n",
       "12  13            1            1            1            1            0\n",
       "13  14            0            0            0            0            0\n",
       "14  15            0            0            0            0            0\n",
       "15  16            1            1            1            1            1\n",
       "16  17            0            0            0            0            0\n",
       "17  18            0            0            0            0            0\n",
       "18  19            1            1            1            1            1\n",
       "19  20            0            0            0            1            0\n",
       "20  21            0            0            0            0            0\n",
       "21  22            1            1            1            1            1\n",
       "22  23            1            1            1            1            1\n",
       "23  24            1            1            1            0            0\n",
       "24  25            0            0            0            0            0\n",
       "25  26            1            1            1            0            1\n",
       "26  27            0            0            0            0            0\n",
       "27  28            0            0            0            0            0\n",
       "28  29            0            0            0            0            0\n",
       "29  30            1            1            1            1            1"
      ]
     },
     "execution_count": 607,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stack Logistic Regression, Random Forest, LinearSVM, GBM\n",
    "\n",
    "# Majority Stacking\n",
    "\n",
    "import os\n",
    "\n",
    "sub_path = \"submissions/\"\n",
    "all_files = os.listdir(sub_path)\n",
    "\n",
    "# Read and concatenate submissions\n",
    "outs = [pd.read_csv(os.path.join(sub_path, f), index_col=0) for f in all_files]\n",
    "concat_sub = pd.concat(outs, axis=1)\n",
    "cols = list(map(lambda x: \"Prediction\" + str(x), range(len(concat_sub.columns))))\n",
    "concat_sub.columns = cols\n",
    "concat_sub.reset_index(inplace=True)\n",
    "concat_sub.head(n=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 608,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0])"
      ]
     },
     "execution_count": 608,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictDF = np.array(concat_sub.iloc[:, 1:5])\n",
    "predictDF[0:5, ] #.head()\n",
    "majority = np.mean(predictDF, axis=1)\n",
    "majority[0:5]\n",
    "stacked = (majority > 0.5) + 0\n",
    "stacked[0:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 609,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Id  Prediction\n",
      "0   1           1\n",
      "1   2           1\n",
      "2   3           0\n",
      "3   4           0\n",
      "4   5           0\n",
      "5   6           0\n",
      "6   7           1\n",
      "7   8           1\n",
      "8   9           1\n",
      "9  10           0\n"
     ]
    }
   ],
   "source": [
    "# Majority stack\n",
    "\n",
    "submission = pd.DataFrame({'Id': range(1, len(x_test)+1), 'Prediction': [int(x) for x in stacked]})\n",
    "print(submission.head(10))\n",
    "\n",
    "submission.to_csv('submission_majority_stack_svm_logreg_rfo_GBM.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 610,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Prediction0</th>\n",
       "      <th>Prediction1</th>\n",
       "      <th>Prediction2</th>\n",
       "      <th>Prediction3</th>\n",
       "      <th>Prediction4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Id  Prediction0  Prediction1  Prediction2  Prediction3  Prediction4\n",
       "0    1            1            1            1            1            1\n",
       "1    2            1            1            1            1            1\n",
       "2    3            0            0            0            1            0\n",
       "3    4            0            0            0            0            0\n",
       "4    5            0            0            0            1            1\n",
       "5    6            0            0            0            0            0\n",
       "6    7            1            1            1            1            1\n",
       "7    8            1            1            1            1            1\n",
       "8    9            1            1            1            1            1\n",
       "9   10            0            0            0            0            0\n",
       "10  11            1            1            1            1            1\n",
       "11  12            0            0            1            1            1\n",
       "12  13            1            1            1            1            0\n",
       "13  14            0            0            0            0            0\n",
       "14  15            0            0            0            0            0\n",
       "15  16            1            1            1            1            1\n",
       "16  17            0            0            0            0            0\n",
       "17  18            0            0            0            0            0\n",
       "18  19            1            1            1            1            1\n",
       "19  20            0            0            0            1            0\n",
       "20  21            0            0            0            0            0\n",
       "21  22            1            1            1            1            1\n",
       "22  23            1            1            1            1            1\n",
       "23  24            1            1            1            0            0\n",
       "24  25            0            0            0            0            0\n",
       "25  26            1            1            1            0            1\n",
       "26  27            0            0            0            0            0\n",
       "27  28            0            0            0            0            0\n",
       "28  29            0            0            0            0            0\n",
       "29  30            1            1            1            1            1"
      ]
     },
     "execution_count": 610,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stack Logistic Regression, Random Forest, LinearSVM, GBM, Multinomial NB\n",
    "\n",
    "# Majority Stacking\n",
    "\n",
    "import os\n",
    "\n",
    "sub_path = \"submissions/\"\n",
    "all_files = os.listdir(sub_path)\n",
    "\n",
    "# Read and concatenate submissions\n",
    "outs = [pd.read_csv(os.path.join(sub_path, f), index_col=0) for f in all_files]\n",
    "concat_sub = pd.concat(outs, axis=1)\n",
    "cols = list(map(lambda x: \"Prediction\" + str(x), range(len(concat_sub.columns))))\n",
    "concat_sub.columns = cols\n",
    "concat_sub.reset_index(inplace=True)\n",
    "concat_sub.head(n=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 611,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0])"
      ]
     },
     "execution_count": 611,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictDF = np.array(concat_sub.iloc[:, 1:6])\n",
    "predictDF[0:5, ] #.head()\n",
    "majority = np.mean(predictDF, axis=1)\n",
    "majority[0:5]\n",
    "stacked = (majority > 0.5) + 0\n",
    "stacked[0:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 612,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Id  Prediction\n",
      "0   1           1\n",
      "1   2           1\n",
      "2   3           0\n",
      "3   4           0\n",
      "4   5           0\n",
      "5   6           0\n",
      "6   7           1\n",
      "7   8           1\n",
      "8   9           1\n",
      "9  10           0\n"
     ]
    }
   ],
   "source": [
    "# Majority stack\n",
    "\n",
    "submission = pd.DataFrame({'Id': range(1, len(x_test)+1), 'Prediction': [int(x) for x in stacked]})\n",
    "print(submission.head(10))\n",
    "\n",
    "submission.to_csv('submission_majority_stack_svm_logreg_rfo_GBM_Mulinomial_Bayes.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Prediction0</th>\n",
       "      <th>Prediction1</th>\n",
       "      <th>Prediction2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Id  Prediction0  Prediction1  Prediction2\n",
       "0    1            1            1            1\n",
       "1    2            1            1            1\n",
       "2    3            0            0            0\n",
       "3    4            0            0            0\n",
       "4    5            0            0            1\n",
       "5    6            0            0            0\n",
       "6    7            1            1            1\n",
       "7    8            1            1            1\n",
       "8    9            1            1            1\n",
       "9   10            0            0            0\n",
       "10  11            1            1            1\n",
       "11  12            0            1            1\n",
       "12  13            1            1            0\n",
       "13  14            0            0            0\n",
       "14  15            0            0            0\n",
       "15  16            1            1            1\n",
       "16  17            0            0            0\n",
       "17  18            0            0            0\n",
       "18  19            1            1            1\n",
       "19  20            0            0            0\n",
       "20  21            0            0            0\n",
       "21  22            1            1            1\n",
       "22  23            1            1            1\n",
       "23  24            1            1            0\n",
       "24  25            0            0            0\n",
       "25  26            1            1            1\n",
       "26  27            0            0            0\n",
       "27  28            0            0            0\n",
       "28  29            0            0            0\n",
       "29  30            1            1            1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stack Logistic Regression (vocab size), Random Forest, LinearSVM\n",
    "\n",
    "# Majority Stacking\n",
    "\n",
    "import os\n",
    "\n",
    "sub_path = \"submissions/\"\n",
    "all_files = os.listdir(sub_path)\n",
    "\n",
    "# Read and concatenate submissions\n",
    "outs = [pd.read_csv(os.path.join(sub_path, f), index_col=0) for f in all_files]\n",
    "concat_sub = pd.concat(outs, axis=1)\n",
    "cols = list(map(lambda x: \"Prediction\" + str(x), range(len(concat_sub.columns))))\n",
    "concat_sub.columns = cols\n",
    "concat_sub.reset_index(inplace=True)\n",
    "concat_sub.head(n=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictDF = np.array(concat_sub.iloc[:, 1:6])\n",
    "predictDF[0:5, ] #.head()\n",
    "majority = np.mean(predictDF, axis=1)\n",
    "majority[0:5]\n",
    "stacked = (majority > 0.5) + 0\n",
    "stacked[0:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Id  Prediction\n",
      "0   1           1\n",
      "1   2           1\n",
      "2   3           0\n",
      "3   4           0\n",
      "4   5           0\n",
      "5   6           0\n",
      "6   7           1\n",
      "7   8           1\n",
      "8   9           1\n",
      "9  10           0\n"
     ]
    }
   ],
   "source": [
    "# Majority stack\n",
    "\n",
    "submission = pd.DataFrame({'Id': range(1, len(x_test)+1), 'Prediction': [int(x) for x in stacked]})\n",
    "print(submission.head(10))\n",
    "\n",
    "submission.to_csv('submission_majority_stack_svm_logreg_vocab_size_rfo.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Prediction0</th>\n",
       "      <th>Prediction1</th>\n",
       "      <th>Prediction2</th>\n",
       "      <th>Prediction3</th>\n",
       "      <th>Prediction4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  Prediction0  Prediction1  Prediction2  Prediction3  Prediction4\n",
       "0   1            1            1            1            1            1\n",
       "1   2            1            1            1            1            1\n",
       "2   3            0            0            0            0            0\n",
       "3   4            0            0            0            0            0\n",
       "4   5            0            0            0            0            1\n",
       "5   6            0            0            0            0            0\n",
       "6   7            1            1            1            1            1\n",
       "7   8            1            1            1            1            1\n",
       "8   9            1            1            1            1            1\n",
       "9  10            0            0            0            0            0"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stack Logistic Regression, Random Forest, LinearSVM times 2, NN\n",
    "\n",
    "# Majority Stacking\n",
    "\n",
    "import os\n",
    "\n",
    "sub_path = \"submissions/\"\n",
    "all_files = os.listdir(sub_path)\n",
    "\n",
    "# Read and concatenate submissions\n",
    "outs = [pd.read_csv(os.path.join(sub_path, f), index_col=0) for f in all_files]\n",
    "concat_sub = pd.concat(outs, axis=1)\n",
    "cols = list(map(lambda x: \"Prediction\" + str(x), range(len(concat_sub.columns))))\n",
    "concat_sub.columns = cols\n",
    "concat_sub.reset_index(inplace=True)\n",
    "concat_sub.head(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Prediction0</th>\n",
       "      <th>Prediction1</th>\n",
       "      <th>Prediction2</th>\n",
       "      <th>Prediction3</th>\n",
       "      <th>Prediction4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.005802</td>\n",
       "      <td>0.006020</td>\n",
       "      <td>0.000389</td>\n",
       "      <td>0.005802</td>\n",
       "      <td>0.017638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Prediction0</th>\n",
       "      <td>0.005802</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.905069</td>\n",
       "      <td>0.906198</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.786237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Prediction1</th>\n",
       "      <td>0.006020</td>\n",
       "      <td>0.905069</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.887909</td>\n",
       "      <td>0.905069</td>\n",
       "      <td>0.768188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Prediction2</th>\n",
       "      <td>0.000389</td>\n",
       "      <td>0.906198</td>\n",
       "      <td>0.887909</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.906198</td>\n",
       "      <td>0.762519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Prediction3</th>\n",
       "      <td>0.005802</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.905069</td>\n",
       "      <td>0.906198</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.786237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Prediction4</th>\n",
       "      <td>0.017638</td>\n",
       "      <td>0.786237</td>\n",
       "      <td>0.768188</td>\n",
       "      <td>0.762519</td>\n",
       "      <td>0.786237</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Id  Prediction0  Prediction1  Prediction2  Prediction3  \\\n",
       "Id           1.000000     0.005802     0.006020     0.000389     0.005802   \n",
       "Prediction0  0.005802     1.000000     0.905069     0.906198     1.000000   \n",
       "Prediction1  0.006020     0.905069     1.000000     0.887909     0.905069   \n",
       "Prediction2  0.000389     0.906198     0.887909     1.000000     0.906198   \n",
       "Prediction3  0.005802     1.000000     0.905069     0.906198     1.000000   \n",
       "Prediction4  0.017638     0.786237     0.768188     0.762519     0.786237   \n",
       "\n",
       "             Prediction4  \n",
       "Id              0.017638  \n",
       "Prediction0     0.786237  \n",
       "Prediction1     0.768188  \n",
       "Prediction2     0.762519  \n",
       "Prediction3     0.786237  \n",
       "Prediction4     1.000000  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check correlation\n",
    "\n",
    "concat_sub.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictDF = np.array(concat_sub.iloc[:, 1:7])\n",
    "predictDF[0:5, ] #.head()\n",
    "majority = np.mean(predictDF, axis=1)\n",
    "majority[0:5]\n",
    "stacked = (majority > 0.5) + 0\n",
    "stacked[0:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Id  Prediction\n",
      "0   1           1\n",
      "1   2           1\n",
      "2   3           0\n",
      "3   4           0\n",
      "4   5           0\n",
      "5   6           0\n",
      "6   7           1\n",
      "7   8           1\n",
      "8   9           1\n",
      "9  10           0\n"
     ]
    }
   ],
   "source": [
    "# Majority stack\n",
    "\n",
    "submission = pd.DataFrame({'Id': range(1, len(x_test)+1), 'Prediction': [int(x) for x in stacked]})\n",
    "print(submission.head(10))\n",
    "\n",
    "submission.to_csv('submission_majority_stack_2svm__logreg_rfo_NN.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Stacking Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Normalize data\n",
    "x_train_s, x_val, y_train_s, y_val = train_test_split(x_train_top, y_train, test_size=0.2, random_state=42)\n",
    "x_train_s_norm = preprocessing.normalize(x_train_s, norm='l2')\n",
    "x_val_norm = preprocessing.normalize(x_val, norm='l2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Id  Prediction\n",
      "0   1           0\n",
      "1   2           0\n",
      "2   3           0\n",
      "3   4           1\n",
      "4   5           1\n",
      "5   6           1\n",
      "6   7           1\n",
      "7   8           0\n",
      "8   9           0\n",
      "9  10           1\n"
     ]
    }
   ],
   "source": [
    "# Best Logistic Regression Model\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Normalize data\n",
    "x_train_norm = preprocessing.normalize(x_train, norm='l2')\n",
    "x_test_norm = preprocessing.normalize(x_test, norm='l2')\n",
    "\n",
    "model1 = LogisticRegression(penalty='l1', C=3.90625)\n",
    "model1.fit(x_train_s_norm, y_train_s)\n",
    "\n",
    "y_pred = model1.predict(x_val_norm)\n",
    "\n",
    "submission = pd.DataFrame({'Id': range(1, len(x_val_norm)+1), 'Prediction': [int(x) for x in y_pred]})\n",
    "print(submission.head(10))\n",
    "\n",
    "submission.to_csv('submissions_CV/stack1/submission_logistic_regression_CV.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Id  Prediction\n",
      "0   1           0\n",
      "1   2           0\n",
      "2   3           0\n",
      "3   4           1\n",
      "4   5           1\n",
      "5   6           0\n",
      "6   7           1\n",
      "7   8           0\n",
      "8   9           0\n",
      "9  10           1\n"
     ]
    }
   ],
   "source": [
    "# Best Random Forest\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Normalize data\n",
    "\n",
    "x_train_norm = preprocessing.normalize(x_train, norm='l2')\n",
    "x_test_norm = preprocessing.normalize(x_test, norm='l2')\n",
    "\n",
    "model2 = RandomForestClassifier(n_estimators=1000)\n",
    "model2.fit(x_train_s_norm, y_train_s)\n",
    "\n",
    "y_pred = model2.predict(x_val_norm)\n",
    "\n",
    "submission = pd.DataFrame({'Id': range(1, len(x_val_norm)+1), 'Prediction': [int(x) for x in y_pred]})\n",
    "print(submission.head(10))\n",
    "\n",
    "submission.to_csv('submissions_CV/stack1/submission_optimal_rfo_CV.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Id  Prediction\n",
      "0   1           0\n",
      "1   2           0\n",
      "2   3           0\n",
      "3   4           1\n",
      "4   5           1\n",
      "5   6           1\n",
      "6   7           1\n",
      "7   8           0\n",
      "8   9           0\n",
      "9  10           1\n"
     ]
    }
   ],
   "source": [
    "# Best SVC\n",
    "\n",
    "from sklearn import svm\n",
    "\n",
    "model3 = svm.SVC(C=1, kernel='linear')\n",
    "model3.fit(x_train_s_norm, y_train_s)\n",
    "\n",
    "y_pred = model3.predict(x_val_norm)\n",
    "\n",
    "submission = pd.DataFrame({'Id': range(1, len(x_val_norm)+1), 'Prediction': [int(x) for x in y_pred]})\n",
    "print(submission.head(10))\n",
    "\n",
    "submission.to_csv('submissions_CV/stack1/submission_optimal_SVC_CV.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "16000/16000 [==============================] - 5s 296us/step - loss: 0.7040 - acc: 0.5305\n",
      "Epoch 2/5\n",
      "16000/16000 [==============================] - 4s 248us/step - loss: 0.6531 - acc: 0.6123\n",
      "Epoch 3/5\n",
      "16000/16000 [==============================] - 4s 259us/step - loss: 0.5728 - acc: 0.6996\n",
      "Epoch 4/5\n",
      "16000/16000 [==============================] - 4s 237us/step - loss: 0.5129 - acc: 0.7445\n",
      "Epoch 5/5\n",
      "16000/16000 [==============================] - 4s 240us/step - loss: 0.4726 - acc: 0.7751\n",
      "   Id  Prediction\n",
      "0   1           0\n",
      "1   2           0\n",
      "2   3           0\n",
      "3   4           1\n",
      "4   5           1\n",
      "5   6           1\n",
      "6   7           1\n",
      "7   8           1\n",
      "8   9           0\n",
      "9  10           1\n"
     ]
    }
   ],
   "source": [
    "# Best NN\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "\n",
    "model4 = Sequential()\n",
    "model4.add(Dense(120, input_shape=(1000,)))\n",
    "model4.add(Activation('sigmoid'))\n",
    "model4.add(Dropout(0.7))\n",
    "model4.add(Dense(20))\n",
    "model4.add(Activation('sigmoid'))\n",
    "\n",
    "model4.add(Dense(2))\n",
    "model4.add(Activation('softmax'))\n",
    "    \n",
    "model4.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "    \n",
    "model4.fit(x_train_s_norm, y_train_s_hot, epochs=5, batch_size=32, verbose=1)\n",
    "\n",
    "y_pred = model4.predict_classes(x_val_norm)\n",
    "\n",
    "submission = pd.DataFrame({'Id': range(1, len(x_val_norm)+1), 'Prediction': [int(x) for x in y_pred]})\n",
    "print(submission.head(10))\n",
    "\n",
    "submission.to_csv('submissions_CV/stack1/submission_optimal_Dense_NN_CV.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best Naive Bayes\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "# from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "label_weights = pd.read_csv(\"./Logistic_L1_weights_229.txt\", delimiter=\"\\t\")\n",
    "\n",
    "def NBayesCrossVal(whichweights, X_orig, Y_orig, laplace=1, kfold=5, modeltype='multinomial'):\n",
    "    \n",
    "    N, D = X_orig.shape\n",
    "    nhypers = whichweights.shape[0] # nhypers X nweights\n",
    "    models = []\n",
    "    val_scores = []\n",
    "\n",
    "    for hyper in range(nhypers): \n",
    "        theseweights = whichweights[hyper, :]\n",
    "        X = X_orig[:, theseweights.astype('bool')]\n",
    "        if modeltype == 'bernoulli':\n",
    "            model = BernoulliNB(alpha=1.0, fit_prior=True)\n",
    "        elif modeltype == 'multinomial':\n",
    "            model = MultinomialNB(alpha=1.0, fit_prior=True)\n",
    "        scores = cross_val_score(model, X, Y_orig, cv=kfold)\n",
    "        models.append(model)\n",
    "        val_scores.append(scores)\n",
    "        \n",
    "    val_scores = np.array(val_scores)\n",
    "    mean_val_scores = np.mean(val_scores, axis=1)\n",
    "    hyper_best_i = np.argmax(mean_val_scores)\n",
    "    print(hyper_best_i, mean_val_scores[hyper_best_i]) #c_best,\n",
    "    \n",
    "    return val_scores, mean_val_scores, hyper_best_i, models\n",
    "\n",
    "nhypers = 20\n",
    "Qs = np.linspace(60, 65, nhypers) # 0.1% of 1000 is 1\n",
    "whichweights = np.zeros((nhypers, x_train_s.shape[1]))\n",
    "abs_weights = np.absolute(label_weights.weights)\n",
    "for i, Q in enumerate(Qs):\n",
    "    cutoff = np.percentile(a=abs_weights, q=Q)\n",
    "    whichweights[i, :] = np.greater_equal(abs_weights, cutoff)\n",
    "\n",
    "percentiles = [np.percentile(a=np.absolute(label_weights.weights), q=Q) for Q in Qs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19 0.851623998028\n"
     ]
    }
   ],
   "source": [
    "val_scores, mean_val_scores, hyper_best_i, models = NBayesCrossVal(whichweights, x_train_s, y_train_s, 1, 5, 'multinomial')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.202192206491\n",
      "65.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x129e3be80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(percentiles[hyper_best_i])\n",
    "print(Qs[hyper_best_i])\n",
    "plt.plot(Qs, mean_val_scores)\n",
    "plt.show()\n",
    "bestweights = whichweights[hyper_best_i, :] #models[33] # No, all the models are the same!\n",
    "bestmodel = models[0] # All the models are the same!\n",
    "bestmatrix = x_train_s[:, bestweights.astype('bool')]\n",
    "bestmodel.fit(bestmatrix, y_train_s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Id  Prediction\n",
      "0   1           0\n",
      "1   2           0\n",
      "2   3           0\n",
      "3   4           1\n",
      "4   5           1\n",
      "5   6           1\n",
      "6   7           1\n",
      "7   8           0\n",
      "8   9           0\n",
      "9  10           1\n"
     ]
    }
   ],
   "source": [
    "y_pred = bestmodel.predict(x_val[:, bestweights.astype('bool')])\n",
    "\n",
    "submission = pd.DataFrame({'Id': range(1, len(x_val_norm)+1), 'Prediction': [int(x) for x in y_pred]})\n",
    "print(submission.head(10))\n",
    "\n",
    "submission.to_csv('submissions_CV/stack1/submission_optimal_Naive_Bayes_Eric_CV.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dylan Logistic Regression\n",
    "\n",
    "# Copied from his ...reg_optimal.py\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "# Import training data\n",
    "original_training_data = np.loadtxt(\"training_data.txt\", skiprows=1)\n",
    "# Import test data\n",
    "original_test_data = np.loadtxt(\"test_data.txt\", skiprows=1)\n",
    "# Produce joint tf-idf-generating dataset\n",
    "pre_tf_idf = np.append(original_training_data[:,1:], original_test_data, axis=0)\n",
    "\n",
    "# Compute tf-idf\n",
    "tfidf_trans = TfidfTransformer()\n",
    "full_tf_idf = tfidf_trans.fit_transform(pre_tf_idf)\n",
    "full_tf_idf = full_tf_idf.toarray()\n",
    "\n",
    "# Reconstitute training data\n",
    "train_labels = original_training_data[:,0]\n",
    "train_labels = train_labels.reshape(20000,1)\n",
    "training_tf_idf = np.append(train_labels, full_tf_idf[0:20000,:], axis=1)\n",
    "\n",
    "# Reconstitute test data\n",
    "test_tf_idf = full_tf_idf[20000:, :]\n",
    "\n",
    "# Train model on tf-idf training data\n",
    "training_x = training_tf_idf[:,1:]\n",
    "training_y = training_tf_idf[:,0]\n",
    "\n",
    "# END copy\n",
    "# Now rename variables to match the rest of this notebook\n",
    "\n",
    "x_train_s_tfifd, x_val_tfifd, y_train_s_tfifd, y_val_tfifd = train_test_split(training_x, training_y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.9483, class_weight=None, dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
       "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression(penalty='l2', C = 0.9483) #0.975\n",
    "model.fit(x_train_s_tfifd, y_train_s_tfifd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Id  Prediction\n",
      "0   1           0\n",
      "1   2           0\n",
      "2   3           0\n",
      "3   4           1\n",
      "4   5           1\n",
      "5   6           1\n",
      "6   7           1\n",
      "7   8           0\n",
      "8   9           0\n",
      "9  10           1\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(x_val_tfifd)\n",
    "\n",
    "submission = pd.DataFrame({'Id': range(1, len(x_val_norm)+1), 'Prediction': [int(x) for x in y_pred]})\n",
    "print(submission.head(10))\n",
    "\n",
    "submission.to_csv('submissions_CV/stack1/submission_optimal_Dylan_TFIFDall_0.9483_CV.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stacking Prediction: Logistic Regression, Random Forest, SVM*2, NN\n",
    "\n",
    "import os\n",
    "\n",
    "sub_path = \"submissions_CV/stack1/\"\n",
    "all_files = os.listdir(sub_path)\n",
    "\n",
    "# Read and concatenate submissions\n",
    "outs = [pd.read_csv(os.path.join(sub_path, f), index_col=0) for f in all_files]\n",
    "concat_sub = pd.concat(outs, axis=1)\n",
    "cols = list(map(lambda x: \"Prediction\" + str(x), range(len(concat_sub.columns))))\n",
    "concat_sub.columns = cols\n",
    "concat_sub.reset_index(inplace=True)\n",
    "\n",
    "predictDF = np.array(concat_sub.iloc[:, 1:7])\n",
    "majority = np.mean(predictDF, axis=1)\n",
    "stacked = (majority > 0.5) + 0\n",
    "\n",
    "y_pred = stacked\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.85150000000000003"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_val, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stacking Prediction: Logistic Regression, Random Forest, SVM\n",
    "\n",
    "import os\n",
    "\n",
    "sub_path = \"submissions_CV/stack2/\"\n",
    "all_files = os.listdir(sub_path)\n",
    "\n",
    "# Read and concatenate submissions\n",
    "outs = [pd.read_csv(os.path.join(sub_path, f), index_col=0) for f in all_files]\n",
    "concat_sub = pd.concat(outs, axis=1)\n",
    "cols = list(map(lambda x: \"Prediction\" + str(x), range(len(concat_sub.columns))))\n",
    "concat_sub.columns = cols\n",
    "concat_sub.reset_index(inplace=True)\n",
    "\n",
    "predictDF = np.array(concat_sub.iloc[:, 1:7])\n",
    "majority = np.mean(predictDF, axis=1)\n",
    "stacked = (majority > 0.5) + 0\n",
    "\n",
    "y_pred = stacked\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.85375000000000001"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_val, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stacking Prediction: Logistic Regression, SVM, NN\n",
    "\n",
    "import os\n",
    "\n",
    "sub_path = \"submissions_CV/stack3/\"\n",
    "all_files = os.listdir(sub_path)\n",
    "\n",
    "# Read and concatenate submissions\n",
    "outs = [pd.read_csv(os.path.join(sub_path, f), index_col=0) for f in all_files]\n",
    "concat_sub = pd.concat(outs, axis=1)\n",
    "cols = list(map(lambda x: \"Prediction\" + str(x), range(len(concat_sub.columns))))\n",
    "concat_sub.columns = cols\n",
    "concat_sub.reset_index(inplace=True)\n",
    "\n",
    "predictDF = np.array(concat_sub.iloc[:, 1:7])\n",
    "majority = np.mean(predictDF, axis=1)\n",
    "stacked = (majority > 0.5) + 0\n",
    "\n",
    "y_pred = stacked\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.85099999999999998"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_val, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stacking Prediction: Logistic Regression (Dylan), Random Forest, SVM, Naive Bayes (Eric)*2\n",
    "\n",
    "import os\n",
    "\n",
    "sub_path = \"submissions_CV/stack4/\"\n",
    "all_files = os.listdir(sub_path)\n",
    "all_files = sorted(all_files)\n",
    "print(all_files)\n",
    "\n",
    "# Read and concatenate submissions\n",
    "outs = [pd.read_csv(os.path.join(sub_path, f), index_col=0) for f in all_files]\n",
    "concat_sub = pd.concat(outs, axis=1)\n",
    "cols = list(map(lambda x: \"Prediction\" + str(x), range(len(concat_sub.columns))))\n",
    "concat_sub.columns = cols\n",
    "concat_sub.reset_index(inplace=True)\n",
    "\n",
    "predictDF = np.array(concat_sub.iloc[:, 1:7])\n",
    "# majority = np.mean(predictDF, axis=1)\n",
    "\n",
    "bestacc = [0.854, 0.853, 0.851, 0.833]\n",
    "bestaccsum = sum(bestacc)\n",
    "\n",
    "def weightedMajority(predictdf):\n",
    "    majority = []\n",
    "    for row in range(len(y_val)):\n",
    "        wmean = (bestacc[0]*predictdf[row, 0] + bestacc[1]*predictdf[row, 1] + bestacc[2]*predictdf[row, 2] + bestacc[3]*predictdf[row, 3]) / (bestaccsum)\n",
    "        majority.append(wmean)\n",
    "        if row % 10 == 0:\n",
    "            print(str(row))\n",
    "    majority = np.array(majority)\n",
    "    return majority\n",
    "\n",
    "majority = weightedMajority(predictDF)\n",
    "\n",
    "if False:\n",
    "    stacked = majority > 0.5\n",
    "    y_pred = stacked\n",
    "    y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictDF[6, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4000"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(y_pred)\n",
    "len(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.85575000000000001"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_val, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "0.85575000000000001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "0.85624999999999996"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "0.85675000000000001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Final Stack #3: Logistic Regression (Dylan), Random Forest, SVM, Naive Bayes (Eric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Eric Final (whole training set)\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "# from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "label_weights = pd.read_csv(\"./Logistic_L1_weights_229.txt\", delimiter=\"\\t\")\n",
    "\n",
    "nhypers = 10\n",
    "Qs = np.linspace(61, 65, nhypers) # 0.1% of 1000 is 1\n",
    "whichweights = np.zeros((nhypers, x_train.shape[1]))\n",
    "abs_weights = np.absolute(label_weights.weights)\n",
    "for i, Q in enumerate(Qs):\n",
    "    cutoff = np.percentile(a=abs_weights, q=Q)\n",
    "    whichweights[i, :] = np.greater_equal(abs_weights, cutoff)\n",
    "\n",
    "percentiles = [np.percentile(a=np.absolute(label_weights.weights), q=Q) for Q in Qs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 0.854149230309\n"
     ]
    }
   ],
   "source": [
    "val_scores, mean_val_scores, hyper_best_i, models = NBayesCrossVal(whichweights, x_train, y_train, 1, 5, 'multinomial')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.199385044853\n",
      "64.5555555556\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x129e52080>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(percentiles[hyper_best_i])\n",
    "print(Qs[hyper_best_i])\n",
    "plt.plot(Qs, mean_val_scores)\n",
    "plt.show()\n",
    "bestweights = whichweights[hyper_best_i, :] #models[33] # No, all the models are the same!\n",
    "bestmodel = models[0] # All the models are the same!\n",
    "bestmatrix = x_train[:, bestweights.astype('bool')]\n",
    "bestmodel.fit(bestmatrix, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Id  Prediction\n",
      "0   1           1\n",
      "1   2           1\n",
      "2   3           0\n",
      "3   4           0\n",
      "4   5           0\n",
      "5   6           0\n",
      "6   7           1\n",
      "7   8           1\n",
      "8   9           1\n",
      "9  10           0\n"
     ]
    }
   ],
   "source": [
    "y_pred = bestmodel.predict(x_test[:, bestweights.astype('bool')])\n",
    "\n",
    "submission = pd.DataFrame({'Id': range(1, len(x_test)+1), 'Prediction': [int(x) for x in y_pred]})\n",
    "print(submission.head(10))\n",
    "\n",
    "submission.to_csv('submissions_CV/stack1/submission_optimal_Naive_Bayes_Eric_Final.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Dylan Final\n",
    "\n",
    "# Copied from his ...reg_optimal.py\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "# Import training data\n",
    "original_training_data = np.loadtxt(\"training_data.txt\", skiprows=1)\n",
    "# Import test data\n",
    "original_test_data = np.loadtxt(\"test_data.txt\", skiprows=1)\n",
    "# Produce joint tf-idf-generating dataset\n",
    "pre_tf_idf = np.append(original_training_data[:,1:], original_test_data, axis=0)\n",
    "\n",
    "# Compute tf-idf\n",
    "tfidf_trans = TfidfTransformer()\n",
    "full_tf_idf = tfidf_trans.fit_transform(pre_tf_idf)\n",
    "full_tf_idf = full_tf_idf.toarray()\n",
    "\n",
    "# Reconstitute training data\n",
    "train_labels = original_training_data[:,0]\n",
    "train_labels = train_labels.reshape(20000,1)\n",
    "training_tf_idf = np.append(train_labels, full_tf_idf[0:20000,:], axis=1)\n",
    "\n",
    "# Reconstitute test data\n",
    "test_tf_idf = full_tf_idf[20000:, :]\n",
    "\n",
    "# Train model on tf-idf training data\n",
    "training_x = training_tf_idf[:,1:]\n",
    "training_y = training_tf_idf[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.9483, class_weight=None, dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
       "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression(penalty='l2', C = 0.9483)\n",
    "model.fit(training_x, training_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Id  Prediction\n",
      "0   1           1\n",
      "1   2           1\n",
      "2   3           0\n",
      "3   4           0\n",
      "4   5           0\n",
      "5   6           0\n",
      "6   7           1\n",
      "7   8           1\n",
      "8   9           1\n",
      "9  10           0\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(test_tf_idf)\n",
    "\n",
    "submission = pd.DataFrame({'Id': range(1, len(test_tf_idf)+1), 'Prediction': [int(x) for x in y_pred]})\n",
    "print(submission.head(10))\n",
    "\n",
    "submission.to_csv('submissions/submission_optimal_Dylan_TFIFDall_0.9483_Final.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Prediction0</th>\n",
       "      <th>Prediction1</th>\n",
       "      <th>Prediction2</th>\n",
       "      <th>Prediction3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  Prediction0  Prediction1  Prediction2  Prediction3\n",
       "0   1            1            1            1            1\n",
       "1   2            1            1            1            1\n",
       "2   3            0            0            0            0\n",
       "3   4            0            0            0            0\n",
       "4   5            0            0            0            1\n",
       "5   6            0            0            0            0\n",
       "6   7            1            1            1            1\n",
       "7   8            1            1            1            1\n",
       "8   9            1            1            1            1\n",
       "9  10            0            0            0            0"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "sub_path = \"submissions/\"\n",
    "all_files = os.listdir(sub_path)\n",
    "\n",
    "# Read and concatenate submissions\n",
    "outs = [pd.read_csv(os.path.join(sub_path, f), index_col=0) for f in all_files]\n",
    "concat_sub = pd.concat(outs, axis=1)\n",
    "cols = list(map(lambda x: \"Prediction\" + str(x), range(len(concat_sub.columns))))\n",
    "concat_sub.columns = cols\n",
    "concat_sub.reset_index(inplace=True)\n",
    "concat_sub.head(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0])"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictDF = np.array(concat_sub.iloc[:, 1:6])\n",
    "predictDF[0:5, ] #.head()\n",
    "majority = np.mean(predictDF, axis=1)\n",
    "majority[0:5]\n",
    "stacked = (majority > 0.5) + 0\n",
    "stacked[0:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Id  Prediction\n",
      "0   1           1\n",
      "1   2           1\n",
      "2   3           0\n",
      "3   4           0\n",
      "4   5           0\n",
      "5   6           0\n",
      "6   7           1\n",
      "7   8           1\n",
      "8   9           1\n",
      "9  10           0\n"
     ]
    }
   ],
   "source": [
    "submission = pd.DataFrame({'Id': range(1, len(x_test)+1), 'Prediction': [int(x) for x in stacked]})\n",
    "print(submission.head(10))\n",
    "\n",
    "submission.to_csv('submission_majority_stack_Final_Stack_3.csv', index=False, header=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
